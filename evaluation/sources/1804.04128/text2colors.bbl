\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{ahn2017text2action}
Ahn, H., Ha, T., Choi, Y., Yoo, H., Oh, S.: {Text2Action}: Generative
  adversarial synthesis from language to action. In: Proc. the IEEE
  International Conference on Robotics and Automation (ICRA) (2018)

\bibitem{bahdanau2014neural}
Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly
  learning to align and translate. In: Proc. the International Conference on
  Learning Representations (ICLR) (2014)

\bibitem{chang2015palette}
Chang, H., Fried, O., Liu, Y., DiVerdi, S., Finkelstein, A.: Palette-based
  photo recoloring. ACM Transactions on Graphics (TOG)  \textbf{34}(4) (2015)

\bibitem{charpiat2008automatic}
Charpiat, G., Hofmann, M., Sch{\"o}lkopf, B.: Automatic image colorization via
  multimodal predictions. In: Proc. the European Conference on Computer Vision
  (ECCV) (2008)

\bibitem{cho2017palettenet}
Cho, J., Yun, S., Lee, K., Choi, J.Y.: {PaletteNet}: Image recolorization with
  given color palette. In: Proc. the IEEE Conference on Computer Vision and
  Pattern Recognition Workshops (2017)

\bibitem{cho2014learning}
Cho, K., Van~Merri{\"e}nboer, B., Gulcehre, C., Bahdanau, D., Bougares, F.,
  Schwenk, H., Bengio, Y.: Learning phrase representations using {RNN}
  encoder-decoder for statistical machine translation. In: Conference on
  Empirical Methods in Natural Language Processing (EMNLP) (2014)

\bibitem{choi2017stargan}
Choi, Y., Choi, M., Kim, M., Ha, J.W., Kim, S., Choo, J.: {StarGAN}: Unified
  generative adversarial networks for multi-domain image-to-image translation.
  In: Proc. the IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR) (2017)

\bibitem{chuang2008probabilistic}
Chuang, J., Stone, M., Hanrahan, P.: A probabilistic model of the categorical
  association between colors. In: Proc. the IS\&T Color and Imaging Conference
  (CIC). vol.~2008 (2008)

\bibitem{crozier1996psychology}
Crozier, W.: The psychology of colour preferences. Coloration Technology
  \textbf{26}(1) (1996)

\bibitem{de2001colours}
De~Bortoli, M., Maroto, J.: Colours across cultures: Translating colours in
  interactive marketing communications. In: Proc. the European Languages and
  the Implementation of Communication and Information Technologies (ELICIT)
  (2001)

\bibitem{guadarrama2017pixcolor}
Guadarrama, S., Dahl, R., Bieber, D., Norouzi, M., Shlens, J., Murphy, K.:
  Pixcolor: Pixel recursive colorization. In: Proc. the British Machine Vision
  Conference (BMVC) (2017)

\bibitem{heer2012color}
Heer, J., Stone, M.: Color naming models for color selection, image editing and
  palette design. In: Proc. the SIGCHI Conference on Human Factors in Computing
  Systems (SIGCHI) (2012)

\bibitem{isola2017image}
Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.: Image-to-image translation with
  conditional adversarial networks. In: Proc. the IEEE Conference on Computer
  Vision and Pattern Recognition (CVPR) (2017)

\bibitem{jahanian2017colors}
Jahanian, A., Keshvari, S., Vishwanathan, S., Allebach, J.P.:
  Colors--messengers of concepts: Visual design mining for learning color
  semantics. ACM Transactions on Computer-Human Interaction (TOCHI)
  \textbf{24}(1) (2017)

\bibitem{kawakami2016character}
Kawakami, K., Dyer, C., Routledge, B.R., Smith, N.A.: Character sequence models
  for colorful words. In: Proc. the Conference on Empirical Methods in Natural
  Language Processing (EMNLP) (2016)

\bibitem{kim2017learning}
Kim, T., Cha, M., Kim, H., Lee, J., Kim, J.: Learning to discover cross-domain
  relations with generative adversarial networks. In: Proc. the International
  Conference on Machine Learning (ICML) (2017)

\bibitem{kingma2014adam}
Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: Proc. the
  International Conference on Learning Representations (ICLR) (2014)

\bibitem{kobayashi2009color}
Kobayashi, S.: Color image scale.
  http://www.ncd-ri.co.jp/english/main\_0104.html  (2009)

\bibitem{labrecque2012exciting}
Labrecque, L.I., Milne, G.R.: Exciting red and competent blue: the importance
  of color in marketing. Journal of the Academy of Marketing Science
  \textbf{40}(5) (2012)

\bibitem{li2015image}
Li, X., Zhao, H., Nie, G., Huang, H.: Image recoloring using geodesic distance
  based color harmonization. Computational Visual Media  \textbf{1}(2) (2015)

\bibitem{liu2014autostyle}
Liu, Y., Cohen, M., Uyttendaele, M., Rusinkiewicz, S.: Autostyle: Automatic
  style transfer from image collections to users' images. Computer Graphics
  Forum (CGF)  \textbf{33}(4) (2014)

\bibitem{luong2015effective}
Luong, M.T., Pham, H., Manning, C.D.: Effective approaches to attention-based
  neural machine translation. In: Proc. the Conference on Empirical Methods in
  Natural Language Processing (EMNLP) (2015)

\bibitem{mcmahan2015bayesian}
McMahan, B., Stone, M.: A bayesian model of grounded color semantics.
  Transactions of the Association of Computational Linguistics (TACL)
  \textbf{3}(1) (2015)

\bibitem{mirza2014conditional}
Mirza, M., Osindero, S.: Conditional generative adversarial nets. arXiv
  preprint arXiv:1411.1784  (2014)

\bibitem{monroe2017colors}
Monroe, W., Hawkins, R.X., Goodman, N.D., Potts, C.: Colors in context: A
  pragmatic neural model for grounded language understanding. Transactions of
  the Association of Computational Linguistics (ACL)  (2017)

\bibitem{munroe2010color}
Munroe, R.: Color survey results. Online at
  http://blog.xkcd.com/2010/05/03/color-surveyresults  (2010)

\bibitem{murray2012toward}
Murray, N., Skaff, S., Marchesotti, L., Perronnin, F.: Toward automatic and
  flexible concept transfer. Computers \& Graphics  \textbf{36}(6) (2012)

\bibitem{pathak2016context}
Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A.: Context
  encoders: Feature learning by inpainting. In: Proc. the IEEE Conference on
  Computer Vision and Pattern Recognition (CVPR) (2016)

\bibitem{pennington2014glove}
Pennington, J., Socher, R., Manning, C.: Glove: Global vectors for word
  representation. In: Proc. the Conference on Empirical Methods in Natural
  Language Processing (EMNLP) (2014)

\bibitem{radford2015unsupervised}
Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with
  deep convolutional generative adversarial networks. In: Proc. the
  International Conference on Learning Representations (ICLR) (2015)

\bibitem{reed2016learning}
Reed, S., Akata, Z., Lee, H., Schiele, B.: Learning deep representations of
  fine-grained visual descriptions. In: Proc. the IEEE Conference on Computer
  Vision and Pattern Recognition (CVPR) (2016)

\bibitem{reed2016generative}
Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H.: Generative
  adversarial text to image synthesis. In: Proc. the International Conference
  on Machine Learning (ICML) (2016)

\bibitem{ronneberger2015u}
Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for
  biomedical image segmentation. In: Proc. the International Conference on
  Medical Image Computing and Computer Assisted Intervention (MICCAI) (2015)

\bibitem{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.: Imagenet large scale visual
  recognition challenge. International Journal of Computer Vision (IJCV)
  \textbf{115}(3) (2015)

\bibitem{sharma2005ciede2000}
Sharma, G., Wu, W., Dalal, E.N.: The {CIEDE2000} color-difference formula:
  Implementation notes, supplementary test data, and mathematical observations.
  Color Research \& Application  \textbf{30}(1) (2005)

\bibitem{solli2010color}
Solli, M., Lenz, R.: Color semantics for image indexing. In: Proc. the
  Conference on Colour in Graphics Imaging and Vision (CGIV) (2010)

\bibitem{sutskever2011generating}
Sutskever, I., Martens, J., Hinton, G.E.: Generating text with recurrent neural
  networks. In: Proc. the International Conference on Machine Learning (ICML)
  (2011)

\bibitem{sutskever2014sequence}
Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural
  networks. In: Advances in Neural Information Processing Systems (NIPS) (2014)

\bibitem{tang2015document}
Tang, D., Qin, B., Liu, T.: Document modeling with gated recurrent neural
  network for sentiment classification. In: Proc. the Conference on Empirical
  Methods in Natural Language Processing (EMNLP) (2015)

\bibitem{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,
  Kaiser, {\L}., Polosukhin, I.: Attention is all you need. In: Advances in
  Neural Information Processing Systems (NIPS) (2017)

\bibitem{WahCUB_200_2011}
Wah, C., Branson, S., Welinder, P., Perona, P., Belongie, S.: {The Caltech-UCSD
  Birds-200-2011 Dataset}. Tech. Rep. CNS-TR-2011-001, California Institute of
  Technology (2011)

\bibitem{xiao2018interactive}
Xiao, Y., Zhou, P., Zheng, Y.: Interactive deep colorization with simultaneous
  global and local inputs. arXiv preprint arXiv:1801.09083  (2018)

\bibitem{zhang2017stackgan}
Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X., Wang, X., Metaxas, D.:
  {StackGAN}: Text to photo-realistic image synthesis with stacked generative
  adversarial networks. In: Proc. the IEEE International Conference on Computer
  Vision (ICCV) (2017)

\bibitem{zhang2016colorful}
Zhang, R., Isola, P., Efros, A.A.: Colorful image colorization. In: Proc. the
  European Conference on Computer Vision (ECCV) (2016)

\bibitem{zhang2017real}
Zhang, R., Zhu, J.Y., Isola, P., Geng, X., Lin, A.S., Yu, T., Efros, A.A.:
  Real-time user-guided image colorization with learned deep priors. ACM
  Transactions on Graphics (TOG)  (2017)

\end{thebibliography}
