\section{Proof of Theorem~\ref{thm:main}}\label{appx:proof}
\allowdisplaybreaks

The arguments used in the proof of Theorem~\ref{thm:main} follow similar steps to those in~\cite{calvo2021state}, with some minor differences specific to our problem formulation, as outlined in Remark~\ref{remark:proof_diff}. We, therefore, include the complete proof here for the paper to be self-complete.% there are differences with prior proofs, specific to our problem formulation, that require us to include the complete proof here.

\subsection{Tightness of The Sequence of Dual Variable Probability Measures}\label{appx:proof_tightness}
We start by proving that the sequence of dual variable probability measures, i.e., $\{p(\bbmu_k|\bbmu_0)\}_{k}$, is tight in the following lemma.

\begin{lemma}
For any $\delta > 0$, there exists a compact set $\ccalA_{\delta}$ such that for every $k \geq 0$, we have $\mathsf{Pr}[\bbmu_k \in \ccalA_{\delta}] > 1 - \delta$.
\end{lemma}

\begin{proof}
Define the dual function, $d(\bbmu)$ as
\begin{align}\label{eq:def_dual_function}
d(\bbmu) = \max_{\bbtheta\in\bbTheta} \ccalL(\bbtheta, \bbmu),
\end{align}
and consider the following set:
\begin{align}\label{eq:def_C}
\ccalC = \left\{\bbmu \in \reals_+^c : d(\bbmu) - P^{\star} \leq \frac{c\eta_{\bbmu}G^2}{2} \right\}.
\end{align}
Now, let
\begin{align}
\ccalA_{\delta} = \ccalB_{\delta} \cup \left(\ccalC \oplus \ccalS_{\sqrt{c\eta_{\bbmu}^2 G^2}}\right),
\end{align}
where $\oplus$ denotes Minkowski sum, $\ccalS_r$ denotes a ball centered at the origin with radius $r\geq0$, and $\ccalB_{\delta}$ is defined as
\begin{align}
\ccalB_{\delta} = \left\{\bbmu \in \reals_+^c : \frac{\| \bbmu - \bbmu^{\star} \|}{\| \bbmu_0 - \bbmu^{\star}\|} \leq \frac{1}{\delta} \right\},
\end{align}
with $\bbmu^{\star}$ representing the optimal set of dual variables. Then, we have
\begin{align}
&\mathsf{Pr}[\bbmu_k \in \ccalA_{\delta}] \nonumber \\
& = \mathsf{Pr}\left[\bbmu_k \in \ccalB_{\delta} \cup \left(\ccalC \oplus \ccalS_{\sqrt{c\eta_{\bbmu}^2 G^2}}\right) \right] \\
& = \underbrace{\mathsf{Pr}\left[\bbmu_k \in \ccalB_{\delta} \cup \left(\ccalC \oplus \ccalS_{\sqrt{c\eta_{\bbmu}^2 G^2}}\right) \middle| \bbmu_{k-1}\in\ccalC \right]}_{\overset{(a)}{=}1} \cdot \ p \nonumber \\
& \quad + \underbrace{\mathsf{Pr}\left[\bbmu_k \in \ccalB_{\delta} \cup \left(\ccalC \oplus \ccalS_{\sqrt{c\eta_{\bbmu}^2 G^2}}\right) \middle| \bbmu_{k-1}\in\ccalC^c \right]}_{\geq \mathsf{Pr}\left[\bbmu_k \in \ccalB_{\delta}  \middle| \bbmu_{k-1}\in\ccalC^c \right]} \cdot \ (1-p) \nonumber \\
& \geq \mathsf{Pr}\left[\bbmu_k \in \ccalB_{\delta}  \middle| \bbmu_{k-1}\in\ccalC^c \right] \\
& = \mathsf{Pr}\left[\frac{\| \bbmu_k - \bbmu^{\star} \|}{\| \bbmu_0 - \bbmu^{\star}\|} \leq \frac{1}{\delta}  \middle| \bbmu_{k-1}\in\ccalC^c \right] \\
& \geq 1 - \left( \frac{\E\left[\| \bbmu_k - \bbmu^{\star} \| \middle| \bbmu_{k-1}\in\ccalC^c\right]}{\| \bbmu_0 - \bbmu^{\star}\|} \right) \delta,
\end{align}
where $p=\mathsf{Pr}\left[\bbmu_{k-1}\in\ccalC \right]$, (a) is true due to the dual dynamics in~\eqref{eq:mu_dynamics} and the fact that the change between $\bbmu_{k-1}$ and $\bbmu_k$ is upper bounded in norm by $\sqrt{c\eta_{\bbmu}^2 G^2}$, and the last inequality is due to conditional Markov's inequality. Therefore, to complete the proof, it suffices to show that (i)
\begin{align}\label{eq:bounded_conditional_difference_norm_muk}
\E\left[\| \bbmu_k - \bbmu^{\star} \| \middle| \bbmu_{k-1}\in\ccalC^c\right] < \| \bbmu_0 - \bbmu^{\star}\|,
\end{align}
and (ii) that $\ccalA_{\delta}$ is compact.

\noindent\textbf{Proof of~\eqref{eq:bounded_conditional_difference_norm_muk}.}
Let $\Delta_{\bbmu_{k-1}}$ be defined as
\begin{align}
\Delta_{\bbmu_{k-1}} \coloneqq \bbg\left( \frac{1}{T_0} \sum_{t=(k-1)T_0}^{kT_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_{k-1})) \right).
\end{align}
Then, from the dual dynamics in~\eqref{eq:mu_dynamics}, we have
\begin{align*}
&\|\bbmu_{k} - \bbmu^{\star}\|^2 \\
&\leq \|\bbmu_{k-1} - \bbmu^{\star} - \eta_{\bbmu} \Delta_{\bbmu_{k-1}} \|^2 \\
&= \|\bbmu_{k-1} - \bbmu^{\star}  \|^2 + \eta_{\bbmu}^2 \|\Delta_{\bbmu_{k-1}} \|^2 \nonumber \\
&\quad - 2\eta_{\bbmu} (\bbmu_{k-1} - \bbmu^{\star})^T \Delta_{\bbmu_{k-1}} \\
&\leq \|\bbmu_{k-1} - \bbmu^{\star}  \|^2 + c \eta_{\bbmu}^2 G^2 - 2\eta_{\bbmu} (\bbmu_{k-1} - \bbmu^{\star})^T \Delta_{\bbmu_{k-1}},
\end{align*}
where the last inequality follows from the fact that for any $i\in\{1,\dots,c\}$, we assume $|g_i\left(\cdot\right)|\leq G$. Taking the expectation of both sides conditioned on $\bbmu_{k-1}$, we have
\begin{align}
&\E\left[\|\bbmu_{k} - \bbmu^{\star}\|^2 \middle| \bbmu_{k-1}\right] \nonumber\\
&\leq \|\bbmu_{k-1} - \bbmu^{\star}  \|^2 + c \eta_{\bbmu}^2 G^2 \nonumber \\
&\quad - 2\eta_{\bbmu} (\bbmu_{k-1} - \bbmu^{\star})^T \E\left[\Delta_{\bbmu_{k-1}}\middle| \bbmu_{k-1}\right]\\
&\leq \|\bbmu_{k-1} - \bbmu^{\star}  \|^2 + c \eta_{\bbmu}^2 G^2 - 2\eta_{\bbmu} (d(\bbmu_{k-1}) - d(\bbmu^{\star}))\label{eq:subgradient}\\
&= \|\bbmu_{k-1} - \bbmu^{\star}  \|^2 + c \eta_{\bbmu}^2 G^2 - 2\eta_{\bbmu} (d(\bbmu_{k-1}) - P^{\star}),\label{eq:pre_C_bound}
\end{align}
where~\eqref{eq:subgradient} follows from the fact that $\Delta_{\bbmu_{k-1}}$ is a subgradient of the dual function~\cite{danskin2012theory}, leading to the inequality $(\bbmu_{k-1} - \bbmu^{\star})^T \E\left[\Delta_{\bbmu_{k-1}}\middle| \bbmu_{k-1}\right] \geq d(\bbmu_{k-1}) - d(\bbmu^{\star})$ thanks to the dual function being convex~\cite{boyd2004convex}. Now, combining the fact that $\bbmu_{k-1}\in\ccalC^c$ with the definition of $\ccalC$ in~\eqref{eq:def_C}, we can continue~\eqref{eq:pre_C_bound} as
\begin{align}
\E\left[\|\bbmu_{k} - \bbmu^{\star}\|^2 \middle| \bbmu_{k-1}\in\ccalC^c\right]
&< \|\bbmu_{k-1} - \bbmu^{\star}\|^2 \\
&< \|\bbmu_{0} - \bbmu^{\star}\|^2,
\end{align}
with the last inequality following from recursion.


\noindent\textbf{Proof of Compactness of $\ccalA_{\delta}$.} Since the Minkowski sum of two compact sets is compact, and also the union of two compact sets is compact, it suffices to show that the set $\ccalC$ is compact.

Given the definition of the dual function in~\eqref{eq:def_dual_function}, for any set of model parameters $\bbtheta\in\bbTheta$ and any set of dual variables $\bbmu\in\reals_+^c$, we have
\begin{align}
d(\bbmu) &\geq \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right)\nonumber \\
   &\qquad\qquad+ \bbmu^T \bbg\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right)
\end{align}
Now, replacing $\bbtheta$ with the strictly-feasible set of model parameters $\hat{\bbtheta}$ considered in Theorem~\ref{thm:main}, we can write
\begin{align}
d(\bbmu) &\geq \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\hat{\bbtheta})) \right)\nonumber \\
   &\qquad\qquad+ \bbmu^T \bbg\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\hat{\bbtheta})) \right)\\
&\geq \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\hat{\bbtheta})) \right) + G' \| \bbmu \|_1.\label{eq:dual_upper_bound}
\end{align}
Now, for any $\bbmu\in\ccalC$, according to the definition in~\eqref{eq:def_C}, the bound in~\eqref{eq:dual_upper_bound} leads to
\begin{align}
P^{\star} + \frac{c\eta_{\bbmu}G^2}{2}  \geq \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\hat{\bbtheta})) \right) + G' \| \bbmu \|_1,
\end{align}
implying that $\bbmu$ belongs to the following ball,
\begin{align}
\| \bbmu \|_1 \leq \frac{P^{\star} + \frac{c\eta_{\bbmu}G^2}{2} - \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\hat{\bbtheta})) \right)}{G'},
\end{align}
hence completing the proof.


\end{proof}

\subsection{Proof of Feasibility in~\eqref{eq:thm_feasibility}}\label{appx:proof_feasibility}

From the dual dynamics in~\eqref{eq:mu_dynamics}, we have
\begin{align}\label{eq:mu_inequality}
% \bbmu_{T+1} &\geq \bbmu_T - \eta_{\bbmu} \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T;\bbtheta_T)) \right).
\bbmu_{K} &\geq \bbmu_{K-1} - \eta_{\bbmu} \bbg\left( \frac{1}{T_0} \sum_{t=(K-1)T_0}^{KT_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_{K-1})) \right)\hspace{-3pt}.
\end{align}
Using the inequality in~\eqref{eq:mu_inequality} recursively yields
% \begin{align}
% \bbmu_{T+1} &\geq \bbmu_1 - \eta_{\bbmu} \sum_{t=1}^T \bbg\left(  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_t)) \right) \\
% &= \bbmu_1 - T \eta_{\bbmu} \left(\frac{1}{T} \sum_{t=1}^T  \bbg\left(  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_t)) \right)\right) \\
% &\geq \bbmu_1 - T \eta_{\bbmu}  \bbg\left( \frac{1}{T} \sum_{t=1}^T  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_t)) \right),
% \end{align}
\begin{align*}
&\bbmu_{K} \nonumber \\
&\geq \bbmu_0 - \eta_{\bbmu} \sum_{k=0}^{K-1} \bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right) \nonumber \\
&= \bbmu_0 - K\eta_{\bbmu} \cdot \frac{1}{K}\hspace{-3pt}\sum_{k=0}^{K-1} \bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right) \nonumber \\
&\geq \bbmu_0 - K\eta_{\bbmu} \bbg\left( \frac{1}{KT_0} \sum_{t=0}^{KT_0-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_{\lfloor t/T_0 \rfloor})) \right),
\end{align*}
where the last inequality follows from the concavity of $\bbg(\cdot)$. Therefore, we have
% \begin{align}\label{eq:muT+1_vs_mu1}
% &\limsup_{T\to\infty}\bbmu_{T+1}  \nonumber\\ 
% &\geq \bbmu_1 - \eta_{\bbmu} \liminf_{T\to\infty} T \bbg\left( \frac{1}{T} \sum_{t=1}^T  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_t)) \right).
% \end{align}
\begin{align}\label{eq:muT+1_vs_mu1}
&\limsup_{K\to\infty}\bbmu_{K+1}  \nonumber\\ 
&\geq \bbmu_0 - \eta_{\bbmu} \liminf_{K\to\infty} K \bbg\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_{\lfloor t/T_0 \rfloor})) \right).
\end{align}
Now, assume by contradiction that one of the constraints in~\eqref{eq:thm_feasibility} is not satisfied. More precisely, assume there exists an index $i\in\{1,\dots,c\}$ and positive constants $\delta>0$ and $\beta\in(0,1)$ such that
\begin{align}\label{eq:contradiction_prob}
\mathsf{Pr}\left[\liminf_{T\to\infty} g_i\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_{\lfloor t/T_0 \rfloor})) \right) \leq -\delta \right] = \beta.
\end{align}
This implies that with non-zero probability $\beta$, we would have
% \begin{align}
% &\limsup_{T\to\infty} \|\bbmu_{T+1}\|_1 \nonumber \\
% &\geq \limsup_{T\to\infty} \mu_{i,T+1}\label{eq:1_norm} \\
% &\geq \mu_{i,1} - \eta_{\bbmu} \liminf_{T\to\infty} T g_i\left( \frac{1}{T} \sum_{t=1}^T  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_t)) \right)\label{eq:ith_bound} \\
% &\geq \mu_{i,1} + \eta_{\bbmu} \liminf_{T\to\infty} T \epsilon \label{eq:contradiction_prob_use} \\
% &= \infty,
% \end{align}
\begin{align}
&\limsup_{K\to\infty} \|\bbmu_{K}\|_1 \nonumber \\
&\geq \limsup_{K\to\infty} \mu_{i,K}\label{eq:1_norm} \\
&\geq \mu_{i,0} - \eta_{\bbmu} \liminf_{K\to\infty} K g_i\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_{\lfloor t/T_0 \rfloor})) \right)\label{eq:ith_bound} \\
&\geq \mu_{i,0} + \eta_{\bbmu} \liminf_{K\to\infty} K \epsilon \label{eq:contradiction_prob_use} \\
&= \infty,
\end{align}
where~\eqref{eq:1_norm} follows from the definition of the $\ell_1$-norm% and the fact that $\mu_{i,T+1} \geq 0$
,~\eqref{eq:ith_bound} follows from the $i$\textsuperscript{th} inequality in~\eqref{eq:muT+1_vs_mu1}, and~\eqref{eq:contradiction_prob_use} follows from~\eqref{eq:contradiction_prob}. This contradicts the fact that the sequence of dual variable probabilities is tight, hence completing the proof.
\hfill$\square$


\subsection{Proof of Optimality in~\eqref{eq:thm_optimality}}


Given the dual dynamics in~\eqref{eq:mu_dynamics} and the fact that projection onto the non-negative orthant does not increase the $\ell_2$-norm, we have
\begin{align}
&\left\|\bbmu_{K+1}\right\|^2\nonumber\\
&\leq \left\|\bbmu_K - \eta_{\bbmu} \bbg\left( \frac{1}{T_0} \sum_{t=KT_0}^{(K+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_K)) \right) \right\|^2\label{eq:norm_dual_update}\\
&=\left\|\bbmu_K \right\|^2 + \eta_{\bbmu}^2 \left\| \bbg\left( \frac{1}{T_0} \sum_{t=KT_0}^{(K+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_K)) \right)\right\|^2 \nonumber \\
&~\quad- 2\eta_{\bbmu}\bbmu_K^T \bbg\left( \frac{1}{T_0} \sum_{t=KT_0}^{(K+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_K)) \right)\label{eq:norm_dual_square_expansion}\\
&\leq\left\|\bbmu_T\right\|^2 + c\eta_{\bbmu}^2 G^2  \nonumber \\
&~\quad - 2\eta_{\bbmu}\bbmu_K^T \bbg\left( \frac{1}{T_0} \sum_{t=KT_0}^{(K+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_K)) \right),\label{eq:g_bounded}
\end{align}
% Since $\left\|\bbmu_{T+1}\right\|^2 \geq 0$, expanding the squared norm on the right-hand side of~\eqref{eq:norm_dual_update} yields
% \begin{align}\label{eq:norm_dual_square_expansion}
% 0 &\leq \left\|\bbmu_T\right\|^2 + \eta_{\bbmu}^2 \left\| \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T, \bbmu_T;\bbtheta)) \right)\right\|^2 - 2\eta_{\bbmu}\bbmu_T^T \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T, \bbmu_T;\bbtheta)) \right) .
% \end{align}
%Since 
where the last inequality follows from the fact that for any $i\in\{1,\dots,c\}$, we assume $|g_i\left(\cdot\right)|\leq G$. Applying~\eqref{eq:g_bounded} recursively yields
\begin{align}
&\left\|\bbmu_{K+1}\right\|^2 \nonumber\\
&\leq \left\|\bbmu_0\right\|^2 + c\eta_{\bbmu}^2 K G^2  \nonumber \\
&~\quad - 2\eta_{\bbmu} \sum_{k=0}^{K-1} \bbmu_k^T \bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right).\label{eq:g_bounded_recursive}
\end{align}
Since $\left\|\bbmu_{K+1}\right\|^2 \geq 0$, rearranging the terms in~\eqref{eq:g_bounded_recursive} and normalizing both sides by $2\eta_{\bbmu}K$ results in
% \begin{align}\label{eq:inner_prod_dual_init}
% \bbmu_T^T \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T, \bbmu_T;\bbtheta)) \right) \leq \frac{1}{2\eta_{\bbmu}}\left\|\bbmu_T\right\|^2 + \frac{c\eta_{\bbmu}G^2}{2}.
% \end{align}
% Applying~\eqref{eq:inner_prod_dual_init} recursively and normalizing by $T$, we will have
\begin{align}\label{eq:inner_prod_dual_recursive_normalized}
&\frac{1}{K} \sum_{k=0}^{K-1} \bbmu_k^T \bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\nonumber \\
&\leq \frac{1}{2\eta_{\bbmu}K} \left\|\bbmu_0\right\|^2 + \frac{c\eta_{\bbmu}G^2}{2}.
\end{align}
Taking the conditional expectation of both sides in~\eqref{eq:inner_prod_dual_recursive_normalized} given $\bbmu_0$, and letting $K\to\infty$, we can write
\begin{align}
&\limsup_{K\to\infty} \E\left[\sum_{k=0}^{K-1} \frac{\bbmu_k^T}{K} \bbg\left(  \sum_{t=kT_0}^{(k+1)T_0-1} \frac{\bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k))}{T_0} \right)\middle|\bbmu_0\right] \nonumber \\
&\leq \frac{c\eta_{\bbmu}G^2}{2}.\label{eq:inner_prod_dual_limsup}
\end{align}


%%%% SINGLE-STEP MU UPDATES
% Given the dual dynamics in~\eqref{eq:mu_dynamics} and the fact that projection onto the non-negative orthant does not increase the $\ell_2$-norm, we have
% \begin{align}
% \left\|\bbmu_{T+1}\right\|^2 &\leq \left\|\bbmu_T - \eta_{\bbmu} \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T;\bbtheta_{\lfloor T / T_0 \rfloor})) \right)\right\|^2\label{eq:norm_dual_update}\\
% &=\left\|\bbmu_T\right\|^2 + \eta_{\bbmu}^2 \left\| \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T;\bbtheta_{\lfloor T / T_0 \rfloor})) \right)\right\|^2 \nonumber \\
% &~\quad- 2\eta_{\bbmu}\bbmu_T^T \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T;\bbtheta_{\lfloor T / T_0 \rfloor})) \right)\label{eq:norm_dual_square_expansion}\\
% &\leq\left\|\bbmu_T\right\|^2 + c\eta_{\bbmu}^2 G^2  \nonumber \\
% &~\quad - 2\eta_{\bbmu}\bbmu_T^T \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T;\bbtheta_{\lfloor T / T_0 \rfloor})) \right),\label{eq:g_bounded}
% \end{align}
% % Since $\left\|\bbmu_{T+1}\right\|^2 \geq 0$, expanding the squared norm on the right-hand side of~\eqref{eq:norm_dual_update} yields
% % \begin{align}\label{eq:norm_dual_square_expansion}
% % 0 &\leq \left\|\bbmu_T\right\|^2 + \eta_{\bbmu}^2 \left\| \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T, \bbmu_T;\bbtheta)) \right)\right\|^2 - 2\eta_{\bbmu}\bbmu_T^T \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T, \bbmu_T;\bbtheta)) \right) .
% % \end{align}
% %Since 
% where the last inequality follows from the fact that for any $k\in\{1,\dots,c\}$, we assume $|g_k\left(  \bbf(\bbH_T, \bbp(\bbH_T;\bbtheta_{\lfloor T / T_0 \rfloor}))\right)|\leq G$. Applying~\eqref{eq:g_bounded} recursively yields
% \begin{align}
% \left\|\bbmu_{T+1}\right\|^2 &\leq \left\|\bbmu_1\right\|^2 + c\eta_{\bbmu}^2 T G^2  \nonumber \\
% &~\quad - 2\eta_{\bbmu} \sum_{t=1}^T \bbmu_t^T \bbg\left(  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_{\lfloor t / T_0 \rfloor})) \right).\label{eq:g_bounded_recursive}
% \end{align}
% Since $\left\|\bbmu_{T+1}\right\|^2 \geq 0$, rearranging the terms in~\eqref{eq:g_bounded_recursive} and normalizing both sides by $2\eta_{\bbmu}T$ results in
% % \begin{align}\label{eq:inner_prod_dual_init}
% % \bbmu_T^T \bbg\left(  \bbf(\bbH_T, \bbp(\bbH_T, \bbmu_T;\bbtheta)) \right) \leq \frac{1}{2\eta_{\bbmu}}\left\|\bbmu_T\right\|^2 + \frac{c\eta_{\bbmu}G^2}{2}.
% % \end{align}
% % Applying~\eqref{eq:inner_prod_dual_init} recursively and normalizing by $T$, we will have
% \begin{align}\label{eq:inner_prod_dual_recursive_normalized}
% \frac{1}{T} \sum_{t=1}^T \bbmu_t^T \bbg\left(  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_{\lfloor t / T_0 \rfloor})) \right) \leq \frac{1}{2\eta_{\bbmu}T} \left\|\bbmu_1\right\|^2 + \frac{c\eta_{\bbmu}G^2}{2}.
% \end{align}
% Taking the conditional expectation of both sides in~\eqref{eq:inner_prod_dual_recursive_normalized} given $\bbmu_1$, and letting $T\to\infty$, we can write
% \begin{align}\label{eq:inner_prod_dual_limsup}
% \limsup_{T\to\infty}\frac{1}{T} \sum_{t=1}^T \E\left[\bbmu_t^T \bbg\left(  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta_{\lfloor t / T_0 \rfloor})) \right) | \bbmu_1 \right] \leq \frac{c\eta_{\bbmu}G^2}{2}.
% \end{align}



% {\color{black} %\textbf{Alternative solution:}

For any iteration $k$, since $\bbtheta_k$ is the maximizer of~\eqref{eq:theta_dynamics}, for any $\bbtheta\in\bbTheta$, we can write
\begin{align}
& \mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\nonumber \\
   &\qquad+ \bbmu_{k}^T \bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\nonumber   \\
& \geq \mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta)) \right)\nonumber \\
   &\qquad+ \bbmu_{k}^T \bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta)) \right)\nonumber 
\end{align}

Taking the expectations of both sides conditioned on $\bbmu_{k}$, we have
\begin{align}
&\E\left[\mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\middle| \bbmu_{k} \right]\nonumber \\
   &\qquad+ \bbmu_{k}^T \E\left[\bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\middle| \bbmu_{k} \right]\nonumber   \\
&\geq \E\left[\mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta)) \right)\right]\nonumber \\
   &\qquad+ \bbmu_{k}^T \E\left[\bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta)) \right)\right] \\
&= \E\left[\mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta)) \right)\right]\nonumber \\
   &\qquad+ \underbrace{\bbmu_{k}^T}_{\geq 0} \underbrace{\E\left[\bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta)) \right)\right]}_{\geq 0 \text{ for any feasible }\bbtheta\in\bbTheta}\label{eq:unbiased_estimate_prev_exp}\\
&= \lim_{T\to\infty} \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right)\nonumber \\
   &\qquad+ \underbrace{\bbmu_{k}^T}_{\geq 0} \lim_{T\to\infty} \underbrace{\bbg\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right)}_{\geq 0 \text{ for any feasible }\bbtheta\in\bbTheta}\label{eq:unbiased_estimate_Ug_Tinf}\\
& \geq \lim_{T\to\infty} \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right), \label{eq:objective_RHS}
\end{align}
where~\eqref{eq:unbiased_estimate_Ug_Tinf} follows from the fact that the expected value of the utility and the constraints within each iteration provide unbiased estimates of the objective and constraints in~\eqref{eq:param_problem}, respectively; i.e., for any $k\in\{0,1,2,\dots,K-1\}$ and $\forall \bbtheta \in \bbTheta$,
\begin{align}
&\E\left[\mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta)) \right)\right] \nonumber \\
&\qquad\qquad\qquad = \lim_{T\to\infty}\mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right) \\
&\E\left[\bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta)) \right)\right] \nonumber \\
&\qquad\qquad\qquad = \lim_{T\to\infty}\bbg\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right).
\end{align}
The inequality in~\eqref{eq:objective_RHS} is true for all feasible $\bbtheta\in\bbTheta$, especially for the optimal set of parameters $\bbtheta^{\star}$, for which the RHS of~\eqref{eq:objective_RHS} equals $P^{\star}$. Therefore, we have
\begin{align}
&\E\left[\mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\middle| \bbmu_{k} \right]\nonumber \\
&\geq P^{\star} - \bbmu_{k}^T \E\left[\bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\middle| \bbmu_{k} \right].
% &\geq P^{\star} - \lim_{T\to\infty} \bbmu_t^T \bbg\left( \frac{1}{T} \sum_{t'=t}^{t+T-1} \E\left[\bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) | \bbmu_t\right] \right) \\
% &\geq P^{\star} - \lim_{T\to\infty} \bbmu_t^T \bbg\left( \frac{1}{T} \sum_{t'=KT}^{t+T-1} \E\left[\bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) | \bbmu_t\right] \right) \\
% &= P^{\star} - \lim_{T\to\infty} \bbmu_t^T \bbg\left( \E\left[\bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_t))| \bbmu_t\right] \right) \nn{?}
\end{align}
Averaging the above inequality over $k\in\{0,\dots,K-1\}$, and taking the expected value conditioned on $\bbmu_0$, we will get
\begin{align}
&\E\Bigg[\frac{1}{K} \sum_{k=0}^{K-1} \mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\Bigg| \bbmu_{0} \Bigg]\nonumber \\
&\geq P^{\star} \nonumber \\
& -\E\Bigg[\frac{1}{K} \sum_{k=0}^{K-1} \bbmu_{k}^T \bbg\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right)\Bigg| \bbmu_{0} \Bigg]\hspace{-1pt}.\label{eq:avg_K_ineq}
\end{align}
Letting $K\to\infty$, and plugging~\eqref{eq:inner_prod_dual_limsup} into~\eqref{eq:avg_K_ineq}, we have
\begin{align}
& P^{\star} - \frac{c\eta_{\mu}G^2}{2} \nonumber \\
&\leq P^{\star} \nonumber \\
& - \limsup_{K\to\infty} \E\left[\sum_{k=0}^{K-1} \frac{\bbmu_k^T}{K} \bbg\left(  \sum_{t=kT_0}^{(k+1)T_0-1} \tfrac{\bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k))}{T_0} \right)\middle|\bbmu_0\right] \\
&\leq \liminf_{K\to\infty} \E\Bigg[\frac{1}{K}\hspace{-2pt} \sum_{k=0}^{K-1} \mathcal{U}\left( \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right) \Bigg] \\
&\leq \liminf_{K\to\infty} \E\Bigg[ \mathcal{U}\left( \frac{1}{K}\hspace{-2pt} \sum_{k=0}^{K-1} \frac{1}{T_0} \sum_{t=kT_0}^{(k+1)T_0-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_k)) \right) \Bigg] \label{eq:U_concavity}\\
&= \liminf_{T\to\infty} \E\Bigg[ \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_{\lfloor t / T_0 \rfloor})) \right) \Bigg] \label{eq:final_optimality}
\end{align}
where~\eqref{eq:U_concavity} is due to concavity of $\mathcal{U}$. This completes the proof, due to the assumption that the limit on the left-hand side of~\eqref{eq:final_optimality} exists.
\hfill$\square$

\begin{remark}\label{remark:proof_diff}
Note that the differences between our proof and that of~\cite{calvo2021state} are two-fold: i) In our work, the updates for the dual variables are based on unbiased gradient estimates in~\eqref{eq:unbiased_estimate_prev_exp} as opposed to the reinforcement learning scenario in~\cite{calvo2021state}; and ii) The time averaging operation in our problem formulation happens inside the utility and constraint functions, $\ccalU$ and $\bbg$, respectively, as opposed to the formulation in~\cite{calvo2021state}, where the time averaging operation happens outside the reward functions.
\end{remark}



% \begin{align}
% &P^{\star} - \frac{1}{K} \sum_{t=K}^T \E\left[\bbmu_t^T \bbg\left( \frac{1}{T} \sum_{t'=t}^{t+T-1} \E\left[\bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) | \bbmu_t\right] \right) \bigg| \bbmu_1\right] \nonumber\\
% % &P^{\star} - \lim_{T\to\infty} \frac{1}{T} \sum_{t=1}^T \E\left[\bbmu_t^T \bbg\left( \E\left[\bbf(\bbH_{t}, \bbp(\bbH_{t};\bbtheta_t))| \bbmu_t\right] \right)| \bbmu_1\right] \nonumber\\
% &\leq \lim_{T\to\infty} \frac{1}{T} \sum_{t=1}^T \E\Bigg[\mathcal{U}\left( \frac{1}{T} \sum_{t'=t}^{t+T-1} \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right)\Bigg| \bbmu_1\Bigg] \\
% &\leq \lim_{T\to\infty} \E\Bigg[\mathcal{U}\left( \frac{1}{T^2} \sum_{t=1}^T \sum_{t'=t}^{t+T-1} \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right)\Bigg| \bbmu_1\Bigg] 
% \end{align}


% }


% PREV SOLUTION USING DUAL FUNCTION CONVEXITY
% \pagebreak


% Now, define the dual function, $d(\bbmu)$ as
% \begin{align}
% d(\bbmu) = \max_{\bbtheta\in\bbTheta} \ccalL(\bbtheta, \bbmu).
% \end{align}
% Then, given the fact that the dual function is convex, we have
% \begin{align}
% \frac{1}{T} \sum_{t=1}^T d(\bbmu_t) &\geq d\left(\frac{1}{T} \sum_{t=1}^T \bbmu_t\right) \\
% &\geq P^{\star},\label{eq:dual_larger_primal}
% \end{align}
% where~\eqref{eq:dual_larger_primal} follows from the fact that the dual function upper bounds the value of the primal for any set of dual variables $\bbmu\in\reals_+^c$. 
% Now, for any Lagrangian-maximizing set of parameters $\bbtheta_t$, we can write the dual function $d(\bbmu_t)$ as
% \begin{align}
% d(\bbmu_t) &= \mathcal{U}\left( \frac{1}{T} \sum_{t'=1}^T \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right) \nonumber \\
% &\quad+ \bbmu_t^T \bbg\left( \frac{1}{T} \sum_{t'=1}^T \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right)\label{eq:dual_mut} %\\
% % &= \E\left[\mathcal{U}\left(  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right)\right] \nonumber \\
% % &\quad+ \E\left[\bbmu_t^T \bbg\left(  \bbf(\bbH_t, \bbp(\bbH_t;\bbtheta)) \right)\right].\label{eq:dual_mut}
% \end{align}

% \begin{align}
% \E[d(\bbmu_t)] &= \E\left[\mathcal{U}\left( \frac{1}{T} \sum_{t'=t+1}^{t+T} \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right) | \bbmu_t\right] \nonumber \\
% &\quad+ \E\left[\bbmu_t^T \bbg\left( \frac{1}{T} \sum_{t'=t+1}^{t+T} \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right)| \bbmu_t\right]\\
% &\leq \E\left[\mathcal{U}\left( \frac{1}{T} \sum_{t'=t+1}^{t+T} \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right) | \bbmu_t\right] \nonumber \\
% &\quad+ \bbmu_t^T \bbg\left(\E\left[ \frac{1}{T} \sum_{t'=t+1}^{t+T} \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) | \bbmu_t\right]\right)
% \end{align}
% Combining~\eqref{eq:dual_mut} and~\eqref{eq:dual_larger_primal}, we have
% \begin{align}
% & \E\left[\mathcal{U}\left( \frac{1}{T^2} \sum_{t=1}^T\sum_{t'=1}^T \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right)\right] \nonumber\\
% &\geq \frac{1}{T} \sum_{t=1}^T \E\left[\mathcal{U}\left( \frac{1}{T} \sum_{t'=1}^T \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right)\right] \nonumber\\
% &\geq P^{\star} - \frac{1}{T} \sum_{t=1}^T \E\left[\bbmu_t^T \bbg\left( \frac{1}{T} \sum_{t'=1}^T \bbf(\bbH_{t'}, \bbp(\bbH_{t'};\bbtheta_t)) \right)\right].
% \end{align}
% % \begin{align}
% % &\frac{1}{T} \sum_{t=1}^T \E\left[\mathcal{U}\left(  \bbf(\bbH_t, \bbp(\bbH_t, \bbmu_t;\bbtheta)) \right)\right] \nonumber\\
% % &\geq P^{\star} - \frac{1}{T} \sum_{t=1}^T \E\left[\bbmu_t^T \bbg\left( \bbf(\bbH_t, \bbp(\bbH_t, \bbmu_t;\bbtheta)) \right)\right].
% % \end{align}
% % Letting $T\to\infty$, we will have
% % \begin{align}
% % &\liminf_{T\to\infty}\frac{1}{T} \sum_{t=1}^T \E\left[\mathcal{U}\left(  \bbf(\bbH_t, \bbp(\bbH_t, \bbmu_t;\bbtheta)) \right)\right] \nonumber \\
% % &\geq P^{\star} - \limsup_{T\to\infty}\frac{1}{T} \sum_{t=1}^T \E\left[\bbmu_t^T \bbg\left( \bbf(\bbH_t, \bbp(\bbH_t, \bbmu_t;\bbtheta)) \right)\right] \nonumber \\
% % &\geq P^{\star} - \frac{c\eta_{\bbmu}G^2}{2},\label{eq:almost_final_optimality}
% % \end{align}
% % where the last inequality results from~\eqref{eq:inner_prod_dual_limsup}. Combining~\eqref{eq:almost_final_optimality} with the fact that $\mathcal{U}(\cdot)$ is concave, we can write
% % \begin{align}
% % &\liminf_{T\to\infty} \E\left[ \mathcal{U}\left( \frac{1}{T} \sum_{t=1}^T \bbf(\bbH_t, \bbp(\bbH_t, \bbmu_t;\bbtheta)) \right)\right] \nonumber \\
% % &\geq \liminf_{T\to\infty} \E\left[ \frac{1}{T} \sum_{t=1}^T \mathcal{U}\left(  \bbf(\bbH_t, \bbp(\bbH_t, \bbmu_t;\bbtheta)) \right)\right] \nonumber \\
% % &= \liminf_{T\to\infty}\frac{1}{T} \sum_{t=1}^T \E\left[\mathcal{U}\left(  \bbf(\bbH_t, \bbp(\bbH_t, \bbmu_t;\bbtheta)) \right)\right] \nonumber \\
% % &\geq P^{\star} - \frac{c\eta_{\bbmu}G^2}{2},\label{eq:final_optimality}
% % \end{align}
% This completes the proof, due to the assumption that the limit on the left-hand side of~\eqref{eq:final_optimality} exists.
%

% \pagebreak

% \balance



\section{Convex Hull Relaxation}\label{appx:convex_hull}
Theorem~\ref{thm:main}---as well as Theorem 1 of~\cite{calvo2021state}---demonstrate the convergence of the time average of the primal-dual iterates. This can indeed be shown for any non-convex optimization problem, and it comes from the fact that the primal-dual iterates operate on a \emph{convex hull} relaxation. More precisely, consider the following generic optimization problem:
\begin{subequations}\label{eq:generic_opt}
\begin{alignat}{2}
    &\max_{x} &~& f_0(x),           \\
    &~~~\text{s.t.} &&  f(x) \geq 0,%
\end{alignat}
\end{subequations}
with the Lagrangian $\ccalL(x,\mu) = f_0(x) + \mu f(x)$ for $\mu \in \reals_+$ and the Lagrangian maximizer
\begin{align}\label{eq:L_max_orig}
x^{\star}(\mu) = \arg \max_x \ccalL(x,\mu).
\end{align}
Now, consider a generalized version of~\eqref{eq:generic_opt}, in which the optimization over $x$ is replaced by an optimization over a \emph{measure} $m(x)$, i.e.,
\begin{subequations}\label{eq:generic_opt_measure}
\begin{alignat}{2}
    &\max_{m(x)} &~& \int f_0(x) \, dm(x),           \\
    &~~~\text{s.t.} &&  \int f(x) \, dm(x) \geq 0.%
\end{alignat}
\end{subequations}
The Lagrangian corresponding to~\eqref{eq:generic_opt_measure} is then given by $\ccalL(m(x),\mu) = \int \left(f_0(x) + \mu f(x) \right)  \, dm(x)$ for $\mu \in \reals_+$, with the Lagrangian maximizer
\begin{align}\label{eq:L_max_measure}
m^{\star}(x|\mu) = \arg \max_{m(x)} \ccalL(m(x),\mu).
\end{align}
The Lagrangian maximizing measure in~\eqref{eq:L_max_measure} may not be unique. However, it can be shown that the Lagrangian maximizer in~\eqref{eq:L_max_orig} also corresponds to a Lagrangian maximizing measure in~\eqref{eq:L_max_measure}, or conversely, the set of Lagrangian maximizing measures in~\eqref{eq:L_max_measure} contains a measure that corresponds to the solution of~\eqref{eq:L_max_orig}.


\section{Proof of Theorem~\ref{thm:near_universality_result}}\label{appx:proof_state_augmented}

The proof of feasibility in~\eqref{eq:thm_feasibility_state_augmented} follows similar steps to those in Appendix~\ref{appx:proof_feasibility} and we, therefore, omit it for brevity. As for the near-optimality result in~\eqref{eq:thm_optimality_state_augmented}, we have %we show that the objectives resulting from the state-augmented procedure and  first consider the following lemma.

\begin{align}
&\lim_{T\to\infty} \Bigg| \E \Bigg[ \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf\left(\bbH_t, \bbp\left(\bbH_t, \bbmu_{\lfloor t/T_0 \rfloor}; \bbphi^{\star}\right) \right) \right) \nonumber \\
&\quad\qquad\qquad - \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t ;\bbtheta_{\lfloor t / T_0 \rfloor})) \right) \Bigg] \Bigg| \\
&\leq \lim_{T\to\infty} \E \ \Bigg| \ \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf\left(\bbH_t, \bbp\left(\bbH_t, \bbmu_{\lfloor t/T_0 \rfloor}; \bbphi^{\star}\right) \right) \right) \nonumber \\
&\quad\qquad\qquad - \mathcal{U}\left( \frac{1}{T} \sum_{t=0}^{T-1} \bbf(\bbH_t, \bbp(\bbH_t ;\bbtheta_{\lfloor t / T_0 \rfloor})) \right) \Bigg| \label{eq:convexity_abs} \\
&\leq \lim_{T\to\infty} \E \ \Bigg\| \ \frac{1}{T} \sum_{t=0}^{T-1} \bigg( \bbf\left(\bbH_t, \bbp\left(\bbH_t, \bbmu_{\lfloor t/T_0 \rfloor}; \bbphi^{\star}\right) \right)  \nonumber \\
&\qquad\qquad\qquad\qquad\quad -  \bbf\left(\bbH_t, \bbp(\bbH_t ;\bbtheta_{\lfloor t / T_0 \rfloor})\right) \bigg) \Bigg\|_{\infty} \label{eq:Lipschitz_U} \\
&\leq  \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1} \E \ \Bigg\| \   \bbf\left(\bbH_t, \bbp\left(\bbH_t, \bbmu_{\lfloor t/T_0 \rfloor}; \bbphi^{\star}\right) \right)  \nonumber \\
&\qquad\qquad\qquad\qquad\quad ~ -  \bbf\left(\bbH_t, \bbp(\bbH_t ;\bbtheta_{\lfloor t / T_0 \rfloor})\right) \Bigg\|_{\infty} \label{eq:convexity_infnorm} \\
&\leq M \lim_{T\to\infty} \frac{1}{T} \sum_{t=0}^{T-1} \E \ \Bigg\| \   \bbp\left(\bbH_t, \bbmu_{\lfloor t/T_0 \rfloor}; \bbphi^{\star}\right)  \nonumber \\
&\qquad\qquad\qquad\qquad\qquad\qquad\quad -  \bbp(\bbH_t ;\bbtheta_{\lfloor t / T_0 \rfloor})  \Bigg\|_{\infty} \label{eq:Lipschitz_f} \\
&\leq M \E \left\| \bbp\left(\bbH, \bbmu; \bbphi^{\star}\right) - \bbp(\bbH ;\bbtheta(\bbmu))  \right\|_{\infty} \label{eq:exp_mu} \\
&\leq M \epsilon,\label{eq:universality_proofbound}
\end{align}
where~\eqref{eq:convexity_abs} results from the convexity of the absolute value function,~\eqref{eq:Lipschitz_U} comes from the Lipschitz continuity of the utility $\mathcal{U}$,~\eqref{eq:convexity_infnorm} results from the convexity of the $\ell_{\infty}$ norm,~\eqref{eq:Lipschitz_f} holds because of the the Lipschitz continuity of the performance function $\bbf$,~\eqref{eq:exp_mu} holds since $\{\bbmu_k\}_{k=1}^K$ are assumed to come from the distribution $p_{\bbmu}$, and~\eqref{eq:universality_proofbound} is true due to the near-universality of the parameterization. This, combined with~\eqref{eq:thm_optimality} from Theorem~\ref{thm:main}, completes the proof.
\hfill$\square$%