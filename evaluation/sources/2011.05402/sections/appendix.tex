\appendix
\section{Appendix}
\label{sec:appendix}
\subsection{Implementation Details}

\noindent
The hyperparameters used are:
\begin{itemize}[itemsep=0pt]
    \item Character embedding size = 128
    \item Number of LSTM layers = 1
    \item Hidden state size of the LSTM = 256
    \item Attention size = 256
    \item Beam size = 4
    \item For the diagonal loss, $j$ = 3
    \item Minibatch size for training = 1
    \item Maximum number of epochs = 150
    \item Patience for early stopping = 10 epochs
    \item Pretraining epochs for encoder/decoder = 10
    \item Pretraining epochs for seq-to-seq model = 5
\end{itemize}

\noindent
We use the same values of the hyperparameters for each language and all the systems. We select the best model with early stopping on the character error rate of the validation set.


\subsection{Additional Experimental Results}

\begin{table}[b]
    \centering
    \begin{tabular}{@{}lrr@{}}
    \toprule
    Model & CER & WER \\
    \midrule
    \textsc{Fp-Ocr} & $8.90$ & $31.64$ \\
    \textsc{Base} & $70.89$ & $100.00$ \\
    \textsc{Copy} & $11.60$ & $26.74$ \\
    \textsc{Ours} & $7.95$ & $20.83$ \\
    \bottomrule
    \end{tabular}
    \caption{Character error rate (CER) and word error rate (WER) for the Yakkha dataset with the multisource model that uses the OCR on Nepali as the high-resource translation. The table shows the mean over five random runs.}
    \label{tab:nepali}
    \vspace{2em}
\end{table}


\paragraph{Performance on Yakkha with Nepali}\autoref{tab:nepali} shows the performance for the Yakkha dataset when using Nepali as the high-resource translation input to the multisource model. The performance is similar to those of the experiments using the English translations, as presented in \autoref{tab:cer}.

\paragraph{Standard deviation on the main results}\autoref{tab:stddev_cer} and \autoref{tab:stddev_wer} show the character error rate and word error rate respectively including the standard deviation over five randomly seeded runs, corresponding to the systems described in \autoref{tab:cer}. 

\begin{table}[tb]
    \centering
    \small
    (a) Ainu\\
    \begin{tabular}{l|r@{\ \ \ }r}
    \toprule
        Model & \multicolumn{1}{c}{Multi} & \multicolumn{1}{c}{Single} \\
        \midrule
        \textsc{Fp-Ocr} & \multicolumn{1}{c}{--} & $1.34$ \\
        \textsc{Base} & $1.56 \pm 0.23$ & $1.41 \pm 0.16$ \\
        \textsc{Copy} & $2.04 \pm 0.62$ & $1.99 \pm 0.41$ \\
        \textsc{Ours} & $0.92 \pm 0.05$ & $\boldsymbol{0.80} \pm 0.07$ \\
    \bottomrule
    \end{tabular}\\
    \vspace{1em}
    (b) Griko\\
    \begin{tabular}{l|r@{\ \ \ }r}
    \toprule
        Model & \multicolumn{1}{c}{Multi} & \multicolumn{1}{c}{Single} \\
        \midrule
        \textsc{Fp-Ocr} & \multicolumn{1}{c}{--} & $3.27$ \\
        \textsc{Base} & $6.78 \pm 0.62$ & $5.95 \pm 0.52$ \\
        \textsc{Copy} & $2.54 \pm 0.31$ & $2.28 \pm 0.28$ \\
        \textsc{Ours} & $\boldsymbol{1.66} \pm 0.03$ & $1.70 \pm 0.21$ \\
    \bottomrule
    \end{tabular}\\
    \vspace{1em}
    (c) Yakkha\\
    \begin{tabular}{l|r@{\ \ \ }r}
    \toprule
        Model & \multicolumn{1}{c}{Multi} & \multicolumn{1}{c}{Single} \\
        \midrule
        \textsc{Fp-Ocr} & \multicolumn{1}{c}{--} & $8.90$ \\
        \textsc{Base} & $70.39 \pm 0.49$ & $71.71 \pm 0.71$  \\
        \textsc{Copy} & $14.77 \pm 0.97$ & $12.30 \pm 2.39$ \\
        \textsc{Ours} & $\boldsymbol{7.75} \pm 0.46$ & $8.44 \pm 0.90$ \\
    \bottomrule
    \end{tabular}
    \caption{Mean and standard deviation of the character error rate with 10-fold cross-validation over five random seeds. The results presented are the same as \autoref{tab:cer} with the added information of standard deviation. The best models for each language are \textbf{highlighted}.}
    \label{tab:stddev_cer}
\end{table}

\begin{table}[tb]
    \centering
    \small
    (a) Ainu\\
    \begin{tabular}{l|r@{\ \ \ }r}
    \toprule
        Model & \multicolumn{1}{c}{Multi} & \multicolumn{1}{c}{Single} \\
        \midrule
        \textsc{Fp-Ocr} & \multicolumn{1}{c}{--} & $6.27$ \\
        \textsc{Base} & $8.56 \pm 1.01$ & $7.88 \pm 0.64$   \\
        \textsc{Copy} & $9.48 \pm 3.07$ & $8.57 \pm 1.45$ \\
        \textsc{Ours} & $5.75 \pm 0.24$ & $\boldsymbol{5.19} \pm 0.31$ \\
    \bottomrule
    \end{tabular}\\
    \vspace{1em}
    (b) Griko\\
    \begin{tabular}{l|r@{\ \ \ }r}
    \toprule
        Model & \multicolumn{1}{c}{Multi} & \multicolumn{1}{c}{Single} \\
        \midrule
        \textsc{Fp-Ocr} & \multicolumn{1}{c}{--} & $15.63$ \\
        \textsc{Base} & $15.13 \pm 0.99$ & $13.67 \pm 1.17$ \\
        \textsc{Copy} & $9.33 \pm 0.49$ & $8.90 \pm 0.51$ \\
        \textsc{Ours} & $\boldsymbol{7.46} \pm 0.09$ & $7.51 \pm 0.31$ \\
    \bottomrule
    \end{tabular}\\
    \vspace{1em}
    (c) Yakkha\\
    \begin{tabular}{l|r@{\ \ \ }r}
    \toprule
        Model & \multicolumn{1}{c}{Multi} & \multicolumn{1}{c}{Single} \\
        \midrule
        \textsc{Fp-Ocr} & \multicolumn{1}{c}{--} & $31.64$ \\
        \textsc{Base} & $98.15 \pm 1.55$ & $99.10 \pm 2.20$  \\
        \textsc{Copy} & $30.36 \pm 1.39$ & $27.81 \pm 1.65$ \\
        \textsc{Ours} & $\boldsymbol{20.95} \pm 1.04$ & $21.33 \pm 0.53$ \\
    \bottomrule
    \end{tabular}
    \caption{Mean and standard deviation of the word error rate with 10-fold cross-validation over five random seeds. The results presented are the same as \autoref{tab:cer} with the added information of standard deviation. The best models for each language are \textbf{highlighted}.}
    \label{tab:stddev_wer}
    \vspace{1em}
\end{table}
