
\title{An Introduction to Software Ecosystems}
% Use \titlerunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\author{Tom Mens \and Coen De Roover}
% Use \authorrunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\institute{Tom Mens \at University of Mons, Place du Parc 20, 7000 Mons, Belgium, \email{tom.mens@umons.ac.be}
    \and Coen De Roover  \at Vrije Universiteit Brussel, Pleinlaan 2, 1050 Etterbeek, Belgium, \email{Coen.De.Roover@vub.be}}
%
% Use the package "url.sty" to avoid
% problems with special characters
% used in your e-mail or web address
%
\maketitle
\label{INT:ch}

%Each chapter should be preceded by an abstract (no more than 200 words) that summarizes the content. The abstract will appear \textit{online} at \url{www.SpringerLink.com} and be available with unrestricted access. This allows unregistered users to read the abstract as a teaser for the complete chapter.
%Please use the 'starred' version of the \texttt{abstract} command for typesetting the text of the online abstracts (cf. source file of this chapter template \texttt{abstract}) and include them with the source files of your manuscript. Use the plain \texttt{abstract} command if the abstract is also to appear in the printed version of the book.}

\abstract*{This chapter defines and presents the kinds of software ecosystems that are targeted in this book.
    The focus is on the development, tooling and analytics aspects of ``software ecosystems'', i.e., communities of software developers and the interconnected software components (e.g., projects, libraries, packages, repositories, plug-ins, apps) they are developing and maintaining.
    The technical and social dependencies between these developers and software components form a socio-technical dependency network, and the dynamics of this network change over time.
    We classify and provide several examples of such ecosystems, many of which will be explored in further detail in the subsequent chapters of the book.
    The chapter also introduces and clarifies the relevant terms needed to understand and analyse these ecosystems, as well as the techniques and research methods that can be used to analyse different aspects of these ecosystems.}

\abstract{This chapter defines and presents the kinds of software ecosystems that are targeted in this book.
    The focus is on the development, tooling and analytics aspects of ``software ecosystems'', i.e., communities of software developers and the interconnected software components (e.g., projects, libraries, packages, repositories, plug-ins, apps) they are developing and maintaining.
    The technical and social dependencies between these developers and software components form a socio-technical dependency network, and the dynamics of this network change over time.
    We classify and provide several examples of such ecosystems, many of which will be explored in further detail in the subsequent chapters of the book.
    The chapter also introduces and clarifies the relevant terms needed to understand and analyse these ecosystems, as well as the techniques and research methods that can be used to analyse different aspects of these ecosystems.}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\input{book/chapter-introduction/definition.tex}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Sources for Mining Software Ecosystems}

The Mining Software Repositories (MSR) research community relies on a wide variety of publicly accessible raw data, APIs or other data extraction tools, data dumps, curated datasets, and data processing tools  (\eg dedicated parsers) depending on the specific purpose and needs of the research being conducted.

\smallskip \textbf{The pros.}
These data sources and their associated tooling form a gold mine for empirical research in software engineering, since they have enabled the MSR field to thrive. 
Relying on existing publicly accessible data substantially reduces the laborious and error-prone effort of the data extraction and data processing phase of empirical research.
As such, it has has allowed researchers and software practitioners to learn a great deal about software engineering practices in the field, and how to improve such practices.
Moreover, this allows multiple researchers to rely on the same data, facilitating comparison and reproducibility of research results~\cite{Gonzalez-Barahona2012}.

\smallskip \textbf{The cons.}
At the same time, these data sources and tools also come with a range of negative consequences such as:
\begin{itemize}
\item Existing datasets and extraction tools can quickly become obsolete, as it is difficult and effort-intensive to keep up with changes in the original data source or in the APIs required to access them. Many initiatives to create and maintain data extraction tools or curated datasets have been discontinued, mainly due to a lack of continued  funding or because the original maintainers have abandoned the initiative due to career changes.
\item Ethical, legal, or privacy reasons may prevent specific parts of the data of interest to be made available. Examples are proprietary copyrighted source code, or personal information that cannot be revealed due by GDPR regulations.
\item Existing datasets may be biased, or not appropriate for specific analyses, because of how the data has been gathered or filtered. 
%For example, a dataset containing only repositories with at least 100 stars, implying that it cannot be used to provide insights in less starred repos. Or a dataset of repos for a specific programming language. A a dataset of accounts that does not disintinguish between human and bot accounts. Or a dataset that does not take into account identity merging.
\item Specific analyses may need specific types of data that are not readily available in existing datasets,  requiring the creation of new datasets. Talking from a personal experience, it often takes several months of effort to obtain, preprocess, validate, curate and improve the quality of the obtained data. Not doing so may lead to results that are inaccurate, biased, not replicable, or not generalisable to other situations.
\item Research that is not relying on curated datasets, but rather on the raw data sources may reduce reproducibility since, unlike for a published dataset, there is no guarantee that the original data will remain the same after publication of the research results. For example, \github repositories may be deleted and the history of a git repository may be changed at any time~\cite{Bird2009,Kalliamvakou2014}.
\end{itemize}

%\tom{List of datasets that have been made available for use in past and current research on analysing software  ecosystems. There are many such datasets (most being obsolete by now), so it is virtually impossible to be complete.}
%\tom{@Coen: suggest to summarise these datasets in the form of a table? (Columns: name of dataset; citation of dataset; contents of dataset; period/duration of data dumps) Perhaps this is not possible since too diverse and too many datasets.}

The following subsections provide a list of data sources that have been used in empirical research on a wide variety of software ecosystems.
This list is non-exhaustive, given the plethora of established and newly-emerging ecosystems, data sources about them, and research studies on them.

\subsection{Mining the \github Ecosystem}

For git repositories hosted on the \github social coding platform, different ways have been proposed to source their data.
\github provides public REST and GraphQL APIs to interact with its huge dataset of events and interaction with the hosted repositories.
As an alternative, different attempts have been made to provide datasets and data dumps containing relevant data extracted from \github, with varying success:
\begin{itemize}
    \item \emph{GHArchive}\footnote{\url{https://www.gharchive.org}} records, archives and makes available the public \github timeline for public consumption and analysis. It contains datasets, aggregated into hourly archives, based on 20+ event types, ranging from new commits and fork events, to opening new tickets, commenting, and adding members to a project.
    \item In a similar way, \emph{GHTorrent} aimed to obtain data from \github public repositories \cite{GHTorrent,Gousios2017}, covering a large part of the activity from 2012 till 2019.
          The latest available data dump was created in March 2021,\footnote{\url{http://ghtorrent-downloads.ewi.tudelft.nl/mysql/}} and no newer data dumps are available.
    \item \emph{TravisTorrent} was a dataset created in 2017 based on Travis CI and GitHub, It provides access to over 2.6 million Travis builds from more than 1,000 GitHub projects \cite{Beller2017-MSR}.
\end{itemize}

\subsection{Mining the Java Ecosystem}

The Java ecosystem  has lead to multiple datasets being produced and used in research.
Qualitas Corpus~\cite{Tempero2010QualitasCorpus}, a curated dataset of Java software systems, aimed for reproducible studies of Java software. Only two datadumps have been released, in 2010 and in 2013.

More recent datasets for Java focused on Apache's Maven Central Repository, a software package registry containing a huge collection of software libraries, For example, Raemaekers \etal provided the Maven Dependency Dataset containing metrics, changes and a dependency graph of 148,253 jar files  \cite{Raemaekers2013}. They used this dataset to study the phenomena of semantic versioning and breaking changes in \cite{raemaekers2014semantic}.
Mitropoulos \etal \cite{Mitropoulos2014} provided a complementary dataset containing the metrics of potential software bugs for every project version included in the Maven Central Repository.

More recently, Benelallam \etal \cite{Benelallam2019} created the Maven Dependency Graph, an open source data set containing a snapshot of the whole Maven Central Repository taken on September 2018, stored in a graph database modelling all dependencies. This dataset was consequently used for various purposes, such as the study of software diversity.

\subsection{Mining Software Library Ecosystems}

Beyond the Maven software library ecosystem for Java, many other software library ecosystems have been studied for a wide range of programming languages. For the purpose of analysing the package dependency networks of these ecosystems, \emph{Libraries.io} \cite{librariesio2020} has been used by several researchers (\eg \cite{zerouali2018empirical,decan:emse:2019}). Five successive data dumps have been made available from 2017 to 2020, containing metadata from a wide range of different package managers. No more recent data dumps have been released since Tidelift decided to discontinue active maintenance of the dataset.

As a kind of successor of Libraries.io, the \emph{Ecosyste.ms} project\footnote{\url{https://ecosyste.ms}} was started in 2022. Currently sponsored by the Open Collective\footnote{\url{https://opencollective.com}}, it focuses on expanding available data and APIs, as such providing a foundational basis for researchers to better analyze open source software, and for funders to better prioritize which projects need to be funded most.
The \emph{Ecosyste.ms} platform provides a shared collection of openly accessible services to support, sustain, and secure critical open source software components.
Each service comes with an openly accessible JSON API to facilitate the creation of new tools and services. The APIs and data structures are designed to be as generic as possible, to allow analysing different data sources in an ecosystem-agnostic way.
Some of the supported services include:
\begin{itemize}
    \item An index of several millions of open source packages from dozens of package registries (for programming languages and Linux distributions), with tens of thousands new package versions being added on a daily basis.
    \item An index of the historical timeline of several billions of events that occurred across public git repositories (hosted on \github, \gitlab or \gitea) over many years, with hundreds of thousands of events being added on an hourly basis.
    \item An index of dozens of millions of open source repositories and \docker projects and their dependencies originating from a dozen of different hosts, with tends of thousands new repositories being added on a daily basis.
    \item A range of services to provide software repository, contributor and security vulnerability metadata, parse software dependency and licensing metadata, resolve software package dependency trees, generate diffs between package releases, and many more.
\end{itemize}



\subsection{Mining other Software Ecosystems}

Beyond the data sources mentioned above, a wide variety of other initiative to mine, analyse or archive software ecosystems have been proposed through a plethora of datasets or data sources that are (or have been) available for researchers or practitioners:

\begin{itemize}
    \item Of particular relevance is the \emph{Software Heritage} ecosystem~\cite{swhipres2017}.  It is the largest public software archive,
          containing the development history of billions of source code files from more than 180 million collaborative software development projects.
          Supported by a partnership with UNESCO, its long-term mission is to collect, preserve, and make easily accessible the source code of publicly available software. It comes with its own filesystem~\cite{swh-fuse-icse2021} and graph dataset~\cite{msr-2020-challenge}. For more details we refer to \chap{SWH} that is entirely focused on this ecosystem.

    \item \emph{World of Code} (WoC) \cite{mockus2019woc, Ma2021WoC} is another ambitious initiative to create a very large and frequently updated collection of historical data in OSS ecosystems. The provided infrastructure facilitates the analysis of technical dependencies, social networks and their interrelationships, by providing tools to efficiently correct, augment, query, and analyze that data. As such, it provides the basis to understand the structure and evolution of the relationships that drive OSS activities.

    \item \emph{Boa}~\cite{dyer2013boa,dyer2015boa,Boa2020MSR} is yet another initiative to support the efficient mining of large-scale datasets of software repository data. Boa provides a domain-specific language and infrastructure to facilitate this, by leveraging distributed computing techniques.

    \item \tom{@Coen: list of datasets to be further processed from here. I don't know if we need a separate bullet for each, and I am very likely to have missed some other relevant ones. On the other hand, we cannot list everyhing.}
    \item In the past, a series of similar attempts have been made to create and support publicly available software datasets and platforms, but these are no longer actively maintained today. We mention some notable examples below.
          %
          The PROMISE Software Engineering Repository is a collection of publicly available datasets to serve researchers in conducting predictive software engineering  in a  repeatable, verifiable and refutable way~\cite{PROMISE2005}. %\tom{(2004-2006)Probably not that interesting since no longer maintained since 2006...}
          %
          FLOSSmole is another collaborative collection of OSS project data~\cite{FLOSSmole}. %\tom{No longer maintained since 2017 so probably not relevant to mention either?}
          %
          Candoia is a platform and ecosystem for building and sharing software repository mining tools and applications~\cite{Candoia2016, 7962355}. %\tom{No longer maintained since 2017 so perhaps not relevant to mention either?}
          %
          Sourcerer was a research project aimed at exploring open source projects through by providing an open source Infrastructure and curated datasets for other researchers to use~\cite{Sourcerer2014}.

    \item Jira is one of the most popular issue tracking systems (ITSs) in practice. A first Jira repository dataset was created in 2015, containing more than 700K issue reports and more than 2 million issue comments extracted from the Jira issue tracking system of the Apache Software Foundation, Spring, JBoss and CodeHaus OSS communities \cite{Ortu2015}.
    A more recent dataset created in 2022 collected data from 16 pubic Jira repositories containing 1822 projects and spanning 2.7 million issues with a combined total of 32 million changes, 9 million comments, and 1 million issue links \cite{Montgomery2022Jira,montgomery2022alternative}.
  
    \item DebSources: open source source code and related metadata for the Debian Linux distribution.  \cite{debsources-ese-2016}
          \tom{and UDD? https://wiki.debian.org/UltimateDebianDatabase}
%TOM: REMOVED FOLLOWING DATASETS FROM HERE SINCE WE CANNOT REFER TO EVERYTHING... TOO MANY DATASETS IN THIS WORLD
 %   \item A dataset of software development bots \cite{Bodegha2021}
 %   \item A dataset of open source license texts \cite{msr-2022-foss-licenses}
  %  \item Andromeda: A dataset of Ansible Galaxy roles and their evolution \cite{2021:msr:opdebeeck}

%TOM: Removed next item from this list, since moved in the section about communication-oriented ecosystems
%    \item The official \stackoverflow data dump, and an open dataset SOTorrent built on top of it in 2022 \cite{Baltes2018,Baltes2019,baltes2021zenodo}.
          
\end{itemize}


\subsection{Mining Software Vulnerabilities in Ecosystems}

%\tom{Talk about the importance of detecting/mitigating/resolving vulnerabilities in software ecosystems, because of the important impact they may cause (due to transitive dependencies) and because of the large potential attack surface especially in OSS (millions of available software components.}

A key concern in software ecosystems, regardless of the kind of ecosystem being considered, is their vulnerability to security issues that can be exploited by hackers to gain access to sensitive information or disrupt operations.
One the reasons for this is their scale. Any software ecosystem is composed of a large collection of software components, and each of these components could potentially be vulnerable. In addition to this, if these components are heavily interdependent, as is the case for many software ecosystems, vulnerabilities may propagate to other software components, further increasing the attack surface.
In the case of OSS ecosystems, their open nature could be considered as a positive aspect, since it helps to identify and fix security vulnerabilities quickly, and to build trust among users and developers. Indeed, a large number of people have the potential to review the code and identify potential security issues, making the software more secure.
However, OSS are also often volunteer-based, increasing the risk that some software components are no longer actively maintained, increasing their risk of suffering from vulnerabilities that will not be fixed or not even be detected.
Because of this, there is a need for advanced and automated security analysis tools and services, as well as up-to-date vulnerability datasets, to automate the process of identifying and fixing security vulnerabilities. Such tools should be seamlessly integrated into the typical tools and practices being used by their respective ecosystem communities.

Without aiming to be complete, we present some vulnerability analysis tools and datasets below, and we provide some pointers to empirical analysis that have been carried out using them to study vulnerabilities in software ecosystems.

\tom{present below vulnerability datasets and tools + add refs having used them}\tom{@Coen feel free to iterate over this and structure this!}


\begin{itemize}
    \item Snyk\footnote{\url{https://snyk.io}}

    \item The NIST National Vulnerability Database (NVD)\footnote{\url{https://nvd.nist.gov}}. Bhandari \etal \cite{Bhandari2021PROMISE} used the NVD database to analyze 1754 open-source projects and extracted fixing commits at different levels, with the aim of fixing vulnerabilities using machine learning models .

    \item Google Open Source Insights (OSI)\footnote{\url{https://deps.dev}} including a BigQuery public dataset

    \item GitHub's dependabot service

    \item {VulinOSS}~\cite{Gkortzis2018MSR} is a dataset of 153 OSS projects including  17K+ security vulnerabilities and  associated software metrics, and metadata \tom{(to be double checked and completed)}
          %ABSTRACT: Examining the different characteristics of open-source software in relation to security vulnerabilities, can provide the research community with findings that can lead to the development of more secure systems. We present a dataset where the reported vulnerabilities of 8694 open-source project versions, can be correlated with the corresponding source code and a number of software metrics. The metrics were obtained by analyzing the project's source code via well-established tools. Apart from commonly used metrics (e.g. loc), we also provide data related to modern development trends such as continuous integration and testing. We outline motivational examples based on the dataset we describe.

    \item {CrossVul}: A Cross-Language Vulnerability Dataset with Commit Data \cite{Nikitopoulos2021CrossVul}
          %ABSTRACT: Examining the characteristics of software vulnerabilities and the code that contains them can lead to the development of more secure software. We present a dataset (∼1.4 GB) containing vulnerable source code files together with the corresponding, patched versions. Contrary to other existing vulnerability datasets, ours includes vulnerable files written in more than 40 programming languages. Each file is associated to (1) a Common Vulnerability Exposures identifier (CVE ID) and (2) the repository it came from. Further, our dataset can be the basis for machine learning applications that identify defects, as we show in specific examples. We also present a supporting dataset that contains commit messages derived from Git commits that serve as security patches. This dataset can be used to train ML models that in turn, can be used to detect security patch commits as we highlight in a specific use case.

    \item Aladics \etal \cite{Aladics2022} created a Java-based vulnerability dataset using the SZZ algorithm, which includes CVE-IDs, repository information, and the fixing and highest-rated vulnerability-introducing commits

    \item {SecureQualitas}: A Security Corpus of Real {Java} Applications \cite{Benabidallah2019SecureQualitas}

    \item A {C/C++} Code Vulnerability Dataset with Code Changes and {CVE} Summaries \cite{Fan2020MSR}
\end{itemize}
EMPIRICAL STUDIES:
\begin{itemize}
    \item \cite{combe2016docker, zerouali2019impact, Zerouali2019Docker,shu2017study} studied vulnerability analysis for Docker.

    \item \cite{decan2018impact,Zapata:ICSME2018,Chinthanet:ASE2020,zimmermann2019small} studied vulnerable dependency migration in the npm ecosystem. \cite{zerouali2022impact} studied security vulnerabilities in npm and RubyGems.

    \item \cite{Alfadel2021} studied security vulnerabilities in the Python ecosystem.

    \item \cite{2019:icse:rahman,2021:tsem:rahman} studied security smells in IaC.
\end{itemize}

others: \cite{Ponta2018}
\cite{Hanif2021}
%Abstract:The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform malicious activities and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective vulnerability detection systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and data mining approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending machine learning approaches, such as supervised learning and deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests’ taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning, ensemble learning and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as buffer overflow, SQL injection and cross-site scripting effectively with a significant detection performance, up to 95% of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications.

\cite{Lomio2022}
%Abstract:
%Software vulnerabilities are weaknesses in source code that might be exploited to cause harm or loss. Previous work has proposed a number of automated machine learning approaches to detect them. Most of these techniques work at release-level, meaning that they aim at predicting the files that will potentially be vulnerable in a future release. Yet, researchers have shown that a commit-level identification of source code issues might better fit the developer’s needs, speeding up their resolution.
%To investigate how currently available machine learning-based vulnerability detection mechanisms can support developers in the detection of vulnerabilities at commit-level.
%We perform an empirical study where we consider nine projects accounting for 8991 commits and experiment with eight machine learners built using process, product, and textual metrics.
%We point out three main findings: (1) basic machine learners rarely perform well; (2) the use of ensemble machine learning algorithms based on boosting can substantially improve the performance; and (3) the combination of more metrics does not necessarily improve the classification capabilities.
%Further research should focus on just-in-time vulnerability detection, especially with respect to the introduction of smart approaches for feature selection and training strategies.

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\section{The CHAOSS Project}
\label{INT:sec:chaoss}
\tom{Probably this does not deserve a full section on its own. To be integrated as part of some other section.}

In an introductory chapter on software ecosystems it is indispensable to also mention the CHAOSS initiative (which is an acronym for Community Health Analytics in Open Source Software)~\cite{Goggins2021CHAOSS}.\footnote{\url{https://chaoss.community}}
It is a Linux Foundation project aimed at better understanding OSS community health on a global scale~\cite{Goggins2021}.
Unhealthy OSS projects can have a negative impact on the community involved in them, as well as on organisations that are relying on them.
CHAOSS therefore focuses on understanding and supporting health through the creation of metrics, metrics models, and software development analytics tools for measuring and visualising OSS community health.

Two main OSS tools are proposed by CHAOSS to do so.
%
The first one is \emph{GrimoireLab}~\cite{GrimoireLab2021}, an open source toolkit with support for extracting, visualising and analysing activity, community and process data from 30+ data sources related to code management, issues, code reviewing, mailing list, developer fora and more.
%
The second tool supported by CHAOSS is \emph{Augur}~\cite{}\tom{TO BE CONTINUED}





%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\section{Ecosystem Tooling and Analytics}
\label{INT:sec:analytics}
\coen{TO DO (assigned to COEN)}

{\color{red}
    %General Introduction about what the book's theme.\tom{Does not seem necessary since this is writen in the preface of the book...}

    Why is it useful / important / relevant / ... to study software ecosystems?

    Which analytics-driven questions are answered in this book?

    %TOM: I think we already have given the explanation below in some form in the beginning of this chapter.
    %Explain what are some of the distinguishing features of software ecosystems research, as compared to "regular" software engineering research? The focus is more on the macro-level view~\cite{gonzalez2009macro}, studying huge numbers of often interconnected software systems (projects / repositories / components / libraries), as opposed to the micro-level analysis of a limited number of software systems. Empirical studies on software ecosystems often encompass millions of interconnected software components, forming huge socio-technical dependency networks of different nature.

    Which tools are relevant / important / ... to support software ecosystem users, contributors, maintainers, ..?
}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

%\section{Research Methods}
%\label{INT:sec:methods}

%\coen{TO DO (assigned to COEN)}

{\color{red}
    Which techniques and tools are used for analysing software ecosystems?

    Which ecosystem-driven tools are presented in this book?
}

%Tools for data extraction? 
%Section 1.4 alrady talkes about data extraction and datasets so this is no longer needed here I think.
%\eg PyDriller \cite{Spadini2018}

%TOM: Grimoirelab and Augur should be mentioned in a separate section related to the CHAOSS project, see earlier.
%GrimoireLab~\cite{GrimoireLab2021} (and its predecessor CVSAnaly)}

\coen{call graph analysis (e.g. \cite{Hejderup2022-EMSE} for fine-grained package dependency analysis)}


%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{Data}
%\label{INT:sec:data}
%
%\tom{Most of this has been moved to the previous "Data sources" subsection.}
%
%\subsubsection*{Source code}
%
%\tom{Source code can take many different forms and can be stored/retrieved from many different places (git repositories, code excerpts on StackOverflow, workflow files, ...}
%
%\subsubsection*{Social data}
%\tom{Names and accounts of contributors to the ecosystem (people, teams, bots), their activities, their interactions and communications, messages, comments, mails, questions and answers}
%
%\subsubsection*{Technical data}
%\tom{Versioning information, release information, dependency information}
%\tom{vulnerability data}
%\tom{issue reports (e.g. stored in issue tracking systems such as JIRA) and bug reports (e.g.  stored in bug tracking systems such as BugZilla), ...}
%\tom{build logs, workflows and their runs, CI/CD data (from Travis CI, or Github Actions or any other CI/CD service)}
%\tom{licensing data}
%\tom{testing data: test files, test results, test coverage analysis reports, test runs, ...}
%\tom{quality metrics: data from static or dynamic code analysis, code smells, quality metrics, community smells, ...}
%
%\subsubsection*{Other}
%
%\tom{E.g. models, databases, metamodels, ...}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\section{Summary}

\tom{@coen, here is a first stab towards a wrap-up / summary / conclusion for this chapter?}

This introductory chapter served as a first stepping stone for newcomers in the research field of software ecosystems.
We aimed to provide the necessary material to get up to speed in this domain.
After a historical account of where software ecosystems originated from, we highlighted the different perspectives on software ecosystems, and their accompanying definitions.
We categorised the different kinds of software ecosystems, providing many examples for each category.

Since this book of which this chapter is part focuses on software ecosystem tooling and analysis, we presented a rich set of data sources and datasets that have been or can be used for mining software ecosystems. Given that the field of software ecosystems is evolving at a rapid pace, it is difficult to predict where we are heading to, and to which extent the current tools and data sources will evolve or get replaced in the future.




