\section{Conclusions}
\label{sec:conclusion}

In this work, we have successfully applied the RL framework Relexi \cite{kurz2022deep} for the development of data-driven turbulence models for implicitly filtered LES.
To this end, we have formulated the turbulence modeling task as an RL problem using LES of forced HIT as the training environment.
The LES was filtered implicitly by a modern high-order discretization based on a DG scheme to demonstrate that the RL framework can incorporate complex implicit LES filter functions into the training process by design.
The employed policy is based on a CNN architecture which relies on elementwise inputs and outputs only without the need of global flow statistics.
The agent was trained within the Relexi framework using the PPO algorithm to adapt the elementwise model parameters of Smagorinsky's model dynamically in space and time.
The underlying spectrum of turbulent kinetic energy of a high-fidelity solution was used as optimization target, which the agent should reproduce as accurate as possible.
We have demonstrated that the agent is able to learn highly accurate and long-term stable turbulence models, which clearly outperform established analytical models.
Moreover, the RL-based models are able to reproduce the target spectrum in actual simulation up to and beyond the expected resolution capabilities of the underlying discretization.
The models were shown to generalize well to other resolutions and other Reynolds numbers they were not originally trained on.
In summary, we have demonstrated that RL provides a framework for consistent, accurate and stable turbulence modeling for implicitly filtered LES.

Future work will focus on the incorporation if physical invariances into the models.
While employing the invariants of the gradient tensor as input features for the policy network incorporates Galilean invariance in a pointwise fashion, the CNN architecture is by default only invariant to shifting operations but not to rotations or reflections.
Since those invariances are not incorporated into the architecture, they have to be learned implicitly from data, which reduces the sample efficiency of the training.
Further investigations will incorporate the physical knowledge about the invariances of the underlying equations into the model architecture with specialized architectures like group convolutional layers \cite{cohen2016group}, which were already applied successfully for turbulence modeling in \cite{pawar2022frame} and in \cite{guan2023learning}, or by interpreting the input data as a graph containing only neighboring information without explicit orientation \cite{niepert2016learning,wu2020comprehensive}.
In addition, the framework will be applied to more sophisticated test cases like wall-bounded flows or shear flows.
In this context, also the use of more complex actions spaces for the agent will be investigated.

To summarize, our work here serves as a proof of concept for finding optimal LES closure models through reinforcement learning.
We do not propose to use any of the models prescribed here in practice, but our results demonstrate how to develop near optimal models with this approach, where the physical consistency and expert knowledge in model creation is fused with the currently most powerful learning algorithm for dynamical systems.
Beyond the application to LES modeling, our work here demonstrates the potential of a high-fidelity flow solver in the loop with an RL optimizer.
