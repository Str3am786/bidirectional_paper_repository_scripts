\begin{thebibliography}{58}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Adhikari et~al.(2020)Adhikari, Yuan, C{\^o}t{\'e}, Zelinka, Rondeau,
  Laroche, Poupart, Tang, Trischler, and Hamilton}]{adhikari2020gatav2}
Ashutosh Adhikari, Xingdi Yuan, Marc-Alexandre C{\^o}t{\'e}, Mikul{\'a}{\v{s}}
  Zelinka, Marc-Antoine Rondeau, Romain Laroche, Pascal Poupart, Jian Tang,
  Adam Trischler, and Will Hamilton. 2020.
\newblock Learning dynamic belief graphs to generalize on text-based games.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~33, pages 3045--3057.

\bibitem[{Adolphs and Hofmann(2020)}]{adolphs2019ledeepchef}
Leonard Adolphs and Thomas Hofmann. 2020.
\newblock Ledeepchef: Deep reinforcement learning agent for families of
  text-based games.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence (AAAI)}, volume~34, pages 7342--7349.

\bibitem[{Ammanabrolu et~al.(2019)Ammanabrolu, Broniec, Mueller, Paul, and
  Riedl}]{ammanabrolu2019quest}
Prithviraj Ammanabrolu, William Broniec, Alex Mueller, Jeremy Paul, and Mark~O
  Riedl. 2019.
\newblock \href {https://www.aclweb.org/anthology/2019.ccnlg-1.1} {Toward
  automated quest generation in text-adventure games}.
\newblock In \emph{Proceedings of the 4th Workshop on Computational Creativity
  in Language Generation}, pages 1--12.

\bibitem[{Ammanabrolu and Hausknecht(2020)}]{ammanabrolu2019kga2c}
Prithviraj Ammanabrolu and Matthew Hausknecht. 2020.
\newblock \href {https://openreview.net/forum?id=B1x6w0EtwH} {Graph constrained
  reinforcement learning for natural language action spaces}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}.

\bibitem[{Ammanabrolu and Riedl(2019{\natexlab{a}})}]{ammanabrolu2019kgdqn}
Prithviraj Ammanabrolu and Mark Riedl. 2019{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/N19-1358} {Playing text-adventure
  games with graph-based deep reinforcement learning}.
\newblock In \emph{Proceedings of the Conference of the North American Chapter
  of the Association for Computational Linguistics: Human Language Technologies
  (NAACL-HLT)}, volume~1, pages 3557--3565.

\bibitem[{Ammanabrolu and
  Riedl(2019{\natexlab{b}})}]{ammanabrolu2019kgdqntransfer}
Prithviraj Ammanabrolu and Mark Riedl. 2019{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/v1/D19-5301} {Transfer in deep
  reinforcement learning using knowledge graphs}.
\newblock In \emph{Proceedings of the Thirteenth Workshop on Graph-Based
  Methods for Natural Language Processing (TextGraphs-13)}, pages 1--10.

\bibitem[{Ammanabrolu et~al.(2020)Ammanabrolu, Tien, Luo, and
  Riedl}]{ammanabrolu2020kga2cexplore}
Prithviraj Ammanabrolu, Ethan Tien, Zhaochen Luo, and Mark~O Riedl. 2020.
\newblock How to avoid being eaten by a grue: Exploration strategies for
  text-adventure agents.
\newblock \emph{arXiv preprint arXiv:2002.08795}.

\bibitem[{Ammanabrolu et~al.(2021)Ammanabrolu, Urbanek, Li, Szlam,
  Rockt{\"a}schel, and Weston}]{ammanabrolu2020quest}
Prithviraj Ammanabrolu, Jack Urbanek, Margaret Li, Arthur Szlam, Tim
  Rockt{\"a}schel, and Jason Weston. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.naacl-main.64} {How to
  motivate your dragon: Teaching goal-driven agents to speak and act in fantasy
  worlds}.
\newblock In \emph{Proceedings of Conference of the North American Chapter of
  the Association for Computational Linguistics: Human Language Technologies
  (NAACL-HLT)}, pages 807--833.

\bibitem[{Andreas et~al.(2017)Andreas, Klein, and Levine}]{andreas2017modular}
Jacob Andreas, Dan Klein, and Sergey Levine. 2017.
\newblock \href {https://proceedings.mlr.press/v70/andreas17a.html} {Modular
  multitask reinforcement learning with policy sketches}.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~70, pages 166--175.

\bibitem[{Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Abbeel, and Zaremba}]{andrychowicz2017her}
Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong,
  Peter Welinder, Bob McGrew, Josh Tobin, Pieter Abbeel, and Wojciech Zaremba.
  2017.
\newblock Hindsight experience replay.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~30, pages 5048--5058.

\bibitem[{Atkinson et~al.(2019)Atkinson, Baier, Copplestone, Devlin, and
  Swan}]{atkinson2019text}
Timothy Atkinson, Hendrik Baier, Tara Copplestone, Sam Devlin, and Jerry Swan.
  2019.
\newblock \href {https://doi.org/10.1109/TG.2019.2896017} {The text-based
  adventure ai competition}.
\newblock \emph{IEEE Transactions on Games}, 11(3):260--266.

\bibitem[{Bahdanau et~al.(2019)Bahdanau, Hill, Leike, Hughes, Kohli, and
  Grefenstette}]{bahdanau2018goal_language}
Dzmitry Bahdanau, Felix Hill, Jan Leike, Edward Hughes, Pushmeet Kohli, and
  Edward Grefenstette. 2019.
\newblock \href {https://openreview.net/forum?id=H1xsSjC9Ym} {Learning to
  understand goal specifications by modelling reward}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}.

\bibitem[{Bellemare et~al.(2016)Bellemare, Srinivasan, Ostrovski, Schaul,
  Saxton, and Munos}]{bellemare2016counting}
Marc Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul, David Saxton,
  and Remi Munos. 2016.
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~29, pages 1471--1479.

\bibitem[{Bengio et~al.(2009)Bengio, Louradour, Collobert, and
  Weston}]{bengio2009curriculum}
Yoshua Bengio, J{\'e}r{\^o}me Louradour, Ronan Collobert, and Jason Weston.
  2009.
\newblock Curriculum learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pages
  41--48.

\bibitem[{Cobbe et~al.(2019)Cobbe, Klimov, Hesse, Kim, and
  Schulman}]{cobbe2019rlgeneralization}
Karl Cobbe, Oleg Klimov, Chris Hesse, Taehoon Kim, and John Schulman. 2019.
\newblock Quantifying generalization in reinforcement learning.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~97, pages 1282--1289.

\bibitem[{C\^ot\'e et~al.(2018)C\^ot\'e, K\'ad\'ar, Yuan, Kybartas, Barnes,
  Fine, Moore, Tao, Hausknecht, Asri, Adada, Tay, and
  Trischler}]{cote2018textworld}
Marc-Alexandre C\^ot\'e, \'Akos K\'ad\'ar, Xingdi Yuan, Ben Kybartas, Tavian
  Barnes, Emery Fine, James Moore, Ruo~Yu Tao, Matthew Hausknecht, Layla~El
  Asri, Mahmoud Adada, Wendy Tay, and Adam Trischler. 2018.
\newblock Textworld: A learning environment for text-based games.
\newblock \emph{arXiv preprint arXiv:1806.11532}.

\bibitem[{Dayan and Hinton(1992)}]{dayan1992hrl_feudal}
Peter Dayan and Geoffrey~E Hinton. 1992.
\newblock Feudal reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~5.

\bibitem[{Fang et~al.(2017)Fang, Li, and Cohn}]{fang2017learning}
Meng Fang, Yuan Li, and Trevor Cohn. 2017.
\newblock \href {https://doi.org/10.18653/v1/D17-1063} {Learning how to active
  learn: A deep reinforcement learning approach}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 595--605.

\bibitem[{Fang et~al.(2019{\natexlab{a}})Fang, Zhou, Shi, Gong, Xu, and
  Zhang}]{fang2019dher}
Meng Fang, Cheng Zhou, Bei Shi, Boqing Gong, Jia Xu, and Tong Zhang.
  2019{\natexlab{a}}.
\newblock \href {https://openreview.net/forum?id=Byf5-30qFX} {{DHER}: Hindsight
  experience replay for dynamic goals}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}.

\bibitem[{Fang et~al.(2019{\natexlab{b}})Fang, Zhou, Du, Han, and
  Zhang}]{fang2019curriculum}
Meng Fang, Tianyi Zhou, Yali Du, Lei Han, and Zhengyou Zhang.
  2019{\natexlab{b}}.
\newblock Curriculum-guided hindsight experience replay.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~32, pages 12602--12613.

\bibitem[{Fu et~al.(2019)Fu, Korattikara, Levine, and
  Guadarrama}]{fu2018goal_language}
Justin Fu, Anoop Korattikara, Sergey Levine, and Sergio Guadarrama. 2019.
\newblock \href {https://openreview.net/forum?id=r1lq1hRqYQ} {From language to
  goals: Inverse reinforcement learning for vision-based instruction
  following}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}.

\bibitem[{Guo et~al.(2020)Guo, Yu, Gao, Gan, Campbell, and
  Chang}]{guo2020emnlp}
Xiaoxiao Guo, Mo~Yu, Yupeng Gao, Chuang Gan, Murray Campbell, and Shiyu Chang.
  2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.624} {Interactive
  fiction game playing as multi-paragraph reading comprehension with
  reinforcement learning}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 7755--7765.

\bibitem[{Hasselt et~al.(2016)Hasselt, Guez, and Silver}]{hasselt2016doubledqn}
Hado~van Hasselt, Arthur Guez, and David Silver. 2016.
\newblock Deep reinforcement learning with double q-learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence (AAAI)}, volume~30, pages 2094--2100.

\bibitem[{Hausknecht et~al.(2020)Hausknecht, Ammanabrolu, C{\^o}t{\'e}, and
  Yuan}]{hausknecht2019jericho}
Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre C{\^o}t{\'e}, and
  Xingdi Yuan. 2020.
\newblock Interactive fiction games: A colossal adventure.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence (AAAI)}, volume~34, pages 7903--7910.

\bibitem[{Hausknecht et~al.(2019)Hausknecht, Loynd, Yang, Swaminathan, and
  Williams}]{hausknecht2019nail}
Matthew Hausknecht, Ricky Loynd, Greg Yang, Adith Swaminathan, and Jason~D
  Williams. 2019.
\newblock Nail: A general interactive fiction agent.
\newblock \emph{arXiv preprint arXiv:1902.04259}.

\bibitem[{He et~al.(2016)He, Chen, He, Gao, Li, Deng, and
  Ostendorf}]{he2016drrn}
Ji~He, Jianshu Chen, Xiaodong He, Jianfeng Gao, Lihong Li, Li~Deng, and Mari
  Ostendorf. 2016.
\newblock \href {https://doi.org/10.18653/v1/P16-1153} {Deep reinforcement
  learning with a natural language action space}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics (ACL)}, pages 1621--1630.

\bibitem[{Jain et~al.(2020)Jain, Fedus, Larochelle, Precup, and
  Bellemare}]{jain2019aaai}
Vishal Jain, William Fedus, Hugo Larochelle, Doina Precup, and Marc~G
  Bellemare. 2020.
\newblock Algorithmic improvements for deep reinforcement learning applied to
  interactive fiction.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence (AAAI)}, volume~34, pages 4328--4336.

\bibitem[{Jiang et~al.(2019)Jiang, Gu, Murphy, and Finn}]{jiang2019hrl}
Yiding Jiang, Shixiang~Shane Gu, Kevin~P Murphy, and Chelsea Finn. 2019.
\newblock Language as an abstraction for hierarchical deep reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~32, pages 9419--9431.

\bibitem[{Kaelbling(1993)}]{kaelbling1993goal}
Leslie~Pack Kaelbling. 1993.
\newblock Learning to achieve goals.
\newblock In \emph{Proceedings of the International Joint Conference on
  Artificial Intelligence (IJCAI)}, pages 1094--1098.

\bibitem[{Kulkarni et~al.(2016)Kulkarni, Narasimhan, Saeedi, and
  Tenenbaum}]{kulkarni2016hrl}
Tejas~D Kulkarni, Karthik Narasimhan, Ardavan Saeedi, and Josh Tenenbaum. 2016.
\newblock Hierarchical deep reinforcement learning: Integrating temporal
  abstraction and intrinsic motivation.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  29:3675--3683.

\bibitem[{Luketina et~al.(2019)Luketina, Nardelli, Farquhar, Foerster, Andreas,
  Grefenstette, Whiteson, and Rocktäschel}]{luketina2019survey}
Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob
  Andreas, Edward Grefenstette, Shimon Whiteson, and Tim Rocktäschel. 2019.
\newblock \href {https://doi.org/10.24963/ijcai.2019/880} {A survey of
  reinforcement learning informed by natural language}.
\newblock In \emph{Proceedings of the International Joint Conference on
  Artificial Intelligence (IJCAI)}, pages 6309--6317.

\bibitem[{Murugesan et~al.(2021)Murugesan, Atzeni, Kapanipathi, Shukla,
  Kumaravel, Tesauro, Talamadupula, Sachan, and
  Campbell}]{murugesan2020commonsense}
Keerthiram Murugesan, Mattia Atzeni, Pavan Kapanipathi, Pushkar Shukla, Sadhana
  Kumaravel, Gerald Tesauro, Kartik Talamadupula, Mrinmaya Sachan, and Murray
  Campbell. 2021.
\newblock Text-based rl agents with commonsense knowledge: New challenges,
  environments and baselines.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence (AAAI)}, volume~35, pages 9018--9027.

\bibitem[{Murugesan et~al.(2020)Murugesan, Atzeni, Shukla, Sachan, Kapanipathi,
  and Talamadupula}]{murugesan2020kg}
Keerthiram Murugesan, Mattia Atzeni, Pushkar Shukla, Mrinmaya Sachan, Pavan
  Kapanipathi, and Kartik Talamadupula. 2020.
\newblock Enhancing text-based reinforcement learning agents with commonsense
  knowledge.
\newblock \emph{arXiv preprint arXiv:2005.00811}.

\bibitem[{Nachum et~al.(2018)Nachum, Gu, Lee, and Levine}]{nachum2018hrl}
Ofir Nachum, Shixiang~Shane Gu, Honglak Lee, and Sergey Levine. 2018.
\newblock Data-efficient hierarchical reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~31, pages 3303--3313.

\bibitem[{Narasimhan et~al.(2015)Narasimhan, Kulkarni, and
  Barzilay}]{narasimhan2015language}
Karthik Narasimhan, Tejas~D Kulkarni, and Regina Barzilay. 2015.
\newblock \href {https://doi.org/10.18653/v1/D15-1001} {Language understanding
  for text-based games using deep reinforcement learning}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1--11.

\bibitem[{Oh et~al.(2017)Oh, Singh, Lee, and Kohli}]{oh2017zero}
Junhyuk Oh, Satinder Singh, Honglak Lee, and Pushmeet Kohli. 2017.
\newblock Zero-shot task generalization with multi-task deep reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~70, pages 2661--2670.

\bibitem[{Peng et~al.(2017)Peng, Li, Li, Gao, Celikyilmaz, Lee, and
  Wong}]{peng2017HRLforDialogue}
Baolin Peng, Xiujun Li, Lihong Li, Jianfeng Gao, Asli Celikyilmaz, Sungjin Lee,
  and Kam-Fai Wong. 2017.
\newblock \href {https://doi.org/10.18653/v1/D17-1237} {Composite
  task-completion dialogue policy learning via hierarchical deep reinforcement
  learning}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 2231--2240.

\bibitem[{Saleh et~al.(2020)Saleh, Jaques, Ghandeharioun, Shen, and
  Picard}]{saleh2020HRLforDialogue}
Abdelrhman Saleh, Natasha Jaques, Asma Ghandeharioun, Judy Shen, and Rosalind
  Picard. 2020.
\newblock Hierarchical reinforcement learning for open-domain dialog.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence (AAAI)}, volume~34, pages 8741--8748.

\bibitem[{Schaul et~al.(2015)Schaul, Quan, Antonoglou, and
  Silver}]{schaul2015per}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver. 2015.
\newblock Prioritized experience replay.
\newblock \emph{arXiv preprint arXiv:1511.05952}.

\bibitem[{Schlichtkrull et~al.(2018)Schlichtkrull, Kipf, Bloem, Van Den~Berg,
  Titov, and Welling}]{schlichtkrull2018rgcn}
Michael Schlichtkrull, Thomas~N Kipf, Peter Bloem, Rianne Van Den~Berg, Ivan
  Titov, and Max Welling. 2018.
\newblock Modeling relational data with graph convolutional networks.
\newblock In \emph{European Semantic Web Conference (ESWC)}, pages 593--607.

\bibitem[{Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov}]{schulman2017ppo}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
  2017.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}.

\bibitem[{Shiarlis et~al.(2018)Shiarlis, Wulfmeier, Salter, Whiteson, and
  Posner}]{shiarlis2018taco}
Kyriacos Shiarlis, Markus Wulfmeier, Sasha Salter, Shimon Whiteson, and Ingmar
  Posner. 2018.
\newblock Taco: Learning task decomposition via temporal alignment for control.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~80, pages 4654--4663.

\bibitem[{Shu et~al.(2018)Shu, Xiong, and Socher}]{shu2018hrl}
Tianmin Shu, Caiming Xiong, and Richard Socher. 2018.
\newblock \href {https://openreview.net/forum?id=SJJQVZW0b} {Hierarchical and
  interpretable skill acquisition in multi-task reinforcement learning}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}.

\bibitem[{Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot
  et~al.}]{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al. 2016.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{nature}, 529(7587):484--489.

\bibitem[{Sohn et~al.(2018)Sohn, Oh, and Lee}]{sohn2018subtask}
Sungryull Sohn, Junhyuk Oh, and Honglak Lee. 2018.
\newblock Hierarchical reinforcement learning for zero-shot generalization with
  subtask dependencies.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~31, pages 7156--7166.

\bibitem[{Sutton et~al.(1999)Sutton, Precup, and Singh}]{sutton1999hrl}
Richard~S Sutton, Doina Precup, and Satinder Singh. 1999.
\newblock Between mdps and semi-mdps: A framework for temporal abstraction in
  reinforcement learning.
\newblock \emph{Artificial intelligence}, 112(1-2):181--211.

\bibitem[{Urbanek et~al.(2019)Urbanek, Fan, Karamcheti, Jain, Humeau, Dinan,
  Rockt{\"a}schel, Kiela, Szlam, and Weston}]{urbanek2019light}
Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel Humeau,
  Emily Dinan, Tim Rockt{\"a}schel, Douwe Kiela, Arthur Szlam, and Jason
  Weston. 2019.
\newblock \href {https://doi.org/10.18653/v1/D19-1062} {Learning to speak and
  act in a fantasy text adventure game}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 673--683.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{vaswani2017transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin. 2017.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~30, pages 5998--6008.

\bibitem[{Vezhnevets et~al.(2017)Vezhnevets, Osindero, Schaul, Heess,
  Jaderberg, Silver, and Kavukcuoglu}]{vezhnevets2017hrl_feudal}
Alexander~Sasha Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Heess, Max
  Jaderberg, David Silver, and Koray Kavukcuoglu. 2017.
\newblock {F}e{U}dal networks for hierarchical reinforcement learning.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~70, pages 3540--3549.

\bibitem[{Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev et~al.}]{vinyals2019alphastar}
Oriol Vinyals, Igor Babuschkin, Wojciech~M Czarnecki, Micha{\"e}l Mathieu,
  Andrew Dudzik, Junyoung Chung, David~H Choi, Richard Powell, Timo Ewalds,
  Petko Georgiev, et~al. 2019.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock \emph{Nature}, 575(7782):350--354.

\bibitem[{Xu et~al.(2020{\natexlab{a}})Xu, Chen, Fang, Wang, and
  Zhang}]{xu2020cog}
Yunqiu Xu, Ling Chen, Meng Fang, Yang Wang, and Chengqi Zhang.
  2020{\natexlab{a}}.
\newblock Deep reinforcement learning with transformers for text adventure
  games.
\newblock In \emph{IEEE Conference on Games (CoG)}, pages 65--72.

\bibitem[{Xu et~al.(2020{\natexlab{b}})Xu, Fang, Chen, Du, Zhou, and
  Zhang}]{xu2020nips}
Yunqiu Xu, Meng Fang, Ling Chen, Yali Du, Joey~Tianyi Zhou, and Chengqi Zhang.
  2020{\natexlab{b}}.
\newblock Deep reinforcement learning with stacked hierarchical attention for
  text-based games.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~33, pages 16495--16507.

\bibitem[{Yao et~al.(2020)Yao, Rao, Hausknecht, and Narasimhan}]{yao2020emnlp}
Shunyu Yao, Rohan Rao, Matthew Hausknecht, and Karthik Narasimhan. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.704} {Keep {CALM}
  and explore: Language models for action generation in text-based games}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 8736--8754.

\bibitem[{Yin and May(2019)}]{yin2019cog}
Xusen Yin and Jonathan May. 2019.
\newblock Comprehensible context-driven text game playing.
\newblock \emph{IEEE Conference on Games (CoG)}, pages 1--8.

\bibitem[{Yin et~al.(2020)Yin, Weischedel, and May}]{yin2020emnlpfinding}
Xusen Yin, Ralph Weischedel, and Jonathan May. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.findings-emnlp.273} {Learning
  to generalize for sequential decision making}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing: Findings (EMNLP-Findings)}, pages 3046--3063.

\bibitem[{Yuan et~al.(2018)Yuan, Côté, Sordoni, Laroche, Tachet~des Combes,
  Hausknecht, and Trischler}]{yuan2018counting}
Xingdi~(Eric) Yuan, Marc-Alexandre Côté, Alessandro Sordoni, Romain Laroche,
  Remi Tachet~des Combes, Matthew Hausknecht, and Adam Trischler. 2018.
\newblock Counting to explore and generalize in text-based games.
\newblock In \emph{European Workshop on Reinforcement Learning (EWRL)}.

\bibitem[{Zahavy et~al.(2018)Zahavy, Haroush, Merlis, Mankowitz, and
  Mannor}]{zahavy2018nips}
Tom Zahavy, Matan Haroush, Nadav Merlis, Daniel~J Mankowitz, and Shie Mannor.
  2018.
\newblock Learn what not to learn: Action elimination with deep reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~31, pages 3562--3573.

\bibitem[{Zhang et~al.(2020)Zhang, Xu, Wang, Wu, Keutzer, Gonzalez, and
  Tian}]{zhang2020counting}
Tianjun Zhang, Huazhe Xu, Xiaolong Wang, Yi~Wu, Kurt Keutzer, Joseph~E
  Gonzalez, and Yuandong Tian. 2020.
\newblock Bebold: Exploration beyond the boundary of explored regions.
\newblock \emph{arXiv preprint arXiv:2012.08621}.

\end{thebibliography}
