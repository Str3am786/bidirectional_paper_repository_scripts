In this work, we discussed two approaches for representative sampling of CF-data, especially for accurately retaining the \emph{relative} performance of different recommendation algorithms. First, we proposed \sampler, which is better than commonly used sampling strategies, followed by introducing \oracle which \emph{analyzes} the performance of different samplers on different datasets. Detailed experiments suggest that \oracle can confidently estimate the downstream utility of any sampler within a few milliseconds, thereby enabling practitioners to benchmark different algorithms on $10$\% data sub-samples, with an average $5.8\times$ time speedup.

To realize the real-world environmental impact of \oracle, we discuss a typical weekly RecSys development cycle 
% in the industry 
and its carbon footprint. 
Taking the Criteo Ad dataset as inspiration, we assume a common industry-scale dataset to have $\sim4$B interactions.
% Inspired by the Criteo Ad Terabyte dataset, which is a collection of 24 days of ad-click logs, we assume a common industrial dataset to have around $4$ billion interactions. 
We assume a hypothetical use case that benchmarks for \eg $25$ different algorithms, each with $40$ different hyper-parameter variations. To estimate the energy consumption of GPUs, we scale the $0.4$ minute MLPerf \cite{mlperf} run of training NeuMF \cite{neural_mf} on the Movielens-20M dataset over an Nvidia DGX-2 machine. The total estimated run-time for all experiments would be $25 \times 40 \times \frac{4B}{20M} \times \frac{0.4}{60} \approx 1340$ hours; and following \cite{co2e}, the net CO$_2$ emissions would roughly be $10 \times 1340 \times 1.58 \times 0.954 \approx 20k$ lbs. To better understand the significance of this number, a brief CO$_2$ emissions comparison is presented in \cref{co2e}. Clearly, \oracle along with saving a large amount of experimentation time and cloud compute cost, can also significantly reduce the carbon footprint of this \emph{weekly process} by more than an average human's \emph{yearly} CO$_2$ emissions.

% \begin{wraptable}{r}{0.36\textwidth}
\input{co2e.tex}
% \end{wraptable}

Despite having significantly benefited the run-time and environmental impacts of benchmarking %recommendation 
algorithms on massive datasets, our analysis heavily relied on the experiments of training seven 
%different 
recommendation algorithms on six datasets and their various samples. Despite the already large experimental cost, we strongly believe that the downstream performance of \oracle could be further improved by simply 
% adding 
considering
more algorithms and diverse datasets.
% with different characteristics. 
In addition to better sampling, analyzing the fairness 
% and privacy 
aspects of training algorithms on sub-sampled datasets is an interesting research direction, which we plan to explore in future work.
% Future work: Fairness, SVP w/ sequential, New samplers