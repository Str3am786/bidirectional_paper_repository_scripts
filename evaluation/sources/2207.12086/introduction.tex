Recently, machine learning has become one of the most successful tools
for supporting decisions, and it has been applied widely to many real-world
applications including face recognition \cite{sharif2016accessorize},
security systems \cite{apruzzese2019addressing}, disease detection
\cite{kumar2016dermatological}, or recommended systems \cite{portugal2018use}.
Two core components of a machine learning tool are the algorithm and
the data. The algorithm can be classified into two mainstreams, namely
classification and clustering while the data can be in different formats,
e.g. tabular or image.

When dealing with images in computer vision applications, machine
learning models (or classifiers) often leverage \textit{data augmentation}
techniques to improve the classification accuracy \cite{fawaz2018data}.
The main idea is that given an image of `dog', if we rotate or flip
the image, then we still recognize the object in the image as a `dog'.
By doing this geometric transformation, the label of an image is unchanged
but we can obtain different variants of the image, helping the machine
learning classifier to observe more data and improve its generalization.
In addition to geometric transformation, other data augmentation techniques
are mix-up \cite{zhang2017mixup} and cut-mix \cite{walawalkar2020attentive}.

In spite of a great success in computer vision, applying data augmentation
to tabular data is challenging. There are three main reasons. First,
an image is typically invariant to a small modification, e.g. flip,
zoom, or rotation whereas a small change for a record in tabular data
can result in a totally different outcome. All features (i.e. pixels)
in images are i.i.d (independent and identical distributed) whereas
each feature in tabular data (e.g. Sex or Age) has different ranges
of values. Finally, one transformation operator can be applied to
all features in images whereas each feature in tabular data often
requires a relevant transformation operator depending on the type
of the feature (continuous, discrete or categorical).

\textbf{Our method.} We propose an efficient classification method
with a new data augmentation technique for tabular data. Our method
has two main steps. First, we use causal reasoning to learn counterfactual
samples for the original training samples. Each counterfactual sample
is a variant of an original sample whose all feature values are the
same except the intervened feature. Since the counterfactual samples
may have different outcomes from the original ones, we obtain their
labels via a matching method. Second, we augment counterfactual samples
to real samples to create a new training set to train the classifier.
Since not all counterfactual samples are useful, we select the meaningful
ones that potentially improve the classification performance using
an active learning based method. Our active learning is an uncertain-based
approach. It determines samples that are difficult to predict, then
obtains their counterfactual version to enrich the training data.
Using both real and counterfactual samples, our classifier improves
its generalization, resulting in a better accuracy on unseen testing
samples.

\textbf{Our contribution.} To summarize, we make the following contributions.
\begin{enumerate}
\item We propose \textbf{CCRAL} (\textit{\uline{C}}\textit{lassifier
with }\textit{\uline{C}}\textit{ausal }\textit{\uline{R}}\textit{easoning
and }\textit{\uline{A}}\textit{ctive }\textit{\uline{L}}\textit{earning}),
a novel method for classification with data augmentation in tabular
data. To the best of our knowledge, \textbf{CCRAL} is the first method
that combines both causal reasoning and active learning to train a
classifier with synthetic samples in tabular data.
\item We develop an efficient framework to generate synthetic data. It consists
of two steps: (1) it creates counterfactual samples via sample matching
and (2) it selects useful counterfactual samples via active learning.
\item We demonstrate the benefits of our method on five real-world tabular
datasets, where our method is significantly better than the standard
classifier in both accuracy and AUC measures.
\end{enumerate}
The rest of the paper is organized as follows. In Section \ref{sec:Related-Works},
we briefly outline the fundamentals of data augmentation methods,
the generation of counterfactual data, and active learning in the
literature. We describe our proposed framework \textbf{CCRAL} with
an algorithm and illustrate the \textit{region of uncertainty} in
Section \ref{sec:Framework}. Our experimental settings, datasets,
results are presented in Section \ref{sec:Experiments}, where we
evaluate the performance of \textbf{CCRAL} and compare it with two
existing methods. Finally, we conclude our work in Section \ref{sec:Conclusion}.
