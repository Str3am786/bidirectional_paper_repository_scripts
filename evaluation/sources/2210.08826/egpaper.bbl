\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{arazo2019unsupervised}
Eric Arazo, Diego Ortego, Paul Albert, Noel Oâ€™Connor, and Kevin Mcguinness.
\newblock Unsupervised label noise modeling and loss correction.
\newblock In {\em International Conference on Machine Learning}, pages
  312--321, 2019.

\bibitem{arpit2017closer}
Devansh Arpit, Stanis{\l}aw Jastrzebski, Nicolas Ballas, David Krueger,
  Emmanuel Bengio, Maxinder~S Kanwal, Tegan Maharaj, Asja Fischer, Aaron
  Courville, Yoshua Bengio, et~al.
\newblock A closer look at memorization in deep networks.
\newblock In {\em International conference on machine learning}, pages
  233--242. PMLR, 2017.

\bibitem{bachman2014learning}
Philip Bachman, Ouais Alsharif, and Doina Precup.
\newblock Learning with pseudo-ensembles.
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\bibitem{bahri2020deep}
Dara Bahri, Heinrich Jiang, and Maya Gupta.
\newblock Deep k-nn for noisy labels.
\newblock In {\em International Conference on Machine Learning}, pages
  540--550. PMLR, 2020.

\bibitem{bai2021understanding}
Yingbin Bai, Erkun Yang, Bo Han, Yanhua Yang, Jiatong Li, Yinian Mao, Gang Niu,
  and Tongliang Liu.
\newblock Understanding and improving early stopping for learning with noisy
  labels.
\newblock {\em Advances in Neural Information Processing Systems},
  34:24392--24403, 2021.

\bibitem{berthelot2019mixmatch}
David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital
  Oliver, and Colin~A Raffel.
\newblock Mixmatch: A holistic approach to semi-supervised learning.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{chen2019understanding}
Pengfei Chen, Ben~Ben Liao, Guangyong Chen, and Shengyu Zhang.
\newblock Understanding and utilizing deep neural networks trained with noisy
  labels.
\newblock In {\em International Conference on Machine Learning}, pages
  1062--1070. PMLR, 2019.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem{chen2020big}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey~E
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock {\em Advances in neural information processing systems},
  33:22243--22255, 2020.

\bibitem{chen2020improved}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock {\em arXiv preprint arXiv:2003.04297}, 2020.

\bibitem{cordeiro2021propmix}
F.~R. Cordeiro, Vasileios Belagiannis, Ian Reid, and Gustavo Carneiro.
\newblock Propmix: Hard sample filtering and proportional mixup for learning
  with noisy labels.
\newblock {\em The 32nd British Machine Vision Conference}, 2021.

\bibitem{cubuk2019autoaugment}
Ekin~D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc~V Le.
\newblock Autoaugment: Learning augmentation strategies from data.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 113--123, 2019.

\bibitem{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition Workshops}, pages 702--703, 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{Goldberger2017TrainingDN}
Jacob Goldberger and Ehud Ben-Reuven.
\newblock Training deep neural-networks using a noise adaptation layer.
\newblock In {\em ICLR}, 2017.

\bibitem{grandvalet2004semi}
Yves Grandvalet and Yoshua Bengio.
\newblock Semi-supervised learning by entropy minimization.
\newblock {\em Advances in neural information processing systems}, 17, 2004.

\bibitem{gu2021instancedependent}
Keren Gu, Xander Masotto, Vandana Bachani, Balaji Lakshminarayanan, Jack
  Nikodem, and Dong Yin.
\newblock An instance-dependent simulation framework for learning with label
  noise, 2021.

\bibitem{han2018co}
Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and
  Masashi Sugiyama.
\newblock Co-teaching: Robust training of deep neural networks with extremely
  noisy labels.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{he2016identity}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Identity mappings in deep residual networks.
\newblock In {\em European conference on computer vision}, pages 630--645.
  Springer, 2016.

\bibitem{huang2017densely}
Gao Huang, Zhuang Liu, Laurens Van Der~Maaten, and Kilian~Q Weinberger.
\newblock Densely connected convolutional networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4700--4708, 2017.

\bibitem{inoue2017multi}
Naoto Inoue, Edgar Simo-Serra, Toshihiko Yamasaki, and Hiroshi Ishikawa.
\newblock Multi-label fashion image classification with minimal human
  supervision.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision Workshops}, pages 2261--2267, 2017.

\bibitem{kim2021fine}
Taehyeon Kim, Jongwoo Ko, JinHwan Choi, Se-Young Yun, et~al.
\newblock Fine samples for learning with noisy labels.
\newblock {\em Advances in Neural Information Processing Systems},
  34:24137--24149, 2021.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Canadian Institute for Advanced Research, 2009.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Advances in neural information processing systems},
  25:1097--1105, 2012.

\bibitem{Laine2017TemporalEF}
Samuli Laine and Timo Aila.
\newblock Temporal ensembling for semi-supervised learning.
\newblock In {\em 5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}, 2017.

\bibitem{lecun2015deep}
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
\newblock Deep learning.
\newblock {\em nature}, 521(7553):436--444, 2015.

\bibitem{lee2013pseudo}
Dong-Hyun Lee.
\newblock Pseudo-label : The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock {\em ICML 2013 Workshop : Challenges in Representation Learning
  (WREPL)}, 07 2013.

\bibitem{lee2019robust}
Kimin Lee, Sukmin Yun, Kibok Lee, Honglak Lee, Bo Li, and Jinwoo Shin.
\newblock Robust inference via generative classifiers for handling noisy
  labels.
\newblock In {\em International Conference on Machine Learning}, pages
  3763--3772. PMLR, 2019.

\bibitem{li2020dividemix}
Junnan Li, Richard Socher, and Steven~CH Hoi.
\newblock Dividemix: Learning with noisy labels as semi-supervised learning.
\newblock {\em arXiv preprint arXiv:2002.07394}, 2020.

\bibitem{li2019learning}
Junnan Li, Yongkang Wong, Qi Zhao, and Mohan~S Kankanhalli.
\newblock Learning to learn from noisy labeled data.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 5051--5059, 2019.

\bibitem{li2021learning}
Junnan Li, Caiming Xiong, and Steven~CH Hoi.
\newblock Learning from noisy data with robust representation learning.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9485--9494, 2021.

\bibitem{li2017webvision}
Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van~Gool.
\newblock Webvision database: Visual learning and understanding from web data.
\newblock {\em arXiv preprint arXiv:1708.02862}, 2017.

\bibitem{liu2020early}
Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda.
\newblock Early-learning regularization prevents memorization of noisy labels.
\newblock {\em Advances in neural information processing systems},
  33:20331--20342, 2020.

\bibitem{lloyd2004observer}
Ricardo~V Lloyd, Lori~A Erickson, Mary~B Casey, King~Y Lam, Christine~M Lohse,
  Sylvia~L Asa, John~KC Chan, Ronald~A DeLellis, H~Ruben Harach, Kennichi
  Kakudo, et~al.
\newblock Observer variation in the diagnosis of follicular variant of
  papillary thyroid carcinoma.
\newblock {\em The American journal of surgical pathology}, 28(10):1336--1340,
  2004.

\bibitem{Nishi_2021_CVPR}
Kento Nishi, Yi Ding, Alex Rich, and Tobias Hollerer.
\newblock Augmentation strategies for learning with noisy labels.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 8022--8031, June 2021.

\bibitem{ortego2020multi}
Diego Ortego, Eric Arazo, Paul Albert, Noel~E O'Connor, and Kevin McGuinness.
\newblock Multi-objective interpolation training for robustness to label noise.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 6606--6615, 2021.

\bibitem{patrini2017making}
Giorgio Patrini, Alessandro Rozza, Aditya Krishna~Menon, Richard Nock, and
  Lizhen Qu.
\newblock Making deep neural networks robust to label noise: A loss correction
  approach.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1944--1952, 2017.

\bibitem{pham2020meta}
Hieu Pham, Zihang Dai, Qizhe Xie, and Quoc~V Le.
\newblock Meta pseudo labels.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11557--11568, 2021.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{reed2014training}
Scott~E. Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru
  Erhan, and Andrew Rabinovich.
\newblock Training deep neural networks on noisy labels with bootstrapping.
\newblock In {\em ICLR 2015}, 2015.

\bibitem{ren2018learning}
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun.
\newblock Learning to reweight examples for robust deep learning.
\newblock In {\em International Conference on Machine Learning}, pages
  4334--4343. PMLR, 2018.

\bibitem{sachdeva2021scanmix}
Ragav Sachdeva, Filipe~R Cordeiro, Vasileios Belagiannis, Ian Reid, and Gustavo
  Carneiro.
\newblock Scanmix: Learning from severe label noise via semantic clustering and
  semi-supervised learning.
\newblock {\em arXiv preprint arXiv:2103.11395}, 2021.

\bibitem{sarfraz2021noisy}
Fahad Sarfraz, Elahe Arani, and Bahram Zonooz.
\newblock Noisy concurrent training for efficient learning under label noise.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision}, pages 3159--3168, 2021.

\bibitem{shu2019meta}
Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng.
\newblock Meta-weight-net: Learning an explicit mapping for sample weighting.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em 3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.

\bibitem{sohn2020fixmatch}
Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang,
  Colin~A Raffel, Ekin~Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li.
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock {\em Advances in Neural Information Processing Systems}, 33:596--608,
  2020.

\bibitem{song2019selfie}
Hwanjun Song, Minseok Kim, and Jae-Gil Lee.
\newblock {SELFIE}: Refurbishing unclean samples for robust deep learning.
\newblock In {\em ICML}, 2019.

\bibitem{szegedy2017inception}
Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alexander~A Alemi.
\newblock Inception-v4, inception-resnet and the impact of residual connections
  on learning.
\newblock In {\em Thirty-first AAAI conference on artificial intelligence},
  2017.

\bibitem{tarvainen2017mean}
Antti Tarvainen and Harri Valpola.
\newblock Mean teachers are better role models: Weight-averaged consistency
  targets improve semi-supervised deep learning results.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{van2020scan}
Wouter Van~Gansbeke, Simon Vandenhende, Stamatios Georgoulis, Marc Proesmans,
  and Luc Van~Gool.
\newblock Scan: Learning to classify images without labels.
\newblock In {\em European Conference on Computer Vision}, pages 268--285.
  Springer, 2020.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{veit2017learning}
Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and Serge
  Belongie.
\newblock Learning from noisy large-scale datasets with minimal supervision.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 839--847, 2017.

\bibitem{wang2017chestx}
Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, and
  Ronald~M Summers.
\newblock Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on
  weakly-supervised classification and localization of common thorax diseases.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2097--2106, 2017.

\bibitem{wang2020training}
Zhen Wang, Guosheng Hu, and Qinghua Hu.
\newblock Training noise-robust deep neural networks via meta-learning.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 4524--4533, 2020.

\bibitem{wu2021ngc}
Zhi-Fan Wu, Tong Wei, Jianwen Jiang, Chaojie Mao, Mingqian Tang, and Yu-Feng
  Li.
\newblock Ngc: A unified framework for learning with open-world noisy data.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 62--71, 2021.

\bibitem{xia2020part}
Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu,
  Gang Niu, Dacheng Tao, and Masashi Sugiyama.
\newblock Part-dependent label noise: Towards instance-dependent label noise.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{xia2019anchor}
Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and
  Masashi Sugiyama.
\newblock Are anchor points really indispensable in label-noise learning?
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{xiao2015learning}
Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang.
\newblock Learning from massive noisy labeled data for image classification.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2691--2699, 2015.

\bibitem{xu2021faster}
Youjiang Xu, Linchao Zhu, Lu Jiang, and Yi Yang.
\newblock Faster meta update strategy for noise-robust deep learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 144--153, 2021.

\bibitem{FaMUS}
Youjiang Xu, Linchao Zhu, Lu Jiang, and Yi Yang.
\newblock Faster meta update strategy for noise-robust deep learning.
\newblock In {\em CVPR}, 2021.

\bibitem{zhang2021flexmatch}
Bowen Zhang, Yidong Wang, Wenxin Hou, Hao Wu, Jindong Wang, Manabu Okumura, and
  Takahiro Shinozaki.
\newblock Flexmatch: Boosting semi-supervised learning with curriculum pseudo
  labeling.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{zhang2016understanding}
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.
\newblock Understanding deep learning requires rethinking generalization.
\newblock {\em arXiv preprint arXiv:1611.03530}, 2016.

\bibitem{zhang2018mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N. Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{zhang2020learning}
Le Zhang, Ryutaro Tanno, Kevin Bronik, Chen Jin, Parashkev Nachev, Frederik
  Barkhof, Olga Ciccarelli, and Daniel~C Alexander.
\newblock Learning to segment when experts disagree.
\newblock In {\em International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pages 179--190. Springer, 2020.

\bibitem{zhang2021learning}
Yikai Zhang, Songzhu Zheng, Pengxiang Wu, Mayank Goswami, and Chao Chen.
\newblock Learning with feature-dependent label noise: A progressive approach.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{zhang2021learning3}
Zizhao Zhang and Tomas Pfister.
\newblock Learning fast sample re-weighting without reward data.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 725--734, 2021.

\bibitem{zhang2020distilling}
Zizhao Zhang, Han Zhang, Sercan~O Arik, Honglak Lee, and Tomas Pfister.
\newblock Distilling effective supervision from severe label noise.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9294--9303, 2020.

\bibitem{zheltonozhskii2022contrast}
Evgenii Zheltonozhskii, Chaim Baskin, Avi Mendelson, Alex~M Bronstein, and Or
  Litany.
\newblock Contrast to divide: Self-supervised pre-training for learning with
  noisy labels.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision}, pages 1657--1667, 2022.

\end{thebibliography}
