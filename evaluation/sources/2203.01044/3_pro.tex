







\section{PROBLEM DEFINITION}
We introduce the problem of entity alignment in KGs. 
Conceptually, a KG can be represented as a set of triples $T$, each of which denotes the relation $r_{ij}\in R$ between two entities $x_i\in E$ and $x_j\in E$. 
In this work, we denote a KG as $G=\{E,R,T\}$ where $E$, $R$, and $T$ are its entity set, relation set, and triple set, respectively. 
%For an entity $x \in E$, $\mathcal{N}(x)$ denotes the set of $x$'s 1-hop neighbors and $|\mathcal{N}(x)|$ is the size of this neighbor set. 


Given two KGs, $G_x = \{E_x,R_x,T_x\}$ and $G_y = \{E_y,R_y,T_y\}$, the set of the existing aligned entity pairs is defined as $S = \{(x,y)|x\in E_x, y \in E_y, x\Leftrightarrow y\}$, where $\Leftrightarrow$ represents equivalence. 
The goal of entity alignment between $G_x$ and $G_y$ is to find the equivalent entity from $E_x$ for each entity in $E_y$, if existed.

%The problem of entity alignment is to discover the unique equivalent entities in $KG_2$ for entities in $KG_1$. 

 Recently, a significant line of work has been focusing on embedding-based techniques for aligning entities in the vector space, e.g., training a neural encoder $f$ to project each entity $x \in E$ into a latent space. 
Among these attempts, most of them focus on the (semi-) supervised setting in the sense that part of $S$ is used for training the alignment models~\cite{MTransE,GCN-Align,CEAFF,tang2019bert-int,wu2019relation}. 
Due to the limited alignment labels across KGs in the real world, we instead propose to study to what extent the entity alignment task can be solved in an unsupervised or self-supervised setting, under which none of the existing alignments in $S$ is available. 

 
%\hhy{Should explain that some works claim that they are semi-supervised, but actually they are not ? The so-called semi-supervise is just the split of the training and test set. In fact, all the methods except those who didn't use any labels are supervised, because they used all the trainng labels which is 30\% of all the linking labels}
%Our goal is to conduct entity alignment on two KGs without any seed from $S$.
%\end{problem}




%Conventional embedding-based entity alignment methods are mostly based on supervised or semi-supervised learning~\cite{chen2016multilingual,GCN-Align,CEAFF,tang2019bert-int,wu2019relation}.  
%However, it is often arduously expensive to obtain label data for Web-scale knowledge graphs. 
%which is expensive and unscalable. 
%In this work, %we endeavor to shed some light on 
%we propose to study the potential of 
%aligning entities \textit{without any labels}, that is, self-supervised entity alignment. 

%and achieving even better performance than those supervised ones. 




\hide{%start of hide =--------------------------------------------------------------
\section{PROBLEM DEFINITION}
Define a KG as a graph $G=\{E,R,T\}$, where $e\in E$, $r \in R$, $t\in T$ denote an entity, a relation and a triple respectively. 
$\mathcal{N}(e)$ denotes the set of $e$'s 1-hop neighbors and $|\mathcal{N}(e)|$ is its size. 
Given two KGs, $G_1 = \{E_1,R_1,T_1\}$ and $G_2 = \{E_2,R_2,T_2\}$, define the set of the already aligned entity pairs as $S = \{(e_i,e_j)|e_i\in E_1, e_j \in E_2, e_i\Leftrightarrow e_j\}$, where $\Leftrightarrow$ represents equivalence. 

Entity alignment task is to discover the unique equivalent entities in $KG_2$ for entities in $KG_1$. 
We train a neural network $f$ to encode $e\in E$ into vectors for alignment. 
According to the proportion of the training dataset that is used, we have two different entity alignment settings:
% \indent $\bullet$ {\bf (Semi-) Supervised} setting: part of $S$ is provided as the training data for training $f$.\\
% \indent $\bullet$ {\bf Unsupervised \& Self-supervised} setting: none of $S$ is provided for training $f$. 
\begin{itemize}
    \setlength{\itemsep}{-3pt}
    \setlength{\parsep}{-5pt}
    \setlength{\parskip}{-1pt}
    \item {\bf (Semi-) Supervised} setting: part of $S$ is provided as the training data for training $f$.\\
    \item {\bf Unsupervised \& Self-supervised} setting: none of $S$ is provided for training $f$.
\end{itemize}

%\hhy{Should explain that some works claim that they are semi-supervised, but actually they are not ? The so-called semi-supervise is just the split of the training and test set. In fact, all the methods except those who didn't use any labels are supervised, because they used all the trainng labels which is 30\% of all the linking labels}
%Our goal is to conduct entity alignment on two KGs without any seed from $S$.
%\end{problem}




%Conventional embedding-based entity alignment methods are mostly based on supervised or semi-supervised learning~\cite{chen2016multilingual,GCN-Align,CEAFF,tang2019bert-int,wu2019relation}.  
%However, it is often arduously expensive to obtain label data for Web-scale knowledge graphs. 
%which is expensive and unscalable. 
%In this work, %we endeavor to shed some light on 
%we propose to study the potential of 
%aligning entities \textit{without any labels}, that is, self-supervised entity alignment. 

%and achieving even better performance than those supervised ones. 

}%end of hide =--------------------------------------------------------------