%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Frank-Wolfe

%% Revisiting FW
@inproceedings{jaggi:icml13,
  author    = {Martin Jaggi},
  title     = {Revisiting Frank-Wolfe:
               Projection-Free Sparse Convex Optimization},
  booktitle = {Proceedings of
               the 30th International Conference on Machine Learning,
               {ICML} 2013},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {28},
  pages     = {427--435},
  publisher = {JMLR.org},
  year      = {2013}
}


%% Original FW
@article{marguerite+:nrl56,
  author  = {Frank, Marguerite and Wolfe, Philip},
  title   = {An algorithm for quadratic programming},
  journal = {Naval Research Logistics Quarterly},
  volume  = {3},
  number  = {1‐2},
  pages   = {95-110},
  year    = {1956}
}


%% Away step Frank-Wolfe
@article{guelat+:mp86,
  title   = {Some comments on Wolfe's ‘away step’},
  author  = {Jacques Gu{\'e}lat and Patrice Marcotte},
  journal = {Mathematical Programming},
  year    = {1986},
  volume  = {35},
  pages   = {110-119}
}


%% Sophisticated version of Pairwise FW
@inproceedings{pedregosa+:aistats20,
  author    = {Fabian Pedregosa and
               Geoffrey N{\'{e}}giar and
               Armin Askari and
               Martin Jaggi},
  title     = {Linearly Convergent Frank-Wolfe without Line-Search},
  booktitle = {The 23rd International Conference on
               Artificial Intelligence and Statistics,
               {AISTATS} 2020, 26-28 August 2020,
               Online [Palermo, Sicily, Italy]},
  series    = {Proceedings of Machine Learning Research},
  publisher = {{PMLR}},
  year      = {2020}
}


%% Pairwise FW
%% Lower bound for FW (You can find the reference).
@inproceedings{lacoste-julien+:nips15,
  author    = {Simon Lacoste{-}Julien and
               Martin Jaggi},
  title     = {On the Global Linear Convergence of
               Frank-Wolfe Optimization Variants},
  booktitle = {Advances in Neural Information Processing Systems 28:
               Annual Conference on Neural Information Processing Systems 2015,
               December 7-12, 2015, Montreal, Quebec, Canada},
  pages     = {496--504},
  year      = {2015}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Boosting


%% AdaBoost
@article{freund+:jcss97,
  author  = {Yoav Freund and
             Robert E. Schapire},
  title   = {A Decision-Theoretic Generalization of
             On-Line Learning and an Application to Boosting},
  journal = {J. Comput. Syst. Sci.},
  volume  = {55},
  number  = {1},
  pages   = {119--139},
  year    = {1997}
}


%% LPBoost
@article{demiriz+:ml02,
  author   = {Demiriz, A and Bennett, K P and Shawe-Taylor, J},
  journal  = {Machine Learning},
  keywords = {boosting,linear programming,lpboost,margin},
  number   = {1-3},
  pages    = {225--254},
  title    = {{Linear Programming Boosting via Column Generation}},
  volume   = {46},
  year     = {2002}
}


%% SoftBoost and lower iteration bound for LPBoost
@inproceedings{warmuth+:nips07,
  author    = {Warmuth, M and Glocer, K and R{\"{a}}tsch, G},
  booktitle = {Advances in
               Neural Information Processing Systems 20 (NIPS 2007)},
  keywords  = {boosting,margin,soft margin},
  pages     = {1585--1592},
  title     = {{Boosting Algorithms for Maximizing the Soft Margin}},
  year      = {2007}
}


%% AdaBoost*
@article{ratsch+:jmlr05,
  author  = {R{\"{a}}tsch, Gunnar and Warmuth, Manfred K},
  journal = {Journal of Machine Learning Research},
  pages   = {2131--2152},
  title   = {{Efficient Margin Maximizing with Boosting}},
  volume  = {6},
  year    = {2005}
}


%% FWBoost
@article{wang+:arxiv15,
  title   = { Functional Frank-Wolfe Boosting for General Loss Functions },
  author  = { Chu Wang and Yingfei Wang and E Weinan and Robert E. Schapire },
  journal = { ArXiv },
  year    = { 2015 },
  volume  = { abs/1510.02558 }
}


%% ERLPBoost
@inproceedings{warmuth+:alt08,
  author    = {Manfred K. Warmuth and
               Karen A. Glocer and
               S. V. N. Vishwanathan},
  title     = {Entropy Regularized LPBoost},
  booktitle = {Algorithmic Learning Theory,
               19th International Conference, {ALT}
               2008, Budapest, Hungary, October 13-16, 2008. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {5254},
  pages     = {256--271},
  publisher = {Springer},
  year      = {2008}
}


%% AdaBoost can be seen as an entropy minimization problem
@inproceedings{jyrki+:colt99,
  author    = {Kivinen, Jyrki and Warmuth, Manfred K},
  booktitle = {Proceedings of
               the 12th Annual Conference on Computational Learning Theory},
  pages     = {134--144},
  publisher = {ACM Press, New York, NY},
  title     = {{Boosting as entropy projection}},
  year      = {1999}
}


%% TotalBoost
@inproceedings{warmuth+:icml06,
  author    = {Warmuth, Manfred K and Liao, Jun and R{\"{a}}tsch, Gunnar},
  booktitle = {Proceedings of
               the 23rd international conference
               on Machine learning (ICML '06)},
  pages     = {1001--1008},
  title     = {{Totally corrective boosting algorithms
               that maximize the margin}},
  year      = {2006}
}


%% SS algorithm (conference version)
@inproceedings{shalev-shwartz+:colt08,
  author    = {Shalev-Shwartz, Shai and Singer, Yoram},
  booktitle = {Proceedings of the 21st Conference on Learning Theory (COLT '08)},
  title     = {{On the Equivalence of
               Weak Learnability and Linear Separability:
               New Relaxations and Efficient Boosting Algorithms}},
  year      = {2008}
}


%% SS algorithm (journal version)
@article{shalev-shwartz+:jml10,
  author  = {Shai Shalev{-}Shwartz and
             Yoram Singer},
  title   = {On the equivalence of
             weak learnability and linear separability:
             new relaxations and efficient boosting algorithms},
  journal = {Mach. Learn.},
  volume  = {80},
  number  = {2-3},
  year    = {2010}
}


%% XGBoost
@inproceedings{tianqi+:kdd16,
  author    = {Chen, Tianqi and Guestrin, Carlos},
  title     = {XGBoost: A Scalable Tree Boosting System},
  year      = {2016},
  publisher = {Association for Computing Machinery},
  booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference 
               on Knowledge Discovery and Data Mining},
  pages     = {785–794},
  keywords  = {large-scale machine learning},
  series    = {KDD '16}
}


%% LightGBM
@inproceedings{ke+:nips17,
  author    = {Guolin Ke and
               Qi Meng and
               Thomas Finley and
               Taifeng Wang and
               Wei Chen and
               Weidong Ma and
               Qiwei Ye and
               Tie{-}Yan Liu},
  editor    = {Isabelle Guyon and
               Ulrike von Luxburg and
               Samy Bengio and
               Hanna M. Wallach and
               Rob Fergus and
               S. V. N. Vishwanathan and
               Roman Garnett},
  title     = {LightGBM:
               {A} Highly Efficient Gradient Boosting Decision Tree},
  booktitle = {Advances in Neural Information Processing Systems 30:
               Annual Conference on Neural Information Processing Systems 2017,
               December 4-9, 2017, Long Beach, CA, {USA}},
  pages     = {3146--3154},
  year      = {2017}
}


%% Generalization bound for (hard) margin maximizing boosting
@article{schapire+:as98,
  author   = {Schapire, Robert E.
              and Freund, Yoav
              and Bartlett, Peter
              and Lee, Wen Sun},
  journal  = {The Annals of Statistics},
  keywords = {boosting},
  number   = {5},
  pages    = {1651--1686},
  title    = {{Boosting the margin:
              a new explanation for the effectiveness of voting methods}},
  volume   = {26},
  year     = {1998}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Others

%% UCI dataset
@misc{dua:2017,
  author      = {Dua, Dheeru and Graff, Casey},
  year        = {2017},
  title       = {{UCI} Machine Learning Repository},
  url         = {http://archive.ics.uci.edu/ml},
  institution = {University of California, Irvine,
                 School of Information and Computer Sciences}
}


%% Finding ERM LTF is NP-hard
@article{klaus-uwe+:css95,
  author  = {Klaus{-}Uwe H{\"{o}}ffgen and
             Hans Ulrich Simon and
             Kevin S. Van Horn},
  title   = {Robust Trainability of Single Neurons},
  journal = {J. Comput. Syst. Sci.},
  volume  = {50},
  number  = {1},
  pages   = {114--125},
  year    = {1995}
}


%% Sauer's lemma
@article{sauer:jct72,
  author  = {Norbert Sauer},
  title   = {On the Density of Families of Sets},
  journal = {J. Comb. Theory, Ser. {A}},
  volume  = {13},
  number  = {1},
  pages   = {145--147},
  year    = {1972}
}


%% The value of the growth function for LTF
@article{vapnik:tvp71,
  author   = {Vapnik, V. N. and Chervonenkis, A. Ya.},
  title    = {On the Uniform Convergence of Relative Frequencies of
              Events to their Probabilities},
  journal  = {Theory of Probability and its Applications},
  keywords = {learning-theory svm kernel},
  number   = 2,
  pages    = {264--280},
  volume   = 16,
  year     = 1971
}


%% Massart's lemma
@article{massart:afst00,
  author    = {Massart, Pascal},
  title     = {Some applications of concentration inequalities to statistics},
  journal   = {Annales de la Facult\'e des sciences de Toulouse : 
               Math\'ematiques},
  pages     = {245--303},
  publisher = {Universit\'e Paul Sabatier. Facult\'e des sciences},
  volume    = {Ser. 6, 9},
  number    = {2},
  year      = {2000},
}



%% Generalization error bound based on VC dimension
@book{vapnik:book00,
  author    = {Vladimir Naumovich Vapnik},
  title     = {The Nature of Statistical Learning Theory, Second Edition},
  series    = {Statistics for Engineering and Information Science},
  publisher = {Springer},
  year      = {2000},
}



%% Boosting SVMs
@inproceedings{garcia+:mldm07,
  author    = {Elkin Garc{\'{\i}}a and
               Fernando Lozano},
  editor    = {Petra Perner},
  title     = {Boosting Support Vector Machines},
  booktitle = {Machine Learning and Data Mining in Pattern Recognition,
               5th International Conference, {MLDM} 2007, Leipzig, Germany,
               July 18-20, 2007, Post Proceedings},
  pages     = {153--167},
  publisher = {ibai Publishing},
  year      = {2007},
}


%% ERLP recurrence relation
@article{abe+:ieice01,
  author  = {Naoki Abe and J{un-ichi} Takeuchi and Manfred K. Warmuth},
  title   = {Polynomial Learnability of Stochastic Rules
             with Respect to the {KL}-Divergence and Quadratic Distance},
  journal = {IEICE Transactions on Information and Systems},
  volume  = {E84-D},
  number  = {3},
  year    = {2001},
  pages   = {299--316}
}


%% Convex analysis (Fenchel conjugacy)
@inbook{borwein+:springer06,
  author    = {Jonathan M. Borwein and Adrian S. Lewis},
  title     = {Convex Analysis},
  booktitle = {Convex Analysis and Nonlinear Optimization: Theoryand Examples},
  year      = {2006},
  publisher = {Springer New York},
  pages     = {65--96},
}


%% Bundle method (BMRM)
@article{teo+:jmlr10,
  author    = {Choon Hui Teo and
               S. V. N. Vishwanathan and
               Alexander J. Smola and
               Quoc V. Le},
  title     = {Bundle Methods for Regularized Risk Minimization},
  journal   = {J. Mach. Learn. Res.},
  volume    = {11},
  pages     = {311--365},
  year      = {2010},
}


%% Nu-SVM. An interpretation for the capping parameters.
@article{scholkopf+:nc00,
  author    = {Bernhard Sch{\"{o}}lkopf and
               Alexander J. Smola and
               Robert C. Williamson and
               Peter L. Bartlett},
  title     = {New Support Vector Algorithms},
  journal   = {Neural Comput.},
  volume    = {12},
  number    = {5},
  pages     = {1207--1245},
  year      = {2000},
}


%% Foundations of Machine Learning second edition
@book{mohri+:mitpress18,
  author    = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalker, Amee},
  edition   = {second},
  publisher = {The MIT Press},
  title     = {{Foundation of Machine Learning}},
  year      = {2018}
}


%% Weight pushing
@inproceedings{mohri+:eurospeech01,
  author    = {Mehryar Mohri and
               Michael Riley},
  title     = {A weight pushing algorithm for
               large vocabulary speech recognition},
  booktitle = {{EUROSPEECH} 2001 Scandinavia,
               7th European Conference on Speech Communication
               and Technology, 2nd {INTERSPEECH} Event},
  pages     = {1603--1606},
  publisher = {{ISCA}},
  year      = {2001}
}


@article{herbster+:jmlr01,
  author    = {Herbster, Mark and Warmuth, Manfred K.},
  title     = {Tracking the Best Linear Predictor},
  year      = {2001},
  publisher = {JMLR.org},
  volume    = {1},
  journal   = {J. Mach. Learn. Res.},
  month     = {sep},
  pages     = {281–309},
}
