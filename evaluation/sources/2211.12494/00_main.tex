% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

\input{preambular}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

% % Include other packages here, before hyperref.
% \usepackage{graphicx}
% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{booktabs}
\usepackage{graphicx}
\usepackage{graphbox}
\usepackage{floatrow}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{paralist}

\usepackage{float}
\usepackage{longtable}

% \usepackage[dvipsnames]{xcolor}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{array}
\usepackage{tabularx}
\usepackage{color}
\usepackage{colortbl}
\usepackage{paralist}
\usepackage{dblfloatfix}
\newcolumntype{K}[1]{>{\centering\arraybackslash}p{#1}}
\newcommand{\band}{\rowcolor{gray!20}}
\newcommand{\bandc}{\cellcolor{gray!20}}
\newcolumntype{?}{!{\vrule width 1.5pt}}

% Argument: custom value to use locally for \floatingpenalty inside footnotes
\newcommand*{\mySpecialfootnotes}[1]{%
  \patchcmd{\@footnotetext}{\floatingpenalty\@MM}{\floatingpenalty#1\relax}%
           {}{\errmessage{Couldn't patch \string\@footnotetext}}%
}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\begin{document}

\title{On the Transferability of Visual Features in Generalized Zero-Shot Learning}


\author{Paola Cascante-Bonilla\textsuperscript{$\dagger$} \quad Leonid Karlinsky\textsuperscript{$\ddagger$} \quad James Seale Smith\textsuperscript{$\mathsection$} \quad Yanjun Qi\textsuperscript{$\natural$} \quad Vicente Ordonez\textsuperscript{$\dagger$}\\
\textsuperscript{$\dagger$}Rice University \quad \textsuperscript{$\ddagger$}MIT-IBM Watson AI Lab \quad \textsuperscript{$\mathsection$}Georgia Institute of Technology \quad \textsuperscript{$\natural$}University of Virginia\\
{\tt\small \{pc51, vicenteor\}@rice.com, leonidka@ibm.com, jamessealesmith@gatech.edu, yq2h@virginia.edu}
}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}


Generalized Zero-Shot Learning (GZSL) aims to train a classifier that can generalize to unseen classes, using a set of attributes as auxiliary information, and the visual features extracted from a pre-trained convolutional neural network.
While recent GZSL methods have explored various techniques to leverage the capacity of these features, there has been an extensive growth of representation learning techniques that remain under-explored. 
In this work, we investigate the utility of different GZSL methods when using different feature extractors, and examine how these models' pre-training objectives, datasets, and architecture design affect their feature representation ability.
Our results indicate that 1) methods using generative components for GZSL provide more advantages when using recent feature extractors;
2) feature extractors pre-trained using self-supervised learning objectives combined with cross-entropy and knowledge distillation provide better feature 
representations, increasing up to 15\% performance when used with recent GZSL techniques; 3) specific feature extractors pre-trained with larger datasets do not necessarily boost the performance of GZSL methods. 
In addition, we investigate how GZSL methods fare against CLIP, a more recent multi-modal pre-trained model with strong zero-shot performance. We found that GZSL tasks still benefit from generative-based GZSL methods along with CLIP's internet-scale pre-training to achieve state-of-the-art performance in fine-grained datasets.
We release a modular framework for analyzing representation learning issues in GZSL here: \href{https://github.com/uvavision/TV-GZSL}{https://github.com/uvavision/TV-GZSL}.

\end{abstract}


\input{01_intro}
\input{02_relatedwork}
\input{03_GSZL}
\input{03.1_embedding}
\input{03.2_generative}
\input{03.3_disentanglement}
\input{05.1_datasets}
\input{04_feature_backbones}
\input{04.1_feature_backbones}
\input{4.1.1_results}


\input{06_conclusion}


{\setlength{\parindent}{0cm}
\textbf{Acknowledgements} This material is based upon work supported by the National Science Foundation under Grant No. 2221943 and Grant No. 2201710.
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\input{09.1_appendixA_intro_broaderImpact}
\input{09.2_appendixB_implementation_details}
\input{09.4_appendixD_all_tables}

\end{document}
