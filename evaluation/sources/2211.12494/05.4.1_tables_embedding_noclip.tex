\begin{table*}[!htbp]
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\newcolumntype{Z}{>{\centering\arraybackslash}X}
\centering
\footnotesize
\setlength\tabcolsep{1pt}
\renewcommand{\arraystretch}{1.2}

\begin{tabularx}{\textwidth}{l c l c l c YYY c YYY c YYY}
\toprule

\multicolumn{17}{@{\hskip 0.11in}c}{\bf \shortstack{Embedding Based GZSL Methods\\ CUB\cite{CUB} Dataset}}  \\
\midrule

{\multirow{2}{*}{\bf \shortstack{Dataset\\Pret. on}}}~ &~~~&
{\multirow{2}{*}{\bf \shortstack{Arch\\ Type}}}~ &~~&
{\multirow{2}{*}{\bf Backbone}}~ &~~&
\multicolumn{3}{@{\hskip 0.11in}c}{\bf DEVISE} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf ESZSL} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf ALE} \\

\cmidrule{7-9}\cmidrule{11-13}\cmidrule{15-17}

&& && && \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} \\

\midrule

\multirow{17}{*}{I-1k} & &
\multirow{12}{*}{CNN} & &
RN101 &  & 
61.96 & 23.41 & 33.98 &&
56.53 & 14.70 & 23.34 &&
62.74 & 26.07 & 36.83 \\ 

% RN101$_{\text{FT}}$
&& && RN101+FT &  & 
83.42 & 28.32 & 42.28 &&
81.45 & 16.14 & 26.94 &&
83.04 & 30.36 & 44.46 \\ 

&& && RN50 &  & 
41.32 & 17.31 & 24.39 &&
41.83 & 13.78 & 20.73 &&
45.96 & 24.70 & 32.13 \\ 

&& && RN152 &  &  
45.73 & 19.01 & 26.86 &&
46.39 & 15.49 & 23.23 &&
52.69 & 24.84 & 33.76  \\ 

&& && GoogleNet &  &  
35.57 & 15.10 & 21.20 && 
30.79 & 9.70 & 14.75 && 
36.86 & 17.67 & 23.89  \\ 

&& && VGG16 &  &  
44.11 & 14.93 & 22.30 && 
46.74 & 7.29 & 12.61 && 
45.81 & 18.26 & 26.11  \\ 

&& && Alexnet &  &  
33.57 & 13.04 & 18.78 && 
33.65 & 5.62 & 9.64 && 
33.15 & 14.82 & 20.48  \\ 

&& && Shufflenet &  &  
47.24 & 20.05 & 28.15 && 
22.16 & 12.13 & 15.67 && 
48.15 & 22.18 & 30.37  \\ 

&& && Inceptionv3 &  &  
58.09 & 21.81 & 31.71 && 
48.30 & 12.91 & 20.38 && 
53.11 & 21.52 & 30.63  \\ 

&& && Inceptionv3$_{\text{adv}}$ &  &  
54.84 & 20.86 & 30.22 && 
47.70 & 11.09 & 18.00 && 
59.37 & 20.24 & 30.18  \\ 

\cmidrule{5-17}
&& && RN50-MOCO$^{\dag}$ &  &  
31.26 & 11.39 & 16.70 && 
7.69 & 3.87 & 5.15 && 
32.73 & 15.77 & 21.28  \\ 

&& && RN50-DINO$^{\dag}$ &  &  
63.20 & 25.84 & 36.68 &&
41.65 & 14.64 & 21.67 && 
60.69 & 25.79 & 36.19  \\


\cmidrule{3-17}

&& MLP&&MLP-Mixer && 
19.17 & 7.76 & 11.05 & &
20.50 & 5.53 & 8.71 & &
19.82 & 8.11 & 11.51  \\

\cmidrule{3-17}

&& \multirow{3}{*}{ViT} &&ViT$_{\text{large}}$&&
71.85 & 23.88 & 35.85 & &
\textbf{83.64} & 12.26 & 21.39  & &
72.20 & 23.44 & 35.39  \\

&& &&DeiT$_{\text{base}}$ && 
70.45 & 25.86 & 37.83 & &
60.88 & 16.81 & 26.35  & &
73.88 & 30.88 & 43.55  \\  

&& &&\cellcolor{gray!18}ViTB16-DINO$^{\dag}$&\cellcolor{gray!18}& 
75.50 & \textbf{32.20} & 45.15 &\cellcolor{gray!18} &
\cellcolor{gray!18}70.89 & \cellcolor{gray!18}\textbf{29.06} & \cellcolor{gray!18}\textbf{41.23}  & &
77.21 & \textbf{36.83} & 49.87  \\ 

\midrule

\multirow{5}{*}{I-21k}
&& MLP && 
MLP-Mixer$_{\text{L16}}$ & &
38.46 & 12.02 & 18.32 & &
34.62 & 5.82 & 9.97 & &
41.66 & 10.68 & 17.00  \\

\cmidrule{3-17}

&& \multirow{3}{*}{ViT} && ViT$_{\text{base}}$ & &
84.52 & 26.75 & 40.64 & &
81.33 & 19.57 & 31.55 & &
83.39 & 29.59 & 43.68  \\ 

&& && ViT$_{\text{large}}$ & &
\textbf{85.24} & 25.61 & 39.38 & &
82.47 & 17.53 & 28.92 & &
83.09 & 22.08 & 34.89  \\  

&& && \cellcolor{gray!18}ViT$_{\text{huge}}$ &\cellcolor{gray!18} &
\cellcolor{gray!18}82.78 & \cellcolor{gray!18}31.31 & \cellcolor{gray!18}\textbf{45.44} & &
61.88 & 18.77 & 28.80 &\cellcolor{gray!18} &
\cellcolor{gray!18}\textbf{84.00} & \cellcolor{gray!18}36.05 & \cellcolor{gray!18}\textbf{50.45}  \\ 

\bottomrule
\end{tabularx}
%\vspace{-0.05in}
\caption{Results of Embedding Based Methods for the CUB\cite{CUB} dataset using different features extracted from a diverse set of architecture types pretrained on ImageNet-1k (I-1k) and ImageNet-21k (I-21k)\cite{Imagenet}. These backbones were trained via: supervised and self-supervised (${\dag}$) learning. The bold numbers correspond to the highest scores per column, and the shaded rows correspond to the most performant image feature per method. +FT indicates the features were fine-tuned with the seen classes from the training set. The ViT$_{\text{huge}}$ features pretrained on ImageNet-21k are the best for all the methods using ALE.  
}
\label{tab:cub_embedding_CNN}
% \vspace{-0.1in}
\end{table*}

\begin{table*}[!htbp]
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\newcolumntype{Z}{>{\centering\arraybackslash}X}
\centering
\footnotesize
\setlength\tabcolsep{1pt}
\renewcommand{\arraystretch}{1.2}

\begin{tabularx}{\textwidth}{l c l c l c YYY c YYY c YYY}
\toprule

\multicolumn{17}{@{\hskip 0.11in}c}{\bf \shortstack{Embedding Based GZSL Methods\\ SUN Dataset}}  \\
\midrule

{\multirow{2}{*}{\bf \shortstack{Dataset\\Pret. on}}}~ &~~~~&
{\multirow{2}{*}{\bf \shortstack{Arch\\ Type}}}~ &~~~~&
{\multirow{2}{*}{\bf Backbone}}~ &~~~~&
\multicolumn{3}{@{\hskip 0.11in}c}{\bf DEVISE} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf ESZSL} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf ALE} \\

\cmidrule{7-9}\cmidrule{11-13}\cmidrule{15-17}

&& && && \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} \\

\midrule

\multirow{17}{*}{I-1k} & &
\multirow{12}{*}{CNN} & &
RN101 & &
32.75 & 18.54 & 23.68 && 
28.41 & 13.75 & 18.53 && 
37.13 & 23.68 & 28.92  \\ 

&& &&RN101+FT &  &
34.03 & 19.93 & 25.14 && 
33.18 & 13.82 & 19.51 && 
37.95 & 22.43 & 28.19  \\ 

&& &&RN50 & &
29.84 & 17.43 & 22.01 && 
25.08 & 14.38 & 18.27 && 
33.91 & 23.54 & 27.79  \\ 

&& &&RN152 & &
30.39 & 17.29 & 22.04 && 
26.63 & 15.90 & 19.91 && 
35.70 & 23.40 & 28.27  \\ 

&& &&GoogleNet & &
18.02 & 10.83 & 13.53 && 
17.52 & 9.31 & 12.15 && 
24.88 & 15.76 & 19.30  \\ 

&& &&VGG16 & &
28.91 & 13.06 & 17.99 && 
25.85 & 9.93 & 14.35 && 
31.78 & 20.21 & 24.71  \\ 

&& &&Alexnet & &
19.61 & 9.31 & 12.62 && 
19.03 & 6.88 & 10.10 && 
23.60 & 13.82 & 17.43  \\ 

&& &&Shufflenet & &
0.23 & 0.00 & 0.00 && 
0.74 & 1.74 & 1.03 && 
29.53 & 17.78 & 22.20  \\ 

&& &&Inceptionv3 & &
31.01 & 14.03 & 19.32 && 
25.08 & 11.25 & 15.53 && 
32.29 & 18.47 & 23.50  \\ 

&& &&Inceptionv3$_{\text{adv}}$ & &
27.91 & 15.00 & 19.51 && 
24.69 & 12.08 & 16.23 && 
33.88 & 21.39 & 26.22  \\ 

\cmidrule{5-17}
&& &&RN50-MOCO$^{\dag}$ & &
2.25 & 0.00 & 0.00 && 
3.14 & 3.33 & 3.23 && 
34.92 & 23.33 & 27.98  \\ 

&& &&RN50-DINO$^{\dag}$ & &
32.56 & 19.03 & 24.02 && 
22.48 & 14.65 & 17.74 && 
41.59 & 27.57 & 33.16  \\ 

\cmidrule{3-17}

&& MLP&&MLP-Mixer && 
6.32 & 3.33 & 4.36 & &
6.40 & 2.36 & 3.45 & &
8.29 & 3.96 & 5.36  \\

\cmidrule{3-17}

&& \multirow{3}{*}{ViT} &&\cellcolor{gray!18}ViT$_{\text{large}}$&\cellcolor{gray!18}&
\textbf{52.33} & 24.51 & 33.39 && 
\textbf{44.84} & 18.82 & 26.51 &\cellcolor{gray!18} &
\cellcolor{gray!18}\textbf{59.77} &\cellcolor{gray!18} \textbf{34.10} & \cellcolor{gray!18}\textbf{43.42}  \\

&& &&DeiT$_{\text{base}}$ && 
37.17 & 17.22 & 23.54 & &
28.49 & 12.57 & 17.44 & &
38.37 & 21.53 & 27.58  \\ 

&& &&ViTB16-DINO$^{\dag}$&& 
35.19 & 20.97 & 26.28 & &
32.48 & 16.11 & 21.54 & &
40.89 & 28.40 & 33.52  \\ 

\midrule

\multirow{5}{*}{I-21k}
&& MLP && 
MLP-Mixer$_{\text{L16}}$ & &
24.57 & 11.18 & 15.37 & &
20.74 & 9.24 & 12.78 & &
29.03 & 13.61 & 18.53  \\ 

\cmidrule{3-17}

&& \multirow{3}{*}{ViT} && ViT$_{\text{base}}$ & &
45.19 & 25.07 & 32.25 & &
40.43 & 19.51 & 26.32 & &
52.87 & 31.81 & 39.72  \\ 

&& && \cellcolor{gray!18}ViT$_{\text{large}}$ &\cellcolor{gray!18} &
\cellcolor{gray!18}49.15 &\cellcolor{gray!18} \textbf{25.56} &\cellcolor{gray!18} \textbf{33.63} &\cellcolor{gray!18} &
\cellcolor{gray!18}43.29 &\cellcolor{gray!18} \textbf{19.86} &\cellcolor{gray!18} \cellcolor{gray!18}\textbf{27.23} & &
55.23 & 33.26 & 41.52  \\ 

&& && ViT$_{\text{huge}}$ & &
38.22 & 19.24 & 25.59 & &
31.71 & 18.13 & 23.06 & &
51.55 & 30.07 & 37.98  \\ 

\bottomrule
\end{tabularx}
%\vspace{-0.05in}
\caption{Results of Embedding Based Methods for the SUN dataset using different features extracted from a diverse set of architecture types pretrained on ImageNet-1k (I-1k) and ImageNet-21k (I-21k). These backbones were trained via: supervised and self-supervised (${\dag}$) learning. The bold numbers correspond to the highest scores per column, and the shaded rows correspond to the most performant image feature per method. +FT indicates the features were fine-tuned with the seen classes from the training set. Surprisingly, Shufflenet and RN50-MOCO features seem to be not suited for this dataset, and using ViT$_{\text{large}}$ pretrained on ImageNet-1k features with ALE beat all methods, including it's counterpart pretrained on ImageNet-21k by a reasonable margin (1.9\%). Moreover, using the ViT$_{\text{large}}$ pretrained on ImageNet-21k features beats all other methods when using DEVISE and ESZSL.
}
\label{tab:sun_embedding_CNN}
% \vspace{-0.1in}
\end{table*}

\begin{table*}[!htbp]
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\newcolumntype{Z}{>{\centering\arraybackslash}X}
\centering
\footnotesize
\setlength\tabcolsep{1pt}
\renewcommand{\arraystretch}{1.2}

\begin{tabularx}{\textwidth}{l c l c l c YYY c YYY c YYY}
\toprule

\multicolumn{17}{@{\hskip 0.11in}c}{\bf \shortstack{Embedding Based GZSL Methods\\ AWA2 Dataset}}  \\ 
\midrule

{\multirow{2}{*}{\bf \shortstack{Dataset\\Pret. on}}}~ &~~~~&
{\multirow{2}{*}{\bf \shortstack{Arch\\ Type}}}~ &~~~~&
{\multirow{2}{*}{\bf Backbone}}~ &~~~~&
\multicolumn{3}{@{\hskip 0.11in}c}{\bf DEVISE} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf ESZSL} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf ALE} \\

\cmidrule{7-9}\cmidrule{11-13}\cmidrule{15-17}

&& && && \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} \\

\midrule

\multirow{17}{*}{I-1k} & &
\multirow{12}{*}{CNN} & &
RN101 &&
71.78 & 17.30 & 27.88 & &
88.84 & 4.04 & 7.72 & &
77.59 & 12.15 & 21.01  \\ 

&& &&RN101+FT &&
87.34 & 18.83 & 30.99 & &
93.07 & 6.12 & 11.49 & &
92.64 & 8.25 & 15.16  \\ 

&& &&RN50 &&
86.02 & 19.49 & 31.78 & &
89.05 & 4.75 & 9.02 & &
84.37 & 10.48 & 18.65  \\ 

&& &&\cellcolor{gray!18}RN152 &\cellcolor{gray!18}&
\cellcolor{gray!18}88.30 & \cellcolor{gray!18}\textbf{21.18} & \cellcolor{gray!18}\textbf{34.17} & &
91.31 & 5.94 & 11.15 & &
85.46 & 12.91 & 22.43  \\ 

&& &&GoogleNet &&
68.56 & 17.40 & 27.76 & &
80.11 & 4.26 & 8.10 & &
82.82 & 5.13 & 9.66  \\ 

&& &&VGG16 &&
78.85 & 16.21 & 26.89 & &
90.06 & 3.11 & 6.00 & &
77.34 & 11.52 & 20.06  \\ 

&& &&Alexnet &&
72.91 & 12.17 & 20.86 & &
79.09 & 2.77 & 5.36 & &
79.17 & 6.11 & 11.34  \\ 

&& &&Shufflenet &&
74.74 & 20.04 & 31.61 & &
51.66 & 3.69 & 6.89 & &
80.75 & 8.84 & 15.93  \\ 

&& &&Inceptionv3 &&
74.54 & 8.08 & 14.58 & &
91.49 & 4.43 & 8.46 & &
78.24 & 10.32 & 18.23  \\ 

&& &&Inceptionv3$_{\text{adv}}$ &&
89.33 & 12.14 & 21.38 & &
91.69 & 3.53 & 6.79 & &
82.21 & 8.06 & 14.69  \\ 

\cmidrule{5-17}
&& &&RN50-MOCO$^{\dag}$ &&
78.23 & 11.07 & 19.39 & &
57.62 & 3.73 & 7.01 & &
81.51 & 4.60 & 8.71  \\ 

&& &&RN50-DINO$^{\dag}$ &&
78.97 & 18.11 & 29.46 & &
81.25 & 8.08 & 14.71 & &
82.78 & 7.62 & 13.96  \\

\cmidrule{3-17}

&& MLP&&MLP-Mixer && 
21.06 & 10.87 & 14.34 && 
38.51 & 2.67 & 4.99 && 
94.29 & 12.78 & 22.52  \\ 

\cmidrule{3-17}

&& \multirow{3}{*}{ViT} &&\cellcolor{gray!18}ViT$_{\text{large}}$&\cellcolor{gray!18}&
83.78 & 18.00 & 29.63 &\cellcolor{gray!18}& 
\cellcolor{gray!18}\textbf{97.07} & \cellcolor{gray!18}\textbf{18.62} & \cellcolor{gray!18}\textbf{31.25} & &
92.28 & 13.75 & 23.93  \\

&& &&\cellcolor{gray!18}DeiT$_{\text{base}}$ &\cellcolor{gray!18}& 
\textbf{91.41} & 9.51 & 17.22 & &
94.08 & 2.33 & 4.54 &\cellcolor{gray!18} &
\cellcolor{gray!18}87.37 & \cellcolor{gray!18}\textbf{14.67} & \cellcolor{gray!18}\textbf{25.12}  \\ 

&& &&ViTB16-DINO$^{\dag}$&& 
71.83 & 19.41 & 30.56 & &
92.34 & 5.08 & 9.63 & &
79.73 & 6.55 & 12.10  \\ 

\midrule

\multirow{5}{*}{I-21k}
&& MLP && 
MLP-Mixer$_{\text{L16}}$ & &
82.92 & 10.37 & 18.43 & &
85.48 & 1.47 & 2.90 & &
86.24 & 1.88 & 3.69  \\ 

\cmidrule{3-17}

&& \multirow{3}{*}{ViT} && ViT$_{\text{base}}$ & &
82.35 & 14.05 & 24.00 & &
96.18 & 7.77 & 14.38 & &
\textbf{95.62} & 11.07 & 19.85  \\ 

&& && ViT$_{\text{large}}$ & &
86.49 & 19.53 & 31.87 & &
96.47 & 10.43 & 18.83 & &
95.03 & 12.76 & 22.49  \\ 

&& && ViT$_{\text{huge}}$ & &
80.00 & 12.37 & 21.43 & &
89.57 & 2.55 & 4.95 & &
81.40 & 6.72 & 12.41  \\ 


\bottomrule
\end{tabularx}
%\vspace{-0.05in}
\caption{Results of Embedding Based Methods for the AWA2 dataset using different features extracted from a diverse set of architecture types pretrained on ImageNet-1k (I-1k) and ImageNet-21k (I-21k). These backbones were trained via: supervised and self-supervised (${\dag}$) learning. The bold numbers correspond to the highest scores per column, and the shaded rows correspond to the most performant image feature per method. +FT indicates the features were fine-tuned with the seen classes from the training set. Surprisingly, the most performant visual features are extracted from a RN152 pretrained on ImageNet-1k, using the DEVISE method.
}
\label{tab:awa2_embedding_CNN}
% \vspace{-0.1in}
\end{table*}