% \onecolumn

\section{Ethical Considerations}
\label{ethical}


Machine learning models still require collecting large amounts of annotated data. In the case of fine-grained recognition, these annotations often require specialized human knowledge. Zero-shot learning offers a way for bypassing the need to collect extensive amounts of data for training models for new classes of objects. 
We show that large-scale pre-trained models along with Generalized Zero-Shot Learning methods can obtain results that are competitive with the specialized knowledge from experts on classes that a trained model has never seen. We hope that the key insights and analysis provided in this paper will be useful in expanding and leveraging zero-shot research along with current progress in multi-modal learning. Allowing for the creation of models that do not depend on large amounts of data could be useful for practitioners without access to large scale resources or in domains where data is scarce such as the medical domain. 
