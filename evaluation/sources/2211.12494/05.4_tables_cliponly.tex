%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}[bp]
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\newcolumntype{Z}{>{\centering\arraybackslash}X}
\centering
\footnotesize
%\small
\setlength\tabcolsep{1pt}
\renewcommand{\arraystretch}{1.2}

\begin{tabularx}{\textwidth}{l c YYY c YYY c YYY}
\toprule

 %& \multicolumn{9}{@{\hskip 0.15in}c}{Base training set: R-VQA$_{NC}$ \,+\, H-VQA$_C$ }\\
%\cmidrule[0.5pt]{2-10}

{\multirow{2}{*}{\bf Backbone}}~~~ &~~~~&
\multicolumn{3}{@{\hskip 0.11in}c}{\bf CUB} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf SUN} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf AWA2} \\

\cmidrule{3-5}\cmidrule{7-9}\cmidrule{11-13}

&& \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} \\

\midrule

% RN101 & \multirow{8}{*}{\rotatebox[origin=c]{45}{'This is a photo of a \{\}'}} &&
RN50 &  & 
45.90 & 45.44 & 45.67 &&
44.61 & 48.96 & 46.68 &&
87.86 & 82.48 & 85.08 \\ 

RN101 &  & 
48.86 & 49.44 & 49.15 && 
45.16 & 49.24 & 47.11 && 
88.66 & 84.79 & 86.67 \\ 

RN50x4 &  & 
51.89 & 55.27 & 53.53 && 
48.53 & 50.56 & 49.52 && 
92.09 & 86.52 & 89.22 \\ 

RN50x16 &  & 
56.82 & 55.19 & 55.99 && 
49.07 & 54.44 & 51.62 &&
94.36 & 89.11 & 91.65 \\ 

RN50x64 &  & 
63.81 & 57.19 & 60.32 && 
55.28 & 51.59 & 53.37 && 
95.11 & 90.11 & 92.54 \\ 

ViTB32 &  & 
51.35 & 49.65 & 50.49 && 
48.26 & 50.97 & 49.58 && 
90.99 & 85.69 & 88.26 \\ 

ViTB32$^{\dag}$ &   & 
61.46 & 58.09 & 59.73 && 
50.66 & 53.75 & 52.16 && 
87.84 & 82.12 & 84.88 \\

ViTB16 &  & 
55.76 & 56.23 & 55.99 &&
50.97 & 56.11 & 53.42 && 
93.68 & 87.19 & 90.32 \\ 

ViTL14 &  & 
62.62 & 63.19 & 62.90 &&
55.97 & 58.06 & 56.99 && 
95.80 & 89.39 & 92.48 \\

% ViTL14$^{\dag}$ & & 
% 64.45 & 62.13 & 63.26 && 
% 57.79 & 61.53 & 59.60 && 
% 96.06 & 88.45 & 92.10 \\

\midrule
\band
ViTL14$^{\Uparrow}$ & & 
\textbf{64.45} & \textbf{62.69} & \textbf{63.56} && 
\textbf{57.79} & \textbf{62.64} & \textbf{60.12} && 
\textbf{96.06} & \textbf{89.91} & \textbf{92.88} \\

\bottomrule
\end{tabularx}
%\vspace{-0.05in}
\caption{Results of using publicly available pre-trained CLIP\cite{CLIP} models with different backbones to evaluate three standard GSZL datasets. ${\Uparrow}$ indicates we used a set of captions similar to the proposed by OpenAI to test on Imagenet\cite{Imagenet}, ${\dag}$ indicates the model used was trained on the Laion400M\cite{LAION400M} dataset.
}
\label{tab:all_datasets_clip_only}
\vspace{-0.0in}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{table}[!ht]
%     \centering
%     \begin{tabular}{ll>{\centering\arraybackslash}p{1.25cm}>{\centering\arraybackslash}p{1.25cm}>{\centering\arraybackslash}p{1.25cm}l}
%         \toprule
%         \multicolumn{1}{c}{Dataset} & Backbone & Seen & Unseen & Harmonic & \multicolumn{1}{c}{Caption}  \\ \hline
%         \multirow{10}{*}{OpenAI Dataset} & RN50 & 45.9 & 45.44 & 45.67 & \multirow{8}{*}{'This is a photo of a \{\}'}  \\ 
%         ~ & RN101 & 48.86 & 49.44 & 49.15 &   \\ 
%         ~ & RN50x4 & 51.89 & 55.27 & 53.53 &   \\ 
%         ~ & RN50x16 & 56.82 & 55.19 & 55.99 &   \\ 
%         ~ & RN50x64 & 63.81 & 57.19 & 60.32 &   \\ 
%         ~ & ViTB32 & 51.35 & 49.65 & 50.49 &   \\ 
%         ~ & ViTB16 & 55.76 & 56.23 & 55.99 &   \\ 
%         ~ & ViTL14 & 62.62 & 63.19 & 62.90 &   \\ \cmidrule{2-6}
%         ~ & ViTL14 & 64.45 & 62.13 & 63.26 & 'Image of a \{\}'  \\ \cmidrule{2-6}
%         \band ~ & ViTL14 & \textbf{64.45} & \textbf{62.69} & \textbf{63.56} & Prompts used for Imagenet  \\ \midrule
%         Laion400 Dataset & ViTB32 & 61.46 & 58.09 & 59.73 & 'Image of a \{\}' \\ 
%         \bottomrule
%     \end{tabular}
%     \vspace{0.01in}
%     \caption{}
%     \label{tab:clip_alone_cub}
% \end{table}


% \begin{table}[!ht]
%     \centering
%     \begin{tabular}{ll>{\centering\arraybackslash}p{1.25cm}>{\centering\arraybackslash}p{1.25cm}>{\centering\arraybackslash}p{1.25cm}l}
%         \toprule
%         \multicolumn{1}{c}{Dataset} & Backbone & Seen & Unseen & Harmonic & \multicolumn{1}{c}{Caption} \\ \hline
%         \multirow{10}{*}{OpenAI Dataset} & RN50 & 44.61 & 48.96 & 46.68 & \multirow{8}{*}{'This is a photo of a \{\}'} \\ 
%         ~ & RN101 & 45.16 & 49.24 & 47.11 & ~ \\ 
%         ~ & RN50x4 & 48.53 & 50.56 & 49.52 & ~ \\ 
%         ~ & RN50x16 & 49.07 & 54.44 & 51.62 & ~ \\ 
%         ~ & RN50x64 & 55.28 & 51.59 & 53.37 & ~ \\ 
%         ~ & ViTB32 & 48.26 & 50.97 & 49.58 & ~ \\ 
%         ~ & ViTB16 & 50.97 & 56.11 & 53.42 & ~ \\ 
%         ~ & ViTL14 & 55.97 & 58.06 & 56.99 & ~ \\ \cmidrule{2-6}
%         ~ & ViTL14 & 57.79 & 61.53 & 59.60 &  'Image of a \{\}' \\ \cmidrule{2-6}
%         \band ~ & ViTL14 & \textbf{57.79} & \textbf{62.64} & \textbf{60.12} & Prompts used for Imagenet \\ \midrule
%         laion400 Dataset & ViTB32 & 50.66 & 53.75 & 52.16 &  'Image of a \{\}' \\ 
%         \bottomrule
%     \end{tabular}
%     \vspace{0.01in}
%     \caption{Results of using publicly available pre-trained CLIP models with different backbones with the SUN dataset in the standard GSZL test splits.}
%     \label{tab:clip_alone_sun}
% \end{table}

% \begin{table}[!ht]
%     \newcolumntype{Y}{>{\raggedright\arraybackslash}X}
%     \newcolumntype{Z}{>{\centering\arraybackslash}X}
%     \centering
%     \footnotesize
%     %\small
%     \setlength\tabcolsep{1pt}
%     \renewcommand{\arraystretch}{1.2}

%     \begin{tabular}{ll>{\centering\arraybackslash}p{1.25cm}>{\centering\arraybackslash}p{1.25cm}>{\centering\arraybackslash}p{1.25cm}l}
%         \toprule
%         \multicolumn{1}{c}{Dataset} & Backbone & Seen & Unseen & Harmonic & \multicolumn{1}{c}{Caption} \\ \hline
%         \multirow{10}{*}{OpenAI Dataset} & RN50 & 87.86 & 82.48 & 85.08 & \multirow{8}{*}{'This is a photo of a \{\}'} \\ 
%         ~ & RN101 & 96.06 & 89.91 & 92.88 & ~ \\ 
%         ~ & RN50x4 & 92.09 & 86.52 & 89.22 & ~ \\ 
%         ~ & RN50x16 & 96.06 & 89.91 & 92.88 & ~ \\ 
%         ~ & RN50x64 & 95.11 & 90.11 & 92.54 & ~ \\ 
%         ~ & ViTB32 & 90.99 & 85.69 & 88.26 & ~ \\ 
%         ~ & ViTB16 & 93.68 & 87.19 & 90.32 & ~ \\ 
%         ~ & ViTL14 & 95.80 & 89.39 & 92.48 & ~ \\ \cmidrule{2-6}
%         ~ & ViTL14 & 96.06 & 88.45 & 92.10 &  'Image of a \{\}' \\ \cmidrule{2-6}
%         \band ~ & ViTL14 & \textbf{96.06} & \textbf{89.91} & \textbf{92.88} & Prompts used for Imagenet \\ \midrule
%         laion400 Dataset & ViTB32 & 87.84 & 82.12 & 84.88 &  'Image of a \{\}' \\ 
%         \bottomrule
%     \end{tabular}
%     \vspace{0.01in}
%     \caption{Results of using publicly available pre-trained CLIP models with different backbones with the AWA2 dataset in the standard GSZL test splits.}
%     \label{tab:clip_alone_awa2}
% \end{table}



% ==========================================================================
% ==========================================================================




% ==========================================================================
% ==========================================================================

