\begin{table*}[!htbp]
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\newcolumntype{Z}{>{\centering\arraybackslash}X}
\centering
\footnotesize
\setlength\tabcolsep{1pt}
\renewcommand{\arraystretch}{1.2}

\begin{tabularx}{\textwidth}{l c l c l c YYY c YYY}
\toprule

\multicolumn{13}{@{\hskip 0.11in}c}{\bf \shortstack{Disentanglement Based GZSL Methods\\ CUB Dataset}}  \\ 
\midrule

{\multirow{2}{*}{\bf \shortstack{Dataset\\Pret. on}}}~ &~~~~&
{\multirow{2}{*}{\bf \shortstack{Arch\\ Type}}}~ &~~~~&
{\multirow{2}{*}{\bf Backbone}}~ &~~~~&
\multicolumn{3}{@{\hskip 0.11in}c}{\bf SDGZSL} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf FREE}  \\

\cmidrule{7-9}\cmidrule{11-13}

&& && && \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} \\

\midrule

\multirow{17}{*}{I-1k} & &
\multirow{12}{*}{CNN} & &

RN101 &&
56.41 & 51.89 & 54.06  & ~ &
58.30 & 55.10 & 56.70  \\

&& &&RN101+FT &&
75.00 & 64.26 & 69.21  & ~ &
75.30 & 56.00 & 64.20  \\

&& &&RN50 &&
48.48 & 37.53 & 42.31  & ~ &
48.40 & 41.10 & 44.45  \\

&& &&RN152 &&
48.22 & 43.37 & 45.67  & ~ &
50.70 & 43.90 & 47.10  \\

&& &&GoogleNet &&
32.72 & 32.88 & 32.80  & ~ &
33.78 & 34.34 & 34.06  \\

&& &&VGG16 &&
37.20 & 34.41 & 35.75  & ~ &
30.02 & 40.14 & 34.35  \\

&& &&Alexnet &&
27.12 & 24.98 & 26.01  & ~ &
15.47 & 34.16 & 21.30  \\ 

&& &&Shufflenet &&
47.66 & 38.90 & 42.84  & ~ &
47.65 & 43.64 & 45.56  \\

&& &&Inceptionv3 &&
56.70 & 46.39 & 51.03  & ~ &
61.88 & 44.60 & 51.83  \\ 

&& &&Inceptionv3$_{\text{adv}}$ &&
51.38 & 46.86 & 49.01  & ~ &
60.82 & 42.02 & 49.70  \\

\cmidrule{5-13}
&& &&RN50-MOCO$^{\dag}$ &&
36.67 & 30.22 & 33.14  & ~ &
42.53 & 29.38 & 34.75  \\

&& &&RN50-DINO$^{\dag}$ &&
59.27 & 51.68 & 55.22  & ~ &
66.62 & 53.08 & 59.08  \\ 

\cmidrule{3-13}

&& MLP&&MLP-Mixer && 
17.66 & 16.74 & 17.19  & ~ &
17.59 & 14.43 & 15.85  \\ 

\cmidrule{3-13}

&& \multirow{3}{*}{ViT} &&ViT$_{\text{large}}$&&
74.17 & 63.17 & 68.23  & ~ &
69.53 & 56.38 & 62.27  \\

&& &&DeiT$_{\text{base}}$ && 
62.91 & 54.40 & 58.35  & ~ &
61.80 & 43.80 & 51.27  \\ 

&& &&ViTB16-DINO$^{\dag}$&& 
68.72 & 64.25 & 66.41  & ~ &
73.70 & 53.46 & 61.97  \\

\midrule

\multirow{5}{*}{I-21k}
&& MLP && 
MLP-Mixer$_{\text{L16}}$ & &
33.77 & 26.13 & 29.46  & ~ &
31.58 & 23.61 & 27.02  \\

\cmidrule{3-13}

&& \multirow{3}{*}{ViT} && ViT$_{\text{base}}$ & &
78.01 & 70.10 & 73.84  & ~ &
67.50 & 66.15 & 66.82  \\

&& && ViT$_{\text{large}}$ & &
79.55 & 64.37 & 71.16  & ~ &
73.07 & 52.91 & 61.37  \\

&& && ViT$_{\text{huge}}$ & &
75.05 & 70.58 & 72.75  & ~ &
66.17 & 67.57 & 66.87  \\

&& &&\cellcolor{gray!18} ViT$_{\text{huge}}$+FT &\cellcolor{gray!18} &
\cellcolor{gray!18}\textbf{79.68} &\cellcolor{gray!18} \textbf{73.27} &\cellcolor{gray!18} \textbf{76.34}  &\cellcolor{gray!18} ~ &
\cellcolor{gray!18}\textbf{80.57} &\cellcolor{gray!18} \textbf{69.71} &\cellcolor{gray!18} \textbf{74.75}  \\


\bottomrule
\end{tabularx}
%\vspace{-0.05in}
\caption{Results of Disentanglement Based Methods for the CUB dataset using different features extracted from a diverse set of architecture types pretrained on ImageNet-1k (I-1k) and ImageNet-21k (I-21k). These backbones were trained via: supervised and self-supervised (${\dag}$) learning. The bold numbers correspond to the highest scores per column, and the shaded rows correspond to the most performant image feature per method. +FT indicates the features were fine-tuned with the seen classes from the training set. The most performant visual features are extracted from a ViT$_{\text{huge}}$ pretrained on ImageNet-21k and fine-tuned with the seen classes, using the SDGZSL method.
}
\label{tab:cub_disentanglement_CNN}
% \vspace{-0.1in}
\end{table*}

\begin{table*}[!htbp]
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\newcolumntype{Z}{>{\centering\arraybackslash}X}
\centering
\footnotesize
\setlength\tabcolsep{1pt}
\renewcommand{\arraystretch}{1.2}

\begin{tabularx}{\textwidth}{l c l c l c YYY c YYY}
\toprule

\multicolumn{13}{@{\hskip 0.11in}c}{\bf \shortstack{Disentanglement Based GZSL Methods\\ SUN Dataset}}  \\ 
\midrule

{\multirow{2}{*}{\bf \shortstack{Dataset\\Pret. on}}}~ &~~~~&
{\multirow{2}{*}{\bf \shortstack{Arch\\ Type}}}~ &~~~~&
{\multirow{2}{*}{\bf Backbone}}~ &~~~~&
\multicolumn{3}{@{\hskip 0.11in}c}{\bf SDGZSL} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf FREE}  \\

\cmidrule{7-9}\cmidrule{11-13}

&& && && \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} \\

\midrule

\multirow{17}{*}{I-1k} & &
\multirow{12}{*}{CNN} & &

RN101 &&
36.67 & 44.44 & 40.18  & ~ &
37.20 & 47.40 & 41.70  \\

&& &&RN101+FT &&
38.57 & 49.44 & 43.33  & ~ &
41.12 & 47.01 & 43.87  \\

&& &&RN50 &&
33.33 & 41.87 & 37.12  & ~ &
33.99 & 42.71 & 37.86  \\

&& &&RN152 &&
34.77 & 44.44 & 39.01  & ~ &
35.12 & 48.19 & 40.63  \\

&& &&GoogleNet &&
26.24 & 31.94 & 28.81  & ~ &
26.32 & 35.69 & 30.30  \\

&& &&VGG16 &&
30.81 & 33.82 & 32.25  & ~ &
27.75 & 40.00 & 32.77  \\

&& &&Alexnet &&
22.64 & 25.76 & 24.10  & ~ &
16.09 & 38.75 & 22.73  \\

&& &&Shufflenet &&
31.55 & 36.39 & 33.80  & ~ &
29.03 & 39.44 & 33.45  \\

&& &&Inceptionv3 &&
31.05 & 43.26 & 36.15  & ~ &
28.91 & 46.11 & 35.54  \\ 

&& &&Inceptionv3$_{\text{adv}}$ &&
31.43 & 44.37 & 36.80  & ~ &
35.12 & 38.54 & 36.75  \\

\cmidrule{5-13}
&& &&RN50-MOCO$^{\dag}$ &&
36.16 & 37.85 & 36.99  & ~ &
36.12 & 41.94 & 38.82  \\

&& &&RN50-DINO$^{\dag}$ &&
40.54 & 49.24 & 44.47  & ~ &
42.95 & 50.07 & 46.23  \\

\cmidrule{3-13}

&& MLP&&MLP-Mixer && 
6.94 & 8.40 & 7.60  & ~ &
6.98 & 13.06 & 9.09  \\

\cmidrule{3-13}

&& \multirow{3}{*}{ViT} &&\cellcolor{gray!18}ViT$_{\text{large}}$&\cellcolor{gray!18}&
\cellcolor{gray!18}51.59 &\cellcolor{gray!18} 63.75 &\cellcolor{gray!18} \textbf{57.03}  &\cellcolor{gray!18} ~ &
\cellcolor{gray!18}\textbf{54.15} &\cellcolor{gray!18} 57.22 &\cellcolor{gray!18} \textbf{55.64}  \\

&& &&DeiT$_{\text{base}}$ && 
31.94 & 45.69 & 37.60  & ~ &
36.98 & 43.54 & 39.99  \\

&& &&ViTB16-DINO$^{\dag}$&& 
40.04 & 51.53 & 45.06  & ~ &
39.61 & 53.19 & 45.41  \\

\midrule

\multirow{5}{*}{I-21k}
&& MLP && 
MLP-Mixer$_{\text{L16}}$ & &
19.92 & 32.99 & 24.84  & ~ &
25.23 & 30.63 & 27.67  \\

\cmidrule{3-13}

&& \multirow{3}{*}{ViT} && ViT$_{\text{base}}$ & &
\textbf{51.63} & 55.56 & 53.52  & ~ &
52.29 & 55.90 & 54.03  \\

&& && ViT$_{\text{large}}$ & &
32.13 & \textbf{68.96} & 43.84  & ~ &
49.34 & \textbf{59.44} & 53.92  \\

&& && ViT$_{\text{huge}}$ & &
30.43 & 62.01 & 40.82  & ~ &
44.42 & 50.00 & 47.04  \\

&& && ViT$_{\text{huge}}$+FT & &
39.53 & 47.99 & 43.35  & ~ &
44.57 & 52.22 & 48.10  \\


\bottomrule
\end{tabularx}
%\vspace{-0.05in}
\caption{Results of Disentanglement Based Methods for the SUN dataset using different features extracted from a diverse set of architecture types pretrained on ImageNet-1k (I-1k) and ImageNet-21k (I-21k). These backbones were trained via: supervised and self-supervised (${\dag}$) learning. The bold numbers correspond to the highest scores per column, and the shaded rows correspond to the most performant image feature per method. +FT indicates the features were fine-tuned with the seen classes from the training set. The most performant visual features are extracted from a ViT$_{\text{large}}$ pretrained on ImageNet-1k using the SDGZSL method.
}
\label{tab:sun_disentanglement_CNN}
% \vspace{-0.1in}
\end{table*}

\begin{table*}[!htbp]
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\newcolumntype{Z}{>{\centering\arraybackslash}X}
\centering
\footnotesize
\setlength\tabcolsep{1pt}
\renewcommand{\arraystretch}{1.2}

\begin{tabularx}{\textwidth}{l c l c l c YYY c YYY}
\toprule

\multicolumn{13}{@{\hskip 0.11in}c}{\bf \shortstack{Disentanglement Based GZSL Methods\\ AWA2 Dataset}}  \\ 
\midrule

{\multirow{2}{*}{\bf \shortstack{Dataset\\Pret. on}}}~ &~~~~&
{\multirow{2}{*}{\bf \shortstack{Arch\\ Type}}}~ &~~~~&
{\multirow{2}{*}{\bf Backbone}}~ &~~~~&
\multicolumn{3}{@{\hskip 0.11in}c}{\bf SDGZSL} &~~~~& 
\multicolumn{3}{@{\hskip 0.11in}c}{\bf FREE}  \\

\cmidrule{7-9}\cmidrule{11-13}

&& && && \textit{Seen} & \textit{Novel} & \textit{Harm.} 
&& \textit{Seen} & \textit{Novel} & \textit{Harm.} \\

\midrule

\multirow{17}{*}{I-1k} & &
\multirow{12}{*}{CNN} & &

RN101 &&
75.27 & 58.65 & 65.93  & ~ &
75.22 & \textbf{56.00} & 64.20  \\

&& &&RN101+FT &&
83.99 & 60.35 & 70.24  & ~ &
\textbf{87.66} & 47.56 & 61.67  \\

&& &&RN50 &&
75.25 & 64.99 & 69.75  & ~ &
84.75 & 41.93 & 56.10  \\

&& &&RN152 &&
79.08 & 68.38 & 73.34  & ~ &
86.78 & 50.13 & 63.55  \\

&& &&GoogleNet &&
71.62 & 54.53 & 61.91  & ~ &
72.03 & 49.45 & 58.64  \\

&& &&VGG16 &&
78.12 & 57.02 & 65.93  & ~ &
76.39 & 54.86 & 63.86  \\

&& &&Alexnet &&
61.06 & 49.09 & 54.43  & ~ &
60.53 & 48.34 & 53.76  \\

&& &&Shufflenet &&
74.12 & 52.98 & 61.79  & ~ &
68.45 & 50.69 & 58.25  \\

&& &&Inceptionv3 &&
84.46 & 57.82 & 68.65  & ~ &
84.40 & 43.32 & 57.26  \\

&& &&\cellcolor{gray!18}Inceptionv3$_{\text{adv}}$ &\cellcolor{gray!18}&
80.22 & 57.68 & 67.11  &\cellcolor{gray!18} ~ &
\cellcolor{gray!18}85.38 &\cellcolor{gray!18} 51.71 &\cellcolor{gray!18} \textbf{64.41}  \\

\cmidrule{5-13}
&& &&RN50-MOCO$^{\dag}$ &&
66.26 & 48.95 & 56.31  & ~ &
72.37 & 48.88 & 58.35  \\

&& &&RN50-DINO$^{\dag}$ &&
68.56 & 64.99 & 66.73  & ~ &
74.89 & 52.41 & 61.67  \\

\cmidrule{3-13}

&& MLP&&MLP-Mixer && 
31.69 & 25.2 & 28.07  & ~ &
28.29 & 22.66 & 25.16  \\ 

\cmidrule{3-13}

&& \multirow{3}{*}{ViT} &&\cellcolor{gray!18}ViT$_{\text{large}}$&\cellcolor{gray!18}&
\cellcolor{gray!18}86.87 &\cellcolor{gray!18} \textbf{70.37} &\cellcolor{gray!18} \textbf{77.75}  & ~ &
87.29 & 48.14 & 62.06  \\

&& &&DeiT$_{\text{base}}$ && 
80.13 & 56.06 & 65.96  & ~ &
72.55 & 41.13 & 52.50  \\

&& &&ViTB16-DINO$^{\dag}$&& 
77.10 & 56.00 & 64.88  & ~ &
80.40 & 44.79 & 57.53  \\

\midrule

\multirow{5}{*}{I-21k}
&& MLP && 
MLP-Mixer$_{\text{L16}}$ & &
52.94 & 37.09 & 43.62  & ~ &
72.82 & 37.4 & 49.42  \\

\cmidrule{3-13}

&& \multirow{3}{*}{ViT} && ViT$_{\text{base}}$ & &
\textbf{88.00} & 60.76 & 71.88  & ~ &
77.14 & 48.44 & 59.51  \\

&& && ViT$_{\text{large}}$ & &
86.04 & 64.65 & 73.83  & ~ &
80.58 & 43.4 & 56.42  \\

&& && ViT$_{\text{huge}}$ & &
83.33 & 62.74 & 71.58  & ~ &
87.43 & 43.28 & 57.90  \\

&& && ViT$_{\text{huge}}$+FT & &
76.94 & 58.43 & 66.42  & ~ &
82.36 & 43.10 & 56.59  \\


\bottomrule
\end{tabularx}
%\vspace{-0.05in}
\caption{Results of Disentanglement Based Methods for the AWA2 dataset using different features extracted from a diverse set of architecture types pretrained on ImageNet-1k (I-1k) and ImageNet-21k (I-21k). These backbones were trained via: supervised and self-supervised (${\dag}$) learning. The bold numbers correspond to the highest scores per column, and the shaded rows correspond to the most performant image feature per method. +FT indicates the features were fine-tuned with the seen classes from the training set. The most performant visual features are extracted from a ViT$_{\text{large}}$ pretrained on ImageNet-1k using the SDGZSL method.
}
\label{tab:awa2_disentanglement_CNN}
% \vspace{-0.1in}
\end{table*}