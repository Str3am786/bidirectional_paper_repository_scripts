% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Caesar.2020}
H.~Caesar, V.~Bankiti \emph{et~al.}, ``nuscenes: A multimodal dataset for
  autonomous driving,'' in \emph{2020 IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2020, pp. 11\,618--11\,628.

\bibitem{Buchholz.2020}
M.~Buchholz, F.~Gies \emph{et~al.}, ``Automation of the unicaragil vehicles,''
  in \emph{29th Aachen Colloquium}, 2020, pp. 1531--1560.

\bibitem{Woopen.2018}
T.~Woopen, B.~Lampe \emph{et~al.}, ``Unicaragil - disruptive modular
  architectures for agile, automated vehicle concepts,'' in \emph{27th Aachen
  Colloquium}, 2018, pp. 663--694.

\bibitem{Bieder.2020}
F.~Bieder, S.~Wirges \emph{et~al.}, ``Exploiting multi-layer grid maps for
  surround-view semantic segmentation of sparse lidar data,'' in \emph{2020
  IEEE Intelligent Vehicles Symposium (IV)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2020.

\bibitem{Richter.2020}
S.~Richter, J.~Beck \emph{et~al.}, ``Semantic evidential grid mapping based on
  stereo vision,'' in \emph{2020 IEEE International Conference on Multisensor
  Fusion and Integration for Intelligent Systems (MFI)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2020.

\bibitem{vanKempen.2021b}
R.~{van Kempen}, B.~Lampe \emph{et~al.}, ``A simulation-based end-to-end
  learning framework for evidential occupancy grid mapping,'' in \emph{2021
  IEEE Intelligent Vehicles Symposium (IV)}, 2021, pp. 934--939.

\bibitem{Lampe.2020}
B.~Lampe, R.~{van Kempen} \emph{et~al.}, ``Reducing uncertainty by fusing
  dynamic occupancy grid maps in a cloud-based collective environment model,''
  in \emph{2020 IEEE Intelligent Vehicles Symposium (IV)}, 2020, pp. 837--843.

\bibitem{Thrun.2005}
S.~Thrun, W.~Burgard, and D.~Fox, \emph{Probabilistic robotics}, ser.
  Intelligent robotics and autonomous agents.\hskip 1em plus 0.5em minus
  0.4em\relax Cambridge, Mass.: {MIT Press}, 2005.

\bibitem{Nuss.2018}
D.~Nuss, S.~Reuter \emph{et~al.}, ``A random finite set approach for dynamic
  occupancy grid maps with real-time application,'' \emph{The International
  Journal of Robotics Research}, vol.~37, no.~8, pp. 841--866, 2018.

\bibitem{Bauer.2019b}
D.~Bauer, L.~Kuhnert, and L.~Eckstein, ``Deep, spatially coherent inverse
  sensor models with uncertainty incorporation using the evidential
  framework,'' in \emph{2019 IEEE Intelligent Vehicles Symposium (IV)}, 2019,
  pp. 2490--2495.

\bibitem{Lee.03.08.2020}
K.-H. Lee, M.~Kliemann \emph{et~al.}, ``Pillarflow: End-to-end birds-eye-view
  flow estimation for autonomous driving,'' 03.08.2020.

\bibitem{Fei.2021b}
J.~Fei, K.~Peng \emph{et~al.}, ``Pillarsegnet: Pillar-based semantic grid map
  estimation using sparse lidar data,'' in \emph{2021 IEEE Intelligent Vehicles
  Symposium (IV)}, 2021, pp. 838--844.

\bibitem{Schreiber.2021b}
M.~Schreiber, V.~Belagiannis \emph{et~al.}, ``Dynamic occupancy grid mapping
  with recurrent neural networks,'' in \emph{2021 IEEE International Conference
  on Robotics and Automation (ICRA)}, 2021, pp. 6717--6724.

\bibitem{Elfes.1989}
A.~Elfes, ``Using occupancy grids for mobile robot perception and navigation,''
  \emph{Computer}, vol.~22, no.~6, pp. 46--57, 1989.

\bibitem{Wirges.2018}
S.~Wirges, C.~Stiller, and F.~Hartenbach, ``Evidential occupancy grid map
  augmentation using deep learning,'' in \emph{2018 IEEE Intelligent Vehicles
  Symposium (IV 2018)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp.
  668--673.

\bibitem{Dequaire.2018}
J.~Dequaire, P.~Ondr{\'u}{\v{s}}ka \emph{et~al.}, ``Deep tracking in the wild:
  End-to-end tracking using recurrent neural networks,'' \emph{The
  International Journal of Robotics Research}, vol.~37, no. 4-5, pp. 492--512,
  2018.

\bibitem{Filatov.2020}
A.~Filatov, A.~Rykov, and V.~Murashkin, ``Any motion detector: Learning
  class-agnostic scene dynamics from a sequence of lidar point clouds,'' in
  \emph{2020 IEEE International Conference on Robotics and Automation
  (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 9498--9504.

\bibitem{Wu.2020}
P.~Wu, S.~Chen, and D.~N. Metaxas, ``Motionnet: Joint perception and motion
  prediction for autonomous driving based on bird's eye view maps,'' in
  \emph{2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  2020, pp. 11\,382--11\,392.

\bibitem{Shepel.2021}
I.~Shepel, V.~Adeshkin \emph{et~al.}, ``Occupancy grid generation with dynamic
  obstacle segmentation in stereo images,'' \emph{IEEE Transactions on
  Intelligent Transportation Systems}, pp. 1--11, 2021.

\bibitem{Shafer.1976}
G.~Shafer, \emph{A mathematical theory of evidence}, ser. Limited paperback
  editions.\hskip 1em plus 0.5em minus 0.4em\relax Princeton, NJ: {Princeton
  Univ. Press}, 1976, vol.~42.

\bibitem{Jsang.2016}
A.~J{\o}sang, \emph{Subjective Logic}.\hskip 1em plus 0.5em minus 0.4em\relax
  Cham: {Springer International Publishing}, 2016.

\bibitem{Sensoy.2018}
M.~Sensoy, L.~Kaplan, and M.~Kandemir, ``Evidential deep learning to quantify
  classification uncertainty,'' in \emph{Advances in Neural Information
  Processing Systems 31 (NeurIPS 2018)}, 2018, pp. 3179--3189.

\bibitem{Shafer.2016}
G.~Shafer, ``Dempster's rule of combination,'' \emph{International Journal of
  Approximate Reasoning}, vol.~79, pp. 26--40, 2016.

\bibitem{Reiher.2020}
L.~Reiher, B.~Lampe, and L.~Eckstein, ``A sim2real deep learning approach for
  the transformation of images from multiple vehicle-mounted cameras to a
  semantically segmented image in bird's eye view,'' in \emph{2020 IEEE 23rd
  International Conference on Intelligent Transportation Systems (ITSC)}, 2020,
  pp. 1--7.

\bibitem{.2021f}
{Zeng Yihan, Chunwei Wang, Yunbo Wang, Hang Xu, Chaoqiang Ye, Zhen Yang, Chao
  Ma}, ``Learning transferable features for point cloud detection via 3d
  contrastive co-training,'' in \emph{Advances in Neural Information Processing
  Systems}, 2021, vol.~34.

\bibitem{VirtualTestDrive.2022}
\BIBentryALTinterwordspacing
{VIRES Simulationstechnologie GmbH}, ``Virtual test drive,'' 2022. [Online].
  Available: \url{https://vires.mscsoftware.com/}
\BIBentrySTDinterwordspacing

\bibitem{Manivasagam.2020}
S.~Manivasagam, S.~Wang \emph{et~al.}, ``Lidarsim: Realistic lidar simulation
  by leveraging the real world,'' in \emph{2020 IEEE/CVF Conference on Computer
  Vision and Pattern Recognition (CVPR)}, 2020, pp. 11\,164--11\,173.

\bibitem{Lang.2019b}
A.~H. Lang, S.~Vora \emph{et~al.}, ``Pointpillars: Fast encoders for object
  detection from point clouds,'' in \emph{2019 IEEE/CVF Conference on Computer
  Vision and Pattern Recognition (CVPR)}, 2019, pp. 12\,689--12\,697.

\end{thebibliography}
