\section{Related Work}

From the early inception of the \emph{k-means} algorithm for clustering \citep{Lloyd1982}, there has been much methodological improvement on this unsupervised task.
This includes methods that perform clustering in the latent space of (variational) autoencoders \citep{Aljalbout2018} or use a mixture of autoencoders for the clustering \citep{Zhang2017a, Locatello2018}.
The method most related to our work is the VQ-VAE \citep{Oord2017}, which can be seen as a special case of our framework (see above).
Its authors have put a stronger focus on the discrete representation as a form of compression instead of clustering.
Hence, our model and theirs differ in certain implementation considerations (see Sec.\ \ref{sec:non-differentiability}).
All these methods have in common that they only yield a single number as a cluster assignment and provide no interpretable structure of relationships between clusters.

The self-organizing map (SOM) \citep{Kohonen1998}, however, is an algorithm that provides such an interpretable structure.
It maps the data manifold to a lower-dimensional discrete space, which can be easily visualized in the 2D case.
It has been extended to model dynamical systems \citep{Barreto2004} and combined with probabilistic models for time series \citep{Sang2008}, although without using learned representations.
There are approaches to turn the SOM into a ``deeper'' model \citep{Dittenbach2000}, combine it with multi-layer perceptrons \citep{Furukawa2005} or with metric learning \citep{Ponski2014}.
However, it has (to the best of our knowledge) not been proposed to use SOMs in the latent space of (variational) autoencoders or any other form of unsupervised deep learning model.

Interpretable models for clustering and temporal predictions are especially crucial in fields where humans have to take responsibility for the model's predictions, such as in health care.
The prediction of a patient's future state is an important problem, particularly on the \emph{intensive care unit} (ICU) \citep{Harutyunyan2017, Badawi2018}.
Probabilistic models, such as Gaussian processes, have been successfully applied in this domain \citep{Colopy2016, Schulam2016}.
Recently, deep generative models have been proposed \citep{Hyland2017}, sometimes even in combination with probabilistic modeling \citep{Lim2018}.
To the best of our knowledge, SOMs have only been used to learn interpretable static representations of patients \citep{Tirunagari2015}, but not dynamic ones.