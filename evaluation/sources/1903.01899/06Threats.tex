\section{Threats to Validity}
\label{section: threats}

In this section, we discuss the threats that could affect the validity of our study.

\paragraph{Construct Validity} Threats to construct validity concern the relation between theory and observation. In our context, this could refer to the reliability of the oracle used to train and evaluate the different approaches investigated in this work. Instances of God Class extracted from HIST and DECOR replication packages have been filtered before being incorporated in our oracle. Furthermore, both papers have been awarded by the community, which confirms the quality of the processes conducted to produce these instances. For Feature Envy, we followed a strict blind procedure where each instance has been investigated by three different persons. However, we can not exclude the possibility of some missed occurrences or false positives. Another threat is related to the replication of some of the competitive approaches. We followed rigorously the guidelines provided by the respective authors, and performed an additional parameter tuning for each approach whenever necessary. However, some differences may remain between our respective implementations.

\paragraph{Internal Validity} Threats to internal validity concern all the factors that could have impacted our results. In our context, this could refer to the training procedure presented in Section~\ref{subsection: training}. Even though we compared the proposed procedure with conventional techniques while performing preliminary experiments, we did not report the results of our comparisons. Hence, a comparative study of the proposed procedure with conventional optimization approaches would be desirable. Note that these techniques are in fact part of the approach we propose and are necessary to train models on real imbalanced datasets. Another threat is related to choice of the machine-learning based classifier (MLP) used in our method. We plan to investigate the use of different machine-learning algorithms to perform aggregation. Finally, to train the competing ensemble method ASCI, we first performed an hyper-parameter tuning of this approach rigorously identical to that of \NAME{} and used the same boosting technique.

\paragraph{External Validity} Threats to external validity concern the generalizability of our findings. To reduce this threat, we experimented our method on a reasonable number of systems (8). Furthermore, the software systems used for evaluation have different domains, origins, sizes and history lengths. However, further evaluation of our approach on a larger set of systems would be desirable. Another threat could be related to the choice of the detection tools chosen to be aggregated. As explained in Section~\ref{subsection: overview} we selected these tools because they are based on different strategies, and thus, are more likely to have complementary results. However, we cannot assert that using \NAME{} to aggregate other detection tools would led to similar results.