\section{Background and Related Work}
\label{section: related work}
This section defines the anti-patterns considered in this study and discusses prior detection approaches proposed in literature, as well as ensemble methods.
\subsection{Definitions}
\subsubsection{God Class}
A God Class or Blob, is a class that tends to centralize most of the system's intelligence, and implements a high number of responsibilities.
It is characterized by the presence of a large number of attributes, methods and dependencies with data classes (i.e., classes only used to store data in the form of attributes that can be accessed via getters and setters). Thus, assigning much of the work to a single class, delegating only minor operations to other small classes causes a negative impact on program comprehension \cite{abbes2011empirical} and reusability. The alternative refactoring operation commonly applied to remove this anti-pattern is called Extract Class Refactoring and consists in splitting the affected God Class into several more cohesive smaller classes \cite{Fowler1999}.

\subsubsection{Feature Envy}
A method that is more interested in the data of another class (the envied class) than that of the class it is actually in. This anti-pattern represents a symptom of the method's misplacement, and is characterized by a lot of accesses to foreign attributes and methods. The main consequences are an increase of coupling and a reduction of cohesion, because the affected method often implements responsibilities more related to the envied class with respect to the methods of its own class. This anti-pattern is commonly removed using Move Method Refactoring, which consists in moving all or parts of the affected method to the envied class \cite{Fowler1999}.

\subsection{Rule Based Approaches}
The first attempts to detect components affected by anti-patterns have focused on the definition of rule-based approaches which rely on some metrics to capture deviations from good object-oriented design principles.
First, Marinescu \cite{marinescu2004detection} presented \textit{detection strategy}, a metric-based mechanism for analyzing source code models and detect design fragments. They illustrate this methodology step by step by defining the detection strategy for God Class. Later, Lanza and Marinescu \cite{lanza2007object} formulated the detection strategies for 11 anti-patterns by designing a set of metrics, along with thresholds, for each anti-pattern. These metric--threshold pairs are then logically combined using AND/OR operators to create the final detection rule. These heuristics have been implemented inside Eclipse plug-ins such as \textit{InCode} \cite{marinescu2010incode}.

Similar to the approach described above, Moha et al.~\cite{Moha10-TSE-DECOR} proposed DECOR (DEtection and CORrection of Design Flaws) which relies on a systematic analysis of the definitions of code and design smells in the literature. They propose templates and a grammar to encode these smells and generate detection algorithms automatically. They applied their approach to four design anti-patterns (God Class, Functional  Decomposition, Spaghetti Code, and Swiss Army Knife) and their 15 underlying code smells. Their detection approach takes the form of a ``Rule Card'' that encodes the formal definition of design anti-patterns and code smells. In this context, the identification of components affected by a God Class is based on both structural and lexical information.


Other approaches rely on the identification of refactoring opportunities to detect anti-patterns. Based on this consideration, instances of a given anti-pattern can be detected in a system by looking at the opportunities to apply the corresponding refactoring operation. In this context, Fokaefs et al.~\cite{fokaefs2012identification} proposed an approach to detect God Classes in a system by suggesting a set of Extract Class Refactoring operations. This set of refactoring opportunities is generated in two main steps. First, they identify cohesive clusters of entities (i.e., attributes and methods) in each class of the system, that could then be extracted as separate classes. To do so, the Jaccard distance is computed among each class members (i.e., entities). The Jaccard distance between two entities $e_{i}$ and $e_{j}$ measures the dissimilarity between their respective \textit{``entity sets''} $S_{i}$ and $S_{j}$ and is computed as follows:
\begin{equation}
\label{jaccard entity to entity}
dist(e_{i}, e_{j}) = 1 - \frac{|S_{i} \cap S_{j}|}{|S_{i} \cup S_{j}|}
\end{equation}
For a method, the \textit{``entity set''} contains the entities accessed by the method, and for an attribute, it contains the methods accessing this attribute. Then, cohesive groups of entities are identified using a hierarchical agglomerative algorithm on the information previously generated. In the second step, the potential classes to be extracted are filtered using a set of rules, to ensure that the behavior of the original program is preserved.
Later, this approach has been implemented as an Eclipse plug-in called \textit{JDeodorant} \cite{fokaefs2011jdeodorant}.

Similarly, methods that can potentially be moved to another class are presented to the software engineer as potential Feature Envy methods. In this context, Tsantalis and Chatzigeorgiou~\cite{tsantalis2009identification} proposed an approach for automatic suggestions of Move Method Refactoring. First, for each method $m$ in the system, a set of candidate target classes $T$ is created by examining the entities that are accessed in the body of $m$. Second, $T$ is sorted according to two criteria: (1) the number of entities that $m$ accesses from each target class of $T$ in descending order and; (2) the Jaccard distance from $m$ to each target class in ascending order if $m$ accesses an equal number of entities from two or more classes. In this context, the Jaccard distance between an entity $e$ and a class $C$ is computed as follows:
\begin{equation}
\label{jaccard entity to class}
dist(e, C) = 1 - \frac{|S_{e} \cap S_{C}|}{|S_{e} \cup S_{C}|} \quad \textrm{where} \quad S_{c} = \bigcup_{e \in C} \{e\}
\end{equation}
With $S_{e}$ the entity set of a method defined in Equation~\ref{jaccard entity to entity}.
Third, $T$ is filtered under the condition that $m$ must modify at least one data structure in the target class. Fourth, they suggest to move $m$ to the first target class in $T$ that satisfies a set of preconditions related to compilation, behavior, and quality. This algorithm is also implemented in the Eclipse plug-in \textit{JDeodorant} \cite{fokaefs2007jdeodorant}.

Anti-patterns can also impact how source code entities evolve with one another over time, when changes are applied to the system. Based on such consideration, Palomba et al.~\cite{PalombaBPOLP13,Palomba15} proposed HIST (Historical Information for Smell deTection), an approach to detect anti-patterns using historical information derived from version control systems (e.g., Git, SVN). They applied their approach to the detection of five anti-patterns: Divergent Change, Shotgun Surgery, Parallel Inheritance, God Class and Feature Envy. The detection process followed by HIST consists of two steps. First, historical information is extracted from versioning systems using a component called the \textit{change history extractor} which outputs the sequence of changes applied to source code entities (i.e., classes or methods) through the history of the system. Second, a set of rules is applied to this so produced sequence to identify occurrences of anti-patterns. For instance, Feature Envy methods are identified as those ``\textit{involved in commits with methods of another class of the system $\beta$ \% more than in commits with methods of their class}''. The value of $\beta$ being set to 80\% after parameters calibration.

\subsection{Machine Learning Based Approaches}
Kreimer~\cite{kreimer2005adaptive} proposed the use of decision trees to identify occurrences of God Class and Long Method. Their model relies on the number of fields, number of methods, and number of statements as decision criteria for God Class detection and have been evaluated on two small systems (IYC and WEKA). This observation has been confirmed 10 years later by Amorim et al.~\cite{amorim2015experience} who extended this approach to 12 anti-patterns.

Khomh et al.~\cite{khomh2009bayesian, khomh2011bdtex} presented BDTEX (Bayesian Detection Expert), a metric based approach to build Bayesian Belief Networks from the definitions of anti-patterns. This approach has been validated on three different anti-patterns (God Class, Functional Decomposition, and Spaghetti Code) and provides a probability that a given entity is affected instead of a boolean value like other approaches. Following, Vaucher et al.~\cite{vaucher2009tracking} relied on Bayesian Belief Networks to track the evolution of the``godliness'' of a class and thus, distinguishing real God Classes from those that are so by design.

Maiga et al.~\cite{maiga2012smurf,maiga2012support} introduced SVMDetect, an approach based on Support Vector Machines to detect four well known anti-patterns: God Class, Functional Decomposition, Spaghetti code, and Swiss Army Knife. The input vector fed into their classifier for God Class detection is composed of 60 structural metrics computed using the PADL meta-model~\cite{gueheneuc2005ptidej}.

Fontana et al.~\cite{fontana2016comparing} performed the largest experiment on the effectiveness of machine learning algorithms for smell detection. They conducted a study where 16 different machine learning algorithms were implemented (along with their boosting variant) for the detection of four smells (Data Class, God Class, Feature Envy, and Long Method) on 74 software systems belonging to the \texttt{Qualitas Corpus} dataset \cite{tempero2010qualitas}. The experiments have been conducted using a set of independent metrics related to class, method, package and project level as input information and the datasets used for training and evaluation have been filtered using an under-sampling technique (i.e., instances have been removed from the original dataset) to avoid the poor performances commonly reported from machine learning models on imbalanced datasets. Their study concluded that the algorithm that performed the best for both God Class and Feature Envy was the J48 decision tree algorithm with an F-measure close to 100\%. However, Di Nucci et al.~\cite{di2018detecting} replicated their study and highlighted many limitations. In particular, the way the datasets used in this study have been constructed is strongly discussed and the performances achieved after replication were far from those originally reported.

More recently, Liu et al.~\cite{liu2018deep} proposed a deep learning based approach to detect Feature Envy. Their approach relies on both structural and lexical information. On one side, the names of the method, the enclosing class (i.e., where the method is implemented) and the envied class are fed into convolutional layers. On the other side, the distance presented in Equation~\ref{jaccard entity to class} is computed for both the enclosing class ($dist(m, ec)$) and the target class ($dist(m, tc)$), and values are fed into other convolutional layers. Then the output of both sides is fed into fully-connected layers to perform classification. To train and evaluate their model, they use an approach similar to Moghadam and Ó Cinnéide~\cite{moghadam2012automated} where labeled samples are automatically generated from open-source applications by the injection of affected methods. These methods assumed to be correctly placed in the original systems are extracted and moved into random classes to produce artificial Feature Envy occurrences (i.e., misplaced methods).

\subsection{Ensemble Methods}
Ensemble methods aim at aggregating multiple classifiers in order to improve the classification performances. Ensemble methods are commonly used in the literature as Boosting techniques \cite{rokach2010ensemble}, i.e., a function is applied to the output of various machine-learning based classifiers trained independently. We found no existing ensemble method proposed for anti-patterns detection, as most of the existing detection approaches rely on manually defined rules. However, two ensemble methods proposed in the context of Bug prediction can be applied to our problem. These methods aim at aggregating the output of multiple machine-learning based classifiers (e.g., Support Vector Machine, Multi-layer Perceptron, Decision Tree) trained to predict the bug-proneness of software components.

First, Liu et al.~\cite{liu2010evolutionary} proposed Validation and Voting, which consists in considering a majority vote over the outputs of the classifiers. Second, Di Nucci et al.~\cite{di2017dynamic} proposed ASCI (Adaptive Selection of Classifiers in bug predIction), an adaptive method which uses a decision tree algorithm to dynamically predict which classifier is the best for each code component to be classified. The workflow of ASCI is organised as follows: Given a training set $T$ of instances (i.e., code components) and their associated labels (i.e., buggy or not buggy), each classifier is experimented against $T$. Then a new training set $T^{*}$ is created by labelling each input instance with the information about the classifier which correctly identified its bug-proneness. Then a decision tree is trained on $T^{*}$ to predict the best classifier for each input instance.    
