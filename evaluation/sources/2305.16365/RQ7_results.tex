\subsection*{\textbf{\RQseven}}

We first request our participants to detail the review process of their project before we gauge their perceptions about how CI may influence the code review process.
	Our participants highlight that the projects have specific \textit{review strategies}\textsuperscript{(184)} that are followed. Examples of these strategies are \textit{peer review}\textsuperscript{(109)} and \textit{expert review}.\textsuperscript{(11)} Additionally, review processes have to be mindful of \textit{quality assurance metrics}.\textsuperscript{(130)} Table \ref{tab:projects_reviewing_process} shows the frequency of codes generated from the responses of our participants.

	% Table generated by Excel2LaTeX from sheet 'Q22'
	\begin{table}
		\centering
		\caption{Frequency of citations for each theme and code related to review processes.}
		\begin{tabular}{cp{13.0em}cc}
			\hline
			\multicolumn{1}{c}{\multirow{2}[4]{*}{\textbf{Theme}}} & \multirow{2}[4]{*}{\textbf{Code}} & \multicolumn{2}{p{10em}}{\textbf{Frequency}} \bigstrut\\
			\cline{3-4}          & \multicolumn{1}{c}{} & \multicolumn{1}{p{5em}}{\textbf{Frequency per code}} & \multicolumn{1}{p{5em}}{\textbf{Frequency per theme}} \bigstrut\\
			\hline
			\multicolumn{1}{c}{\multirow{9}[18]{*}{\parbox{3cm}{\centering \textbf{Project review strategy}}}} & Peer review & 109   & \multirow{9}[18]{*}{184} \bigstrut\\
			\cline{2-3}          & GitHub standard review & 37    &  \bigstrut\\
			\cline{2-3}          & Expert review & 11    &  \bigstrut\\
			\cline{2-3}          & Ad-hoc code review process & 9     &  \bigstrut\\
			\cline{2-3}          & Review checklist & 5     &  \bigstrut\\
			\cline{2-3}          & Development branch review & 5     &  \bigstrut\\
			\cline{2-3}          & Project goals & 3     &  \bigstrut\\
			\cline{2-3}          & Mailing list discussion & 3     &  \bigstrut\\
			\cline{2-3}          & Pair programming & 2     &  \bigstrut\\

			\hline
			\multicolumn{1}{c}{\multirow{11}[22]{*}{\parbox{3cm}{\centering \textbf{Quality assurance metrics}}}} & CI check & 44    & \multirow{11}[22]{*}{130} \bigstrut\\
			\cline{2-3}          & Tests verification & 38    &  \bigstrut\\
			\cline{2-3}          & Code style & 20    &  \bigstrut\\
			\cline{2-3}          & Proper documentation & 7     &  \bigstrut\\
			\cline{2-3}          & Linter check & 6     &  \bigstrut\\
			\cline{2-3}          & Security & 3     &  \bigstrut\\
			\cline{2-3}          & Data coverage check & 3     &  \bigstrut\\
			\cline{2-3}          & Efficiency check & 3     &  \bigstrut\\
			\cline{2-3}          & Avoiding conflicts & 2     &  \bigstrut\\
			\cline{2-3}          & Code line inspection & 2     &  \bigstrut\\
			\cline{2-3}          & Error detection & 2     &  \bigstrut\\
			\hline
			NA    &     &     & 92 \bigstrut\\
			\hline
		\end{tabular}%
		\label{tab:projects_reviewing_process}%
	\end{table}%

	\textit{Peer review}\textsuperscript{(109)} and \textit{CI check}\textsuperscript{(44)} are the most frequently mentioned codes. 
	\textit{Peer review} is the process of manually checking violations of code standards and logical errors in a patch submitted by developers~\citep{rahman2017impact}. In the existing literature, peer review has been demonstrated to be effective for improving design quality and the overall quality of software projects \citep{rahman2017impact}. 
	In a similar vein, many quotes\textsuperscript{(109)} from our participants highlight the use of peer review in their projects. For example, C420 states that in the \textit{dropwizard} project, \textit{``All changes are reviewed by one or two peers depending on self-assessed complexity of the change''}.
	Other developers state that their projects follow the \textit{GitHub standard review}\textsuperscript{(37)} flow. For instance, C308 states: \textit{``We use GitHub flow, open PR, require review(s), review with suggestions or concerns, discuss and revise if needed and review again, then merge.''} 

	We also identify more specific review strategies in some projects, e.g., \textit{review checklist},\textsuperscript{(5)} \textit{development branch review},\textsuperscript{(5)} \textit{project goals},\textsuperscript{(3)} \textit{mailing list discussion}\textsuperscript{(3)} and \textit{pair programming}.\textsuperscript{(2)} For instance, when talking about the \textit{review checklist}, C203 states that \textit{``Code review occurs when a PR is opened. We have a checklist for both the reviewer and committer to go through for each change. Tests run on each PR and the tests need to pass before a change can be merged.''} Additionally, the submitted PR should be aligned with the project goals, as explained by 
	C129 when declaring that \textit{``The reviewer should read and understand all of the changes, and the changes should be in-line with the project's conventions and goals.''}	We also receive 9 responses in which participants do not identify a specific review process in their projects. These participants state that their projects follow an \textit{ad-hoc code review process}.

	The \textit{quality assurance metrics}\textsuperscript{(130)} theme has also been frequently cited by our participants when explaining the review process of their projects. Indeed, improving the quality of patches to software projects is one of the main motivators of modern code review \citep{bacchelli2013expectations, bavota2015four}. When observing quality assurance metrics, reviewers often use the results of \textit{CI checks}\textsuperscript{(44)} to ensure the quality of submitted PRs. Other verifications are frequently mentioned by participants when checking code quality, e.g., \textit{tests verification},\textsuperscript{(38)} \textit{code style},\textsuperscript{(20)} and \textit{proper documentation}.\textsuperscript{(7)} Project maintainers, in general, rely on automated tools to support the process of code review \citep{Vasilescu2015-tn}. CI is often used in popular open-source projects to check whether the PR breaks the build. Moreover, CI verifies whether the tests pass and automatically checks whether the PR matches the project style guide \citep{cassee2020silent}. According to C160, \textit{``If CI is green and PR looks sane, merge.''} Additionally, C408 explains that, in their project, the review process also has to \textit{``check CI jobs (lint, test, build).''} 

	\begin{center}
		\begin{tabular}{|p{.95\columnwidth}|}
			\hline
			\textit{Our participants perceive that their projects have specific code review strategies (e.g., peer review and expert review). Moreover, the review process of our participants' projects rely on quality assurance verification (e.g., CI check, code style, proper documentation).}\\
			\hline
		\end{tabular}
	\end{center}

\vspace{2mm}
\noindent\textbf{The perceived impact of CI on the project review process}
\vspace{2mm}

	\textit{\textbf{Most of our participants' quotes (58\%, \nicefrac{335}{578}) agree that CI influences the review process of software projects.}} Among the 578 quotes related to the influence of CI on the code review process, we observe that the majority (58\%, \nicefrac{335}{578}) state that CI has some influence on the code review process. 15\% (\nicefrac{87}{578}) of quotes state that CI has no influence on code review, while 27\% (\nicefrac{156}{578}) of quotes did not express a clear position.

	\textit{Automation}\textsuperscript{(139)} is the most cited code when it comes to how CI influences code review. As expressed by C100, \textit{``It made it [the code review process] more efficient because the amount of manual testing that needs to happen reduced a lot. It also democratized the process, so the whole team is able to get started doing reviews.''} 
	Indeed, automated processes (as brought by CI) are often combined with manual code reviews made by the quality assurance team \citep{rahman2017impact}. The infrastructure of CI is frequently used with automated builds and quality checks, involving static analysis tools and automated testing  \citep{zampetti2019study}. In that respect, our participants argue that CI influences code reviews because reviewers enjoy a \textit{better focus}\textsuperscript{(25)} during the review, e.g., a better focus on the code logic, security, and design. C352 elaborates on this focus when stating the following: \textit{``We try to use linters/style checkers to remove the style nit part of the code review process. It means we spent more time thinking about the architecture and logic vs. the formatting''}.

	In addition, reviewers can have a better focus on specific checks because of the \textit{PR filtering}\textsuperscript{(51)} process promoted by the use of CI. The process of PR filtering reduces the reviewers' burden by filtering out PRs that break the build. For instance, 
	C059 highlights that \textit{``we do not even start reviews before CI is green.''} The study by \cite{zampetti2019study} reveals that PRs with green builds have slightly more chances to get merged than broken builds, although other process-related factors have a stronger correlation with the merge process. Table \ref{tab:impact_of_CI_on_reviewing_process} shows the complete list of codes related to how CI influences code review processes.

	% Table generated by Excel2LaTeX from sheet 'Q23'
	\begin{table}
		\centering
		\caption{Frequency of citations for each theme and code related to the impact of CI on review processes.}
		\begin{tabular}{p{11.0em}p{12.5em}cc}
			\hline
			\multirow{2}[4]{*}{\textbf{Theme}} & \multirow{2}[4]{*}{\textbf{Code}} & \multicolumn{2}{p{11.25em}}{\textbf{Frequency}} \bigstrut\\
			\cline{3-4}    \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{p{5.915em}}{\textbf{Frequency per code}} & \multicolumn{1}{p{5.335em}}{\textbf{Frequency per theme}} \bigstrut\\
			\hline
			\multirow{2}[2]{*}{\parbox{3cm}{\centering \textbf{CI does not influence code review}}} & \multirow{2}[2]{*}{} & \multirow{2}[2]{*}{} & \multirow{2}[2]{*}{87} \bigstrut[t]\\
			\multicolumn{1}{c}{} & \multicolumn{1}{c}{} &       &  \bigstrut[b]\\
			\hline
			\multirow{11}[22]{*}{\parbox{3cm}{\centering \textbf{CI impacts code review}}} & Automation & 139   & \multirow{11}[22]{*}{335} \bigstrut\\
			\cline{2-3}    \multicolumn{1}{c}{} & PR filtering & 51    &  \bigstrut\\
			\cline{2-3}    \multicolumn{1}{c}{} & Higher confidence & 43    &  \bigstrut\\
			\cline{2-3}    \multicolumn{1}{c}{} & Better focus & 25    &  \bigstrut\\
			\cline{2-3}    \multicolumn{1}{c}{} & Faster review & 15    &  \bigstrut\\
%			\cline{2-3}    \multicolumn{1}{c}{} & CI indicator availability & 12     &  \bigstrut\\
% 	        MERGING CI INDICATOR AVAILABILITY WITH CI INDICATOR Earlier feedback
			\cline{2-3}    \multicolumn{1}{c}{} & Earlier feedback & 38    &  \bigstrut\\
			\cline{2-3}    \multicolumn{1}{c}{} & Less review workload & 7     &  \bigstrut\\
			\cline{2-3}    \multicolumn{1}{c}{} & Regression identification & 4     &  \bigstrut\\
%			\cline{2-3}    \multicolumn{1}{c}{} & Awareness & 4     &  \bigstrut\\
% 	        MERGING AWARENESS WITH CI INDICATOR AVAILABILITY
			\cline{2-3}    \multicolumn{1}{c}{} & Easier to reference failure & 3     &  \bigstrut\\
%			\cline{2-3}    \multicolumn{1}{c}{} & Easier review & 3     &  \bigstrut\\
% 	        MERGING Easier review WITH Faster review
			\cline{2-3}    \multicolumn{1}{c}{} & Improved testability & 4     &  \bigstrut\\
%			\cline{2-3}    \multicolumn{1}{c}{} & Faster merging & 2     &  \bigstrut\\
% 	        MERGING Faster merging WITH Faster review
			\cline{2-3}    \multicolumn{1}{c}{} & Smaller PR granularity & 6     &  \bigstrut\\
%			\cline{2-3}    \multicolumn{1}{c}{} & Improved code quality & 1     &  \bigstrut\\
			\hline
			{\centering NA}    &     &    & 156 \bigstrut\\
			\hline
		\end{tabular}%
		\label{tab:impact_of_CI_on_reviewing_process}%
	\end{table}%

	\textit{Higher confidence}\textsuperscript{(43)} is recurrently cited when it comes to how CI influences code review.  
	C370 argues that, with CI, there is a \textit{``reduced time of the code review because you are more confident the PR works and focus more on code quality during the review than checking the logic.''} Another important point offered by CI within the reviewer tasks is the \textit{earlier feedback}\textsuperscript{(26)} of the proposed PRs. 
	C316 argues that CI \textit{``increased the speed [of code review], as certain issues are pointed out immediately''}.

	\textit{\textbf{Although most of the quotes related to RQ7 agree that CI influences code review, still, 15\% (\nicefrac{87}{578}) of quotes state that CI has no influence on code review processes.}} 
	For instance, C215 perceives that CI influences the release process of software projects, but does not influence code review, \textit{``I think CI does not have much to do with code review speed. Reviewers only receive one bit of information from CI, and they are expected to look at the code carefully, not the CI results. But the project manager tends to be more confident in releasing new versions with CI enabled''}.

	\begin{center}
		\begin{tabular}{|p{.96\columnwidth}|}
			\hline
			\textbf{Summary:}
			\textit{Most participants agree that CI influences code review processes. 58\% (\nicefrac{335}{578}) of the quotes related to CI and code review agree that CI has an impact on code review. According to participants, automation is a key aspect of CI that speeds up code review.}\\
			\textbf{Implications:}
			\textit{CI may quicken the process of sorting which PRs are worth reviewing, e.g., a PR with green build status, which may improve the decision-making process of software projects.}
			\\
			\hline
		\end{tabular}
	\end{center}