\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{alshammari2022long}
Shaden Alshammari, Yu-Xiong Wang, Deva Ramanan, and Shu Kong.
\newblock Long-tailed recognition via weight balancing.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2022.

\bibitem{antoniou2017data}
Antreas Antoniou, Amos Storkey, and Harrison Edwards.
\newblock Data augmentation generative adversarial networks.
\newblock {\em arXiv}, 2017.

\bibitem{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock {\em arXiv preprint arXiv:1907.02893}, 2019.

\bibitem{azizi2023synthetic}
Shekoofeh Azizi, Simon Kornblith, Chitwan Saharia, Mohammad Norouzi, and
  David~J Fleet.
\newblock Synthetic data from diffusion models improves imagenet
  classification.
\newblock {\em arXiv preprint arXiv:2304.08466}, 2023.

\bibitem{bahng2020learning}
Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo, and Seong~Joon Oh.
\newblock Learning de-biased representations with biased representations.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  528--539. PMLR, 2020.

\bibitem{ben2009robust}
Aharon Ben-Tal, Laurent El~Ghaoui, and Arkadi Nemirovski.
\newblock {\em Robust optimization}, volume~28.
\newblock Princeton university press, 2009.

\bibitem{cao2019learning}
Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma.
\newblock Learning imbalanced datasets with label-distribution-aware margin
  loss.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2019.

\bibitem{chen2023fantasia3d}
Rui Chen, Yongwei Chen, Ningxin Jiao, and Kui Jia.
\newblock Fantasia3d: Disentangling geometry and appearance for high-quality
  text-to-3d content creation.
\newblock {\em arXiv preprint arXiv:2303.13873}, 2023.

\bibitem{chen2015webly}
Xinlei Chen and Abhinav Gupta.
\newblock Webly supervised learning of convolutional networks.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2015.

\bibitem{chen2022imagine}
Xiaohua Chen, Yucan Zhou, Dayan Wu, Wanqian Zhang, Yu Zhou, Bo Li, and Weiping
  Wang.
\newblock Imagine by reasoning: A reasoning-based implicit semantic data
  augmentation for long-tailed classification.
\newblock In {\em AAAI Conference on Artificial Intelligence (AAAI)}, 2022.

\bibitem{chuang2021fair}
Ching-Yao Chuang and Youssef Mroueh.
\newblock Fair mixup: Fairness via interpolation.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2021.

\bibitem{cui2021parametric}
Jiequan Cui, Zhisheng Zhong, Shu Liu, Bei Yu, and Jiaya Jia.
\newblock Parametric contrastive learning.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2021.

\bibitem{cui2019class}
Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie.
\newblock Class-balanced loss based on effective number of samples.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2019.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2009.

\bibitem{dosovitskiy2015flownet}
Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Hausser, Caner Hazirbas,
  Vladimir Golkov, Patrick Van Der~Smagt, Daniel Cremers, and Thomas Brox.
\newblock Flownet: Learning optical flow with convolutional networks.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2015.

\bibitem{10.1145/2783258.2783311}
Michael Feldman, Sorelle~A. Friedler, John Moeller, Carlos Scheidegger, and
  Suresh Venkatasubramanian.
\newblock Certifying and removing disparate impact.
\newblock In {\em KDD}, page 259–268, 2015.

\bibitem{geirhos2020shortcut}
Robert Geirhos, J{\"o}rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel,
  Wieland Brendel, Matthias Bethge, and Felix~A Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock {\em Nature Machine Intelligence}, 2020.

\bibitem{han2022realflow}
Yunhui Han, Kunming Luo, Ao Luo, Jiangyu Liu, Haoqiang Fan, Guiming Luo, and
  Shuaicheng Liu.
\newblock Realflow: Em-based realistic optical flow dataset generation from
  videos.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2022.

\bibitem{hardt2016equality}
Moritz Hardt, Eric Price, and Nati Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2016.

\bibitem{he2009learning}
Haibo He and Edwardo~A Garcia.
\newblock Learning from imbalanced data.
\newblock {\em IEEE Transactions on knowledge and data engineering},
  21:1263--1284, 2009.

\bibitem{he2022synthetic}
Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song
  Bai, and Xiaojuan Qi.
\newblock Is synthetic data from generative models ready for image recognition?
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2023.

\bibitem{huang2019deep}
Chen Huang, Yining Li, Chen~Change Loy, and Xiaoou Tang.
\newblock Deep imbalanced learning for face recognition and attribute
  prediction.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence
  (TPAMI)}, 42(11):2781--2794, 2019.

\bibitem{hwang2022selecmix}
Inwoo Hwang, Sangjun Lee, Yunhyeok Kwak, Seong~Joon Oh, Damien Teney, Jin-Hwa
  Kim, and Byoung-Tak Zhang.
\newblock Selecmix: Debiased learning by contradicting-pair sampling.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem{idrissi2022simple}
Badr~Youbi Idrissi, Martin Arjovsky, Mohammad Pezeshki, and David Lopez-Paz.
\newblock Simple data balancing achieves competitive worst-group-accuracy.
\newblock In {\em Conference on Causal Learning and Reasoning}, pages 336--351,
  2022.

\bibitem{jahanian2021generative}
Ali Jahanian, Xavier Puig, Yonglong Tian, and Phillip Isola.
\newblock Generative models as a data source for multiview representation
  learning.
\newblock {\em International Conference on Learning Representations (ICLR)},
  2022.

\bibitem{jiang2021self}
Ziyu Jiang, Tianlong Chen, Bobak~J Mortazavi, and Zhangyang Wang.
\newblock Self-damaging contrastive learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2021.

\bibitem{jung2022learning}
Sangwon Jung, Sanghyuk Chun, and Taesup Moon.
\newblock Learning fair classifiers with partially annotated group labels.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2022.

\bibitem{jung2023reweighting}
Sangwon Jung, Taeeon Park, Sanghyuk Chun, and Taesup Moon.
\newblock Re-weighting based group fairness regularization via classwise robust
  optimization.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2023.

\bibitem{kamiran2012data}
Faisal Kamiran and Toon Calders.
\newblock Data preprocessing techniques for classification without
  discrimination.
\newblock {\em Knowledge and information systems}, 33:1--33, 2012.

\bibitem{kim2020m2m}
Jaehyung Kim, Jongheon Jeong, and Jinwoo Shin.
\newblock M2m: Imbalanced classification via major-to-minor translation.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2020.

\bibitem{kim2022learning}
Nayeong Kim, Sehyun Hwang, Sungsoo Ahn, Jaesik Park, and Suha Kwak.
\newblock Learning debiased classifier with biased committee.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem{kirichenko2023last}
Polina Kirichenko, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Last layer re-training is sufficient for robustness to spurious
  correlations.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2023.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{lee2021learning}
Jungsoo Lee, Eungyeup Kim, Juyoung Lee, Jihyeon Lee, and Jaegul Choo.
\newblock Learning debiased representation via disentangled feature
  augmentation.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  volume~34, 2021.

\bibitem{lee2022surgical}
Yoonho Lee, Annie~S Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao, Percy Liang,
  and Chelsea Finn.
\newblock Surgical fine-tuning improves adaptation to distribution shifts.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2022.

\bibitem{li2021self}
Tianhao Li, Limin Wang, and Gangshan Wu.
\newblock Self supervision to distillation for long-tailed visual recognition.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2021.

\bibitem{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2017.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2014.

\bibitem{liu2021just}
Evan~Z Liu, Behzad Haghgoo, Annie~S Chen, Aditi Raghunathan, Pang~Wei Koh,
  Shiori Sagawa, Percy Liang, and Chelsea Finn.
\newblock Just train twice: Improving group robustness without training group
  information.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2021.

\bibitem{liu2015deep}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 3730--3738, 2015.

\bibitem{liu2019large}
Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella~X
  Yu.
\newblock Large-scale long-tailed recognition in an open world.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2019.

\bibitem{mayer2016large}
Nikolaus Mayer, Eddy Ilg, Philip Hausser, Philipp Fischer, Daniel Cremers,
  Alexey Dosovitskiy, and Thomas Brox.
\newblock A large dataset to train convolutional networks for disparity,
  optical flow, and scene flow estimation.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2016.

\bibitem{LfF}
Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin.
\newblock Learning from failure: Training debiased classifier from biased
  classifier.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem{nam2022spread}
Junhyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin.
\newblock Spread spurious attribute: Improving worst-group accuracy with
  spurious attribute estimation.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2022.

\bibitem{narayanan2018translation}
Arvind Narayanan.
\newblock Translation tutorial: 21 fairness definitions and their politics.
\newblock In {\em FAccT}, volume 1170, 2018.

\bibitem{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
  Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock {\em International Conference on Machine Learning (ICML)}, 2022.

\bibitem{oh2018learning}
Tae-Hyun Oh, Ronnachai Jaroensri, Changil Kim, Mohamed Elgharib, Fr'edo Durand,
  William~T Freeman, and Wojciech Matusik.
\newblock Learning-based video motion magnification.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2018.

\bibitem{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem{pan2021dual}
Liyuan Pan, Shah Chowdhury, Richard Hartley, Miaomiao Liu, Hongguang Zhang, and
  Hongdong Li.
\newblock Dual pixel exploration: Simultaneous depth estimation and image
  restoration.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4340--4349, 2021.

\bibitem{park2022majority}
Seulki Park, Youngkyu Hong, Byeongho Heo, Sangdoo Yun, and Jin~Young Choi.
\newblock The majority can help the minority: Context-rich minority
  oversampling for long-tailed classification.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2022.

\bibitem{poole2023dreamfusion}
Ben Poole, Ajay Jain, Jonathan~T. Barron, and Ben Mildenhall.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2023.

\bibitem{raj2023dreambooth3d}
Amit Raj, Srinivas Kaza, Ben Poole, Michael Niemeyer, Ben Mildenhall, Nataniel
  Ruiz, Shiran Zada, Kfir Aberman, Michael Rubenstein, Jonathan Barron,
  Yuanzhen Li, and Varun Jampani.
\newblock Dreambooth3d: Subject-driven text-to-3d generation.
\newblock 2023.

\bibitem{ren2020balanced}
Jiawei Ren, Cunjun Yu, Xiao Ma, Haiyu Zhao, Shuai Yi, et~al.
\newblock Balanced meta-softmax for long-tailed visual recognition.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem{roh2020fairbatch}
Yuji Roh, Kangwook Lee, Steven~Euijong Whang, and Changho Suh.
\newblock Fairbatch: Batch selection for model fairness.
\newblock {\em International Conference on Learning Representations (ICLR)},
  2021.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2022.

\bibitem{ruiz2022dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and
  Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for
  subject-driven generation.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2023.

\bibitem{ryou2019anchor}
Serim Ryou, Seong-Gyun Jeong, and Pietro Perona.
\newblock Anchor loss: Modulating loss scale based on prediction difficulty.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2019.

\bibitem{sagawa2019distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock {\em International Conference on Learning Representations (ICLR)},
  2020.

\bibitem{sagawa2020investigation}
Shiori Sagawa, Aditi Raghunathan, Pang~Wei Koh, and Percy Liang.
\newblock An investigation of why overparameterization exacerbates spurious
  correlations.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2020.

\bibitem{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L
  Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim
  Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem{sambasivan2021everyone}
Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen
  Paritosh, and Lora~M Aroyo.
\newblock “everyone wants to do the model work, not the data work”: Data
  cascades in high-stakes ai.
\newblock In {\em proceedings of the 2021 CHI Conference on Human Factors in
  Computing Systems}, 2021.

\bibitem{samuel2021distributional}
Dvir Samuel and Gal Chechik.
\newblock Distributional robustness loss for long-tail learning.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2021.

\bibitem{sandfort2019data}
Veit Sandfort, Ke Yan, Perry~J Pickhardt, and Ronald~M Summers.
\newblock Data augmentation using generative adversarial networks (cyclegan) to
  improve generalizability in ct segmentation tasks.
\newblock {\em Scientific reports}, 9:16884, 2019.

\bibitem{scimeca2022iclr}
Luca Scimeca, Seong~Joon Oh, Sanghyuk Chun, Michael Poli, and Sangdoo Yun.
\newblock Which shortcut cues will dnns choose? a study from the
  parameter-space perspective.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2022.

\bibitem{shen2016relay}
Li Shen, Zhouchen Lin, and Qingming Huang.
\newblock Relay backpropagation for effective learning of deep convolutional
  neural networks.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2016.

\bibitem{sun2021autoflow}
Deqing Sun, Daniel Vlasic, Charles Herrmann, Varun Jampani, Michael Krainin,
  Huiwen Chang, Ramin Zabih, William~T Freeman, and Ce Liu.
\newblock Autoflow: Learning a better training set for optical flow.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2021.

\bibitem{tartaglione2021end}
Enzo Tartaglione, Carlo~Alberto Barbano, and Marco Grangetto.
\newblock End: Entangling and disentangling deep representations for bias
  correction.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pages 13508--13517, 2021.

\bibitem{teney2020unshuffling}
Damien Teney, Ehsan Abbasnejad, and Anton van~den Hengel.
\newblock Unshuffling data for improved generalization in visual question
  answering.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  pages 1417--1427, 2021.

\bibitem{tian2020contrastive}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive multiview coding.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2020.

\bibitem{trabucco2023effective}
Brandon Trabucco, Kyle Doherty, Max Gurinas, and Ruslan Salakhutdinov.
\newblock Effective data augmentation with diffusion models.
\newblock {\em arXiv}, 2023.

\bibitem{tran2017bayesian}
Toan Tran, Trung Pham, Gustavo Carneiro, Lyle Palmer, and Ian Reid.
\newblock A bayesian data augmentation approach for learning deep models.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2017.

\bibitem{vapnik1999nature}
Vladimir Vapnik.
\newblock {\em The nature of statistical learning theory}.
\newblock Springer science \& business media, 1999.

\bibitem{wang2021longtailed}
Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella Yu.
\newblock Long-tailed recognition by routing diverse distribution-aware
  experts.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2021.

\bibitem{WelinderEtal2010}
P. Welinder, S. Branson, T. Mita, C. Wah, F. Schroff, S. Belongie, and P.
  Perona.
\newblock {Caltech-UCSD Birds 200}.
\newblock Technical Report CNS-TR-2010-001, California Institute of Technology,
  2010.

\bibitem{whang2021responsible}
Steven~Euijong Whang, Ki~Hyun Tae, Yuji Roh, and Geon Heo.
\newblock Responsible ai challenges in end-to-end machine learning.
\newblock {\em arXiv preprint arXiv:2101.05967}, 2021.

\bibitem{yao2022improving}
Huaxiu Yao, Yu Wang, Sai Li, Linjun Zhang, Weixin Liang, James Zou, and Chelsea
  Finn.
\newblock Improving out-of-distribution robustness via selective augmentation.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  25407--25437. PMLR, 2022.

\bibitem{yebin2023textmania}
Moon Ye-Bin, Jisoo Kim, Hongyeob Kim, Kilho Son, and Tae-Hyun Oh.
\newblock Textmania: Enriching visual feature by text-driven manifold
  augmentation.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2023.

\bibitem{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2019.

\bibitem{zeng2022fair}
Xianli Zeng, Edgar Dobriban, and Guang Cheng.
\newblock Fair bayes-optimal classifiers under predictive parity.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem{zhang2017mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{zhang2022correct}
Michael Zhang, Nimit~S Sohoni, Hongyang~R Zhang, Chelsea Finn, and Christopher
  R{\'e}.
\newblock Correct-n-contrast: A contrastive approach for improving robustness
  to spurious correlations.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2022.

\bibitem{zhang2023deep}
Yifan Zhang, Bingyi Kang, Bryan Hooi, Shuicheng Yan, and Jiashi Feng.
\newblock Deep long-tailed learning: A survey.
\newblock 2023.

\bibitem{zhang2021datasetgan}
Yuxuan Zhang, Huan Ling, Jun Gao, Kangxue Yin, Jean-Francois Lafleche, Adela
  Barriuso, Antonio Torralba, and Sanja Fidler.
\newblock Datasetgan: Efficient labeled data factory with minimal human effort.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2021.

\bibitem{zhifei2017cvpr}
Zhifei Zhang, Yang Song, and Hairong Qi.
\newblock Age progression/regression by conditional adversarial autoencoder.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2017.

\bibitem{zheng2017unlabeled}
Zhedong Zheng, Liang Zheng, and Yi Yang.
\newblock Unlabeled samples generated by gan improve the person
  re-identification baseline in vitro.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2017.

\end{thebibliography}
