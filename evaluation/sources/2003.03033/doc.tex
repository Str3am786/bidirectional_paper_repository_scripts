
\documentclass{article}  % sysml

\usepackage{booktabs}
\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
% \usepackage[accepted]{sysml2019}
\usepackage[accepted]{mlsys2020}
% \usepackage{sysml2019}


\newcommand{\npapers}{\text{81 }}
\newcommand{\rawnpapers}{81}

% \usepackage{flafter}  %

% \usepackage[sorting=ynt]{biblatex}
% \usepackage[sorting=ynt]{natbib}
% \usepackage[sort]{natbib}
% \DeclareSortingScheme{noneyear}{
%  \sort{\citeorder}
%  \sort{\field{year}}
% }

% \usepackage[sorting=ynt]{natbib}

\input{setup.tex}

% optional custom title for header
% \sysmltitlerunning{What is the State of Neural Network Pruning?}
\mlsystitlerunning{What is the State of Neural Network Pruning?}

\begin{document}

\twocolumn[
% ================================================================
\mlsystitle{What is the State of Neural Network Pruning?}
% \mlsystitle{Have We Actually Learned Anything about Pruning Neural Networks?}

\mlsyssetsymbol{equal}{*}
\begin{mlsysauthorlist}
\mlsysauthor{Davis Blalock}{equal,csail}
\mlsysauthor{Jose Javier Gonzalez Ortiz}{equal,csail}
\mlsysauthor{Jonathan Frankle}{csail}
\mlsysauthor{John Guttag}{csail}
\end{mlsysauthorlist}

\mlsysaffiliation{csail}{MIT CSAIL, Cambridge, MA, USA}
\mlsyscorrespondingauthor{Davis Blalock}{dblalock@mit.edu}

% apparently these only show up in pdf metadata, not document
\mlsyskeywords{Deep Learning, Pruning}

% \vskip 0.3in
\vskip 0.2in

% ------------------------------------------------
\begin{abstract}
% ------------------------------------------------

Neural network pruning---the task of reducing the size of a network by removing parameters---has been the subject of a great deal of work in recent years. We provide a meta-analysis of the literature, including an overview of approaches to pruning and consistent findings in the literature. After aggregating results across \npapers papers and pruning hundreds of models in controlled conditions, our clearest finding is that the community suffers from a lack of standardized benchmarks and metrics.
This deficiency is substantial enough that it is hard to compare pruning techniques to one another or determine how much progress the field has made over the past three decades.
To address this situation, we identify issues with current practices, suggest concrete remedies, and introduce ShrinkBench, an open-source framework to facilitate standardized evaluations of pruning methods. We use ShrinkBench to compare various pruning techniques and show that its comprehensive evaluation can prevent common pitfalls when comparing pruning methods.

\end{abstract}
]  % end of manual twocolumn for sysml

% \maketitle

\printAffiliationsAndNotice{\mlsysEqualContribution} % otherwise use the standard text.

% ================================================================
\section{Introduction} \label{sec:intro}
% ================================================================
\vspace{-.75mm}

\input{intro.tex}


%================================================================
\section{Overview of Pruning}
%================================================================

% \input{overview.tex}
\input{overview_v2.tex}

%================================================================
\vspace{-2mm}
\section{Lessons from the Literature} \label{sec:lessons}
\vspace{-.5mm}
%================================================================

% \input{lessons.tex}
\input{lessons2.tex}

%================================================================
\section{Missing Controlled Comparisons}
%================================================================

\input{is_problem.tex}

%================================================================
% \section{Why the Lack of Comparisons?}
% \vspace*{4mm}
\section{Further Barriers to Comparison}
%================================================================

\input{why_problem.tex}

%================================================================
\section{Summary and Recommendations}
%================================================================

\input{recommendations.tex}

%================================================================
\section{ShrinkBench} \label{sec:bench}
%================================================================

% \input{shrinkbench.tex}
\input{shrinkbench_v2.tex}


%================================================================
\vspace{-1mm}
\section{Conclusion}
%================================================================

Considering the enormous interest in neural network pruning over the past decade, it seems natural to ask simple questions about the relative efficacy of different pruning techniques.
Although a few basic findings are shared across the literature, missing baselines and inconsistent experimental settings make it impossible to assess the state of the art or confidently compare the dozens of techniques proposed in recent years.
After carefully studying the literature and enumerating numerous areas of incomparability and confusion, we suggest concrete remedies in the form of a list of best practices and an open-source library---ShrinkBench---to help future research endeavors to produce the kinds of results that will harmonize the literature and make our motivating questions easier to answer. Furthermore, ShrinkBench results on various pruning techniques evidence the need for standardized experiments when evaluating neural network pruning methods.

%================================================================
\section*{Acknowledgements}
%================================================================

We thank Luigi Celona for providing the data used in \cite{luigi} and Vivienne Sze for helpful discussion. This research was supported by the Qualcomm Innovation Fellowship, the ``la Caixa'' Foundation Fellowship, Quanta Computer, and Wistron Corporation.

%``Benchmark Analysis of Representative Deep Neural Network Architectures.'' []

% ================================================================
% References
% ================================================================

% \IEEEtriggeratref{27} % trigger column break to make cols even
% \bibliographystyle{ACM-Reference-Format}
% \bibliographystyle{abbrev}
% \bibliographystyle{sysml2019}
\bibliographystyle{mlsys2020}
% \bibliography{prune,architectures,misc,understandDnn,classic,datasets,compress,science,metapapers,neuroscience}
\bibliography{combined}


\clearpage
\newpage  % so we can cut the pdf
\appendix



% TODO uncomment appendix after debug !!!!!!!!!!!!!!!!!!



\appendix
\input{appendix_corpus}
\input{appendix_checklist}
\input{appendix_framework}
\input{appendix_results}

\end{document}
