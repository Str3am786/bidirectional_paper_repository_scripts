\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Paper Title*\\
{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
should not be used}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
\and
\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address}
}

\maketitle

\begin{abstract}
This document is a model and instructions for \LaTeX.
This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, 
or Math in Paper Title or Abstract.
\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introduction}
This document is a model and instructions for \LaTeX.
Please observe the conference page limits. 

\section{Ease of Use}

\subsection{Maintaining the Integrity of the Specifications}

The IEEEtran class file is used to format your paper and style the text. All margins, 
column widths, line spaces, and text fonts are prescribed; please do not 
alter them. You may note peculiarities. For example, the head margin
measures proportionately more than is customary. This measurement 
and others are deliberate, using specifications that anticipate your paper 
as one part of the entire proceedings, and not as an independent document. 
Please do not revise any of the current designations.

\section{Prepare Your Paper Before Styling}
Before you begin to format your paper, first write and save the content as a 
separate text file. Complete all content and organizational editing before 
formatting. Please note sections \ref{AA}--\ref{SCM} below for more information on 
proofreading, spelling and grammar.

Keep your text and graphic files separate until after the text has been 
formatted and styled. Do not number text heads---{\LaTeX} will do that 
for you.

\subsection{Abbreviations and Acronyms}\label{AA}
Define abbreviations and acronyms the first time they are used in the text, 
even after they have been defined in the abstract. Abbreviations such as 
IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use 
abbreviations in the title or heads unless they are unavoidable.

\subsection{Units}
\begin{itemize}
\item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
\item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
\item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
\item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
\end{itemize}

\subsection{Equations}
Number equations consecutively. To make your 
equations more compact, you may use the solidus (~/~), the exp function, or 
appropriate exponents. Italicize Roman symbols for quantities and variables, 
but not Greek symbols. Use a long dash rather than a hyphen for a minus 
sign. Punctuate equations with commas or periods when they are part of a 
sentence, as in:
\begin{equation}
a+b=\gamma\label{eq}
\end{equation}

Be sure that the 
symbols in your equation have been defined before or immediately following 
the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
the beginning of a sentence: ``Equation \eqref{eq} is . . .''

\subsection{\LaTeX-Specific Advice}

Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
of ``hard'' references (e.g., \verb|(1)|). That will make it possible
to combine sections, add equations, or change the order of figures or
citations without having to go through the file line by line.

Please don't use the \verb|{eqnarray}| equation environment. Use
\verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
environment leaves unsightly spaces around relation symbols.

Please note that the \verb|{subequations}| environment in {\LaTeX}
will increment the main equation counter even when there are no
equation numbers displayed. If you forget that, you might write an
article in which the equation numbers skip from (17) to (20), causing
the copy editors to wonder if you've discovered a new method of
counting.

{\BibTeX} does not work by magic. It doesn't get the bibliographic
data from thin air but from .bib files. If you use {\BibTeX} to produce a
bibliography you must send the .bib files. 

{\LaTeX} can't read your mind. If you assign the same label to a
subsubsection and a table, you might find that Table I has been cross
referenced as Table IV-B3. 

{\LaTeX} does not have precognitive abilities. If you put a
\verb|\label| command before the command that updates the counter it's
supposed to be using, the label will pick up the last counter to be
cross referenced instead. In particular, a \verb|\label| command
should not go before the caption of a figure or a table.

Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
will not stop equation numbers inside \verb|{array}| (there won't be
any anyway) and it might stop a wanted equation number in the
surrounding equation.

\subsection{Some Common Mistakes}\label{SCM}
\begin{itemize}
\item The word ``data'' is plural, not singular.
\item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
\item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
\item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
\item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
\item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
\item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
\item Do not confuse ``imply'' and ``infer''.
\item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
\item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
\item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
\end{itemize}
An excellent style manual for science writers is \cite{b7}.

\subsection{Authors and Affiliations}
\textbf{The class file is designed for, but not limited to, six authors.} A 
minimum of one author is required for all conference articles. Author names 
should be listed starting from left to right and then moving down to the 
next line. This is the author sequence that will be used in future citations 
and by indexing services. Names should not be listed in columns nor group by 
affiliation. Please keep your affiliations as succinct as possible (for 
example, do not differentiate among departments of the same organization).

\subsection{Identify the Headings}
Headings, or heads, are organizational devices that guide the reader through 
your paper. There are two types: component heads and text heads.

Component heads identify the different components of your paper and are not 
topically subordinate to each other. Examples include Acknowledgments and 
References and, for these, the correct style to use is ``Heading 5''. Use 
``figure caption'' for your Figure captions, and ``table head'' for your 
table title. Run-in heads, such as ``Abstract'', will require you to apply a 
style (in this case, italic) in addition to the style provided by the drop 
down menu to differentiate the head from the text.

Text heads organize the topics on a relational, hierarchical basis. For 
example, the paper title is the primary text head because all subsequent 
material relates and elaborates on this one topic. If there are two or more 
sub-topics, the next level head (uppercase Roman numerals) should be used 
and, conversely, if there are not at least two sub-topics, then no subheads 
should be introduced.

\subsection{Figures and Tables}
\paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
bottom of columns. Avoid placing them in the middle of columns. Large 
figures and tables may span across both columns. Figure captions should be 
below the figures; table heads should appear above the tables. Insert 
figures and tables after they are cited in the text. Use the abbreviation 
``Fig.~\ref{fig}'', even at the beginning of a sentence.

\begin{table}[htbp]
\caption{Table Type Styles}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
\cline{2-4} 
\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
\hline
copy& More table copy$^{\mathrm{a}}$& &  \\
\hline
\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
\end{tabular}
\label{tab1}
\end{center}
\end{table}

\begin{figure}[htbp]
\centerline{\includegraphics{fig1.png}}
\caption{Example of a figure caption.}
\label{fig}
\end{figure}

Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
rather than symbols or abbreviations when writing Figure axis labels to 
avoid confusing the reader. As an example, write the quantity 
``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
units in the label, present them within parentheses. Do not label axes only 
with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
\{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
quantities and units. For example, write ``Temperature (K)'', not 
``Temperature/K''.

\section*{Acknowledgment}

The preferred spelling of the word ``acknowledgment'' in America is without 
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
acknowledgments in the unnumbered footnote on the first page.

\section*{References}

Please number citations consecutively within brackets \cite{b1}. The 
sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

Number footnotes separately in superscripts. Place the actual footnote at 
the bottom of the column in which it was cited. Do not put footnotes in the 
abstract or reference list. Use letters for table footnotes.

Unless there are six authors or more give all authors' names; do not use 
``et al.''. Papers that have not been published, even if they have been 
submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
Capitalize only the first word in a paper title, except for proper nouns and 
element symbols.

For papers published in translation journals, please give the English 
citation first, followed by the original foreign-language citation \cite{b6}.

\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
\end{thebibliography}
\vspace{12pt}
\color{red}
IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}

\documentclass[conference, 10pt]{IEEEtran}
%\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{float}
\usepackage{url}

\begin{document}

\bibliographystyle{ieeetr}


\title{Vermillion: A High-Performance Scalable IoT Middleware for Smart Cities}
%\thanks{Identify applicable funding agency here. If none, delete this.}
\author{\IEEEauthorblockN{Poorna Chandra Tejasvi\IEEEauthorrefmark{1},
Vasanth Rajaraman\IEEEauthorrefmark{2}, Arun Babu Puthuparambil\IEEEauthorrefmark{3}, Akhil Pankaj\IEEEauthorrefmark{4},
Bharadwaj Amrutur \IEEEauthorrefmark{5}}
\IEEEauthorblockA{Robert Bosch Centre for Cyber-Physical Systems,
Indian Institute of Science,\\
Bangalore, India\\
Email: \IEEEauthorrefmark{1}poornachandra@iisc.ac.in,
\IEEEauthorrefmark{2}vasanthr@iisc.ac.in,
\IEEEauthorrefmark{3}barun@iisc.ac.in,
\IEEEauthorrefmark{4}akhilpankaj@iisc.ac.in,
\IEEEauthorrefmark{5}amrutur@iisc.ac.in}}

\maketitle

\begin{abstract}
With the massive increase in the number of IoT devices being deployed in smart cities, it becomes paramount for middlewares to be able to handle very high loads and support demanding use-cases. In order to do so, middlewares must scale horizontally while providing a commensurate increase in availability and throughput. Currently, most open-source IoT middlewares do not provide out-of-the-box support for scaling horizontally. In this paper, we present ``Vermillion'', a scalable, secure and open-source IoT middleware for smart cities which provides in-built support for scaling-out. We make three contributions in this paper. Firstly, the middleware platform itself along with a formal process for data exchange between data producers and consumers. Secondly, we propose the use of hash-based federation to distribute and manage load across various message broker nodes while eliminating inter-node synchronisation overheads. Thirdly, we discuss a case study where Vermillion was deployed in a city and briefly discuss about deployment considerations using the obtained results.
\end{abstract}

\begin{IEEEkeywords}
Smart Cities, Middleware, Vermillion, Scalable, High-Performance
\end{IEEEkeywords}

\section{Introduction}
Metropolitan cities face increasing pressure on their already limited resources due to unplanned allowance of rapid urbanisation. This leads to urban sprawls and unsustainable loads on critical resources in cities \cite{tian2017impacts}. A promising solution to the aforementioned problems is the use of IoT technologies to regulate unchecked resource consumption. Although the use of IoT does not completely solve the problem, it significantly ameliorates it, thus paving the way for reasonably sustainable growth of cities \cite{su2011smart}

The use of IoT in cities comes with immense benefits such as being able to actively monitor services, resource usage, potential dangers etc. thus enabling city administrators to take prophylactic steps in preventing problems from occurring \cite{villanueva2013civitas}. Therefore, it is no surprise that the number of IoT devices will reach 18 billion by 2022 \cite{rostanski2014evaluation}. To be able to handle such rapid growth, it is very essential for IoT middlewares to technologically adapt to such demanding circumstances. There will, inevitably, be very large loads on these middlewares and they will be expected to perform with near-zero downtime while at the same time ensuring a high throughput. 

To address this problem, we have developed Vermillionhttps://github.com/rbccps-iisc/iudx-resource-server, a scalable, secure and open-source IoT middleware, built for performance.  Vermillion comprises of numerous containerised microservices all of which work together to provide a view of a single logical entity. It uses Vertx.io \cite{vertx} for the HTTPS proxy, RabbitMQ https://www.rabbitmq.com as the message broker, PostgreSQL \cite{postgres} as the authentication database and MongoDB https://www.mongodb.com/ as the historical data store. All of these microservices have been containerised using Docker \cite{docker} and are orchestrated either using docker-compose (for a single node deployment) or using docker swarm and Ansible https://www.ansible.com (for a multi-node deployment)

The primary focus of Vermillion was performance and functionality. We developed this middleware over multiple iterations, learning lessons from each, and we have finally arrived at a set of tools and practices that work well together to provide good performance results. The first tool that significantly aided in giving a performance boost was Vertx. Most traditional network libraries and frameworks spawn one thread per concurrent user. This thread dies after the user has finished their operation or is returned to the thread pool if it is a slightly more optimised implementation. Although it is a very straightforward solution to handling concurrency and load, it comes with a lot of overheads of thread and resource management. With a lot of concurrent users, there is only up to a point until which vertical scaling helps alleviate this problem. Beyond that, thread scheduling and resource management become very expensive. 

%Do we need this?
\begin{figure}[H]
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{eventloop.png}
\caption{Event loops in Vertx\cite{eventloop}}
\label{eventloop}
\end{figure}

Vertx is an event-driven and non-blocking toolkit that takes a different approach towards handling this problem.  Events are processed over event loops which are non-blocking. Each event loop has a dedicated thread associated with it. Vertx spawns two event loops per CPU core of the machine. Events get processed in a stipulated amount of time and are not allowed to block the event loop. This approach, as shown in Figure \ref{eventloop}, along with several other optimisations in the Vertx core library, which we cannot describe here due to a space constraint, has allowed it to outperform most other web servers along various measurement parameters https://www.techempower.com/benchmarks/. 

The second optimisation that we used to improve broker operation performance is by maintaining a connection pool in the HTTPS proxy. Typical RabbitMQ operations take anywhere between 14-19 TCP packets \cite{cloudamqp}. These operations include opening a connection, opening a channel, performing the operation, closing the channel and finally closing the connection. Connection pools greatly reduce connection establishment latencies for clients since they reuse connections and channels. When a client connects for the very first time, the initial overhead is incurred and the created channel is stored in memory. For every other subsequent operation, the channel is retrieved from the pool and is used for the desired client operation.

The third optimisation, especially in the multi-node deployment, is the use of a simple hash function to distribute load across many RabbitMQ nodes. We describe the hash function in detail in section \ref{hashalgo}. To compare the results we obtained from the hash-based scheme, we set up an identical cluster using RabbitMQ's internal clustering tool and we measure the throughput in both these cases.

\section{Related Work}
A variety of open-source IoT middlewares are discussed in \cite{ray2016survey} and \cite{farahzadi2018middleware} and compared extensively on various aspects like Application Development, Data Management, System Management, Heterogeneity Management, Analytics, Visualisation and so on. In both of the papers, the necessity of a middleware in an IoT environment is highlighted.  A few notable middlewares from both \cite{ray2016survey} and \cite{farahzadi2018middleware} includes ThingsSpeak, FIWARE, Xively. These middlewares however, are more focused on providing features for easy application development, visualisation and data management. 

A Service-Oriented Architecture (SOA) based Multi-Agent System (MAS) middleware \cite{zhiliang2011soa} combines the advantages of both SOA and MAS to deliver a viable performing middleware which can service 60 requests per second. The proposed architecture was able to convert a heterogeneous network into a homogeneous one system which enjoys added benefits of loosely coupled, robust, versatile, flexible and dynamic components.

According to \cite{da2018performance} and \cite{cardoso2017benchmarking} middlewares can be analysed on qualitative as well as quantitative dimensions. Qualitative aspects can include metrics such as data security, number of SDKs, number of updates available, communication protocols, support, documentation and so on. Quantitative dimensions can include response times, size of data/packet, error percentage etc. Inatel, a proprietary IoT middleware, is compared against 4 other open-source middlewares on the aforementioned aspects, out of which Fiware with Orion performed the best [4]. Similarly, FIWARE is compared with ETSI M2M [5] where FIWARE performs overall well with minimal content-length in the HTTP request and response messages. ETSI M2M suffered serious implementation flaws due to library errors and the absence of a reference implementation.

MediaSense \cite{kanter2012mediasense} is another open-source middleware which offers scalable, seamless and real-time access to sensors and actuators. The paper discusses the various requirements that a generic IoT middleware should satisfy. Proof-of-concept applications have been developed to demonstrate its capabilities in health monitoring, object-tracking, energy consumption, etc. No quantitative assessments were conducted whatsoever to support these claims. 

Performance evaluation of RabbitMQ when subjected to intense load is conducted in \cite{vandikas2014performance} and \cite{rostanski2014evaluation}. Instead of comparing the IoT-framework described in \cite{vandikas2014performance} with other middlewares, it establishes a baseline for performance on a single node system. 
Even though a clustered architecture was discussed, the performance of only a single node system on RabbitMQ was evaluated in \cite{vandikas2014performance} which is usually not the case when it comes to actual deployments. A varying number of producers and consumers were simulated, generating $10^5$ HTTPS requests, throughput (msgs/secs)  and memory consumption were recorded. The numbers showed linear scalability but were still not satisfactory.

A variety of configurations for RabbitMQ were presented in\cite{rostanski2014evaluation} to achieve High Availability and Fault-Tolerant system. A setup similar to the one mentioned in \cite{vandikas2014performance} was adopted with varying number of clients and publishers, and throughput(msgs/sec) was captured. These configurations though suffered significant performance degradation on a 3 node clustered system.

One common drawback on the systems mentioned above and in \cite{ray2016survey,farahzadi2018middleware} is that, firstly, the platforms focus on Integrated Command and Control Centres (ICCC) dashboards where the emphasis is on data acquisition and visualisation rather than on data exchange. Secondly, most of them are not completely open-source and performance numbers are not reported. So planning for a city-scale deployment becomes very difficult. Thirdly, in many platforms, the concept of standardised data exchange through REST APIs is not defined.
For middlewares where performance numbers are available \cite{zhiliang2011soa}\cite{da2018performance}\cite{cardoso2017benchmarking}\cite{vandikas2014performance}\cite{rostanski2014evaluation} they fell short on performance, scalability or both. With this paper, we try to address all of the aforementioned drawbacks and provide details on how Vermillion addresses these issues in detail.


\section{System Architecture}

We now present detailed system-level architectural details of Vermillion, both for a single-node as well as for a multi-node deployment. Vermillion comprises multiple modular components, or microservices, each of which is responsible for a specific set of functions. All of these microservices have been packaged as portable docker containers, so that setup and installation overheads are significantly reduced. The microservices have been containerised such that they intelligently wait for their dependent services to start-up before starting-up themselves whether on a single node deployment or a multi-node deployment. This approach obviates the need for microservice level orchestration, further reducing installation time.  A description of the individual microservices is as follows:

\begin{itemize}
\item \textbf{HTTPS Proxy}: This is the module that is responsible for the main application logic of Vermillion. It maintains the connection pools, computes the hash function for multi-node deployment and also round-robins between broker nodes in the cluster-mode deployment. It provides wrappers for all low-level broker operations such as publish, subscribe, bind, unbind and so on. It is designed such that it is stateless so that as many replicas can be spawned as needed without worrying about data integrity between proxy servers. It is written purely in Java using the Vertx toolkit.  

\item \textbf{Message Broker (Broker)}: We use RabbitMQ as the message broker for our middleware. RabbitMQ is a high-performance message broker written in Erlang \cite{ionescu2015analysis} that has a good throughput and scales very wellhttps://content.pivotal.io/blog/rabbitmq-hits-one-million-messages-per-second-on-google-compute-engine. It is very customisable and provides fine-grained access-policy authoring features. For authentication and authorisation, we use an HTTP authorisation backend along with a cache plugin that keeps authorisation policies cached for quicker access.  

\item \textbf{Authentication and Authorisation Database (Auth DB)}: This is a PostgreSQL database that is used to store user IDs, hashes of API keys and permissions. The tables are designed in such a way there are no joins involved. This approach helps to reduce latencies involved in complex join operations across indices of multiple tables. This database is also used by the RabbitMQ HTTP backend to authenticate users.

\item \textbf{Broker Authorisation Backend (Auth Backend)}: RabbitMQ can be configured to use a variety of ways to authenticate and authorise users. We chose to configure it to use an HTTP backend because the logic for the complex permission systems of Vermillion could not be expressed using RabbitMQ's internal policies. Secondly, since the Auth DB was already storing authentication and authorisation information we did not want to create a split-brain situation by mirroring these policies in the broker's internal database. Hence, we chose to use an HTTP auth backend that simply connects to the Auth DB and provides a wrapper for Vermillion permission systems in the form of APIs for the broker to invoke.

\item \textbf{Historical Data Store}: We use MongoDB as the historical data store which stores data points from all connected devices. MongoDB is a NoSQL database that is simple to use, light on memory usage and has good query capabilities https://www.mongodb.com/. We currently do not expose this data for general use to consumers. It is only meant for archival purposes.

\item \textbf{Utility Services}: This comprises of two modules: the DB connector and the unbind daemon. The DB connector is responsible for pulling out messages from all broker nodes and pushing it into the historical data store. The unbind daemon is responsible for periodically checking for expired entries in the Auth DB and deleting bindings between corresponding exchanges and queues in the broker.
\end{itemize}

\subsection{Deployment Options}
Vermillion can be deployed in three modes - a single-node deployment, a multi-node clustered deployment or a multi-node federated deployment which uses the hash-based federation algorithm. Fig. \ref{multinode} illustrates the multi-node deployment of Vermillion. 

In the single-node deployment, all docker containers run on the same machine. While this is a quick way to get Vermillion running, it is only recommended for small cities and development environments. While this mode of deployment provides a good throughput, it may not be enough for a large city or for a city with a very high number of sensors.

In the clustered deployment mode, all broker nodes are replicas of each other i.e. exchanges and bindings exist on all nodes of the cluster. Queues reside on the node on which they were created. RabbitMQ automatically routes consume requests to the respective node on which the queues reside. We do not use queue mirroring since enabling this option causes a significant decrease in throughput. Clustering option can be used to achieve fault tolerance by configuring mirrored queues at the expense of throughput.

Vermillion can also be configured to run in a federated mode where a simple hash function is used to load balance between the broker nodes. Using this technique, each broker node can run independently, while the orchestration logic can reside in the HTTPS proxy thus eliminating the need for broker level data synchronisation and state-awareness. 

\begin{figure}
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{MultiNode.png}
\caption{Multi-Node Architecture}
\label{multinode}
\end{figure}

\section{The Federation Algorithm} \label{hashalgo}
The federation algorithm is a simple modular hash function that uses the first character of a username to distribute load among various message brokers. The algorithm obtains a numerical equivalent of the first character of the username to compute the bucket number of the broker. This is done using the ASCII \cite{ascii} representation of the letter. Once the bucket number has been obtained, the corresponding URL is constructed by appending the bucket number to the base URL ``rabbit" and is returned to the calling function which establishes a connection with the respective broker. The pseudo-code is shown in Algorithm \ref{hash} 

Line \ref{mainline} in the algorithm denotes the main logic of the hash. For each $k\in\{1,\ldots,26\}$ and for each nodes $=2,\;3,\ldots$, we define  

\begin{equation}
bucket = (k \; \% \; nodes) \; + \; 1.
\end{equation} 

It is easy to prove that the computed bucket number always lies in $[1,nodes]$ Since $k \; \% \; nodes$ always lies in $[0,nodes-1]$, it follows that $(k \; \% \; nodes) +1$ lies in $[1,nodes]$. Hence, $bucket \in [1,nodes]$.

The hash algorithm used is a really simple one that neither uniformly distributes the load nor is consistent when nodes are added or removed from the deployment. However, we wanted to underscore the benefits of using a hash function, and how it helps in improving the overall throughput, rather than on the performance and consistency of the algorithm itself. Vermillion has been designed such that any hash function can easily be plugged in and used.

\begin{algorithm}[H]
\caption{Hash based Federation}\label{hash}
\begin{algorithmic}[1]
\Procedure{computehash}{$username, nodes$}
\State $\textit{firstchar} \gets \text{lowercase(}\textit{username}\text{[0])}$
\State $k \gets \text{ASCII value of } \textit{firstchar}$
\State $k \gets k - 96$ \Comment{Map letters to integers, a=1, b=2 etc}
\State $bucket \gets (k  \; \% \; nodes) \; + \; 1$ \Comment{$bucket \in [1,nodes]$} \label{mainline}
\State \Return \textit{bucket}
\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Data Exchange Flow}
We now turn our attention to the mechanisms that Vermillion provides to ease the process of data exchange between data providers and data consumers in a smart city. Most IoT middlewares, as stated earlier, focus on the Integrated Command and Control Centre (ICCC) dashboard for city administrators rather than creating an ecosystem for data to be exchanged between parties. When cities do expose data, they are in the form of static files. This kind of set up precludes private parties from participating and monetising any insights they generate out of the public datasets.

Vermillion, not only allows for static files to be hosted, but also for real-time data to be shared between providers and consumers. Furthermore, the data providers can choose who they share the data with, and how much of data they have access to; thus allowing for data to be monetised. The following subsections will detail this formal data exchange procedure.

Vermillion has four categories to which a user can belong. 

\begin{itemize}
\item \textit{Administrator} - A user who is an administrator is of the Vermillion server.
\item \textit{Provider} - A provider is a user who owns certain datasets and/or devices.
\item \textit{Entity} - An entity is any sensor, pseudo-sensor or application that is owned by a provider
\item \textit{Subscriber} - A subscriber is a special type of entity which mostly subscribes to data. A subscriber also must be owned by a provider.
\end{itemize}

\subsection{Resource Registration}

A Provider is validated and registered with Vermillion by the administrator. Upon registration, a provider API-key is generated for the given provider-id. This API key forms the basis for identity establishment of the provider. The generated API key is hashed and stored in the PostgreSQL database. With this, the provider can register entities (publishers and subscribers) with Vermillion. The work-flow for registration of a publisher and data publication is shown in the Figure \ref{registration}. 

\begin{itemize}
\item To register a publisher, the provider calls the ‘/owner/register-entity’ API with a JSON structured catalogue-item which consists of meta-information about the device e.g., its location, the type of data it publishes and so on. Vermillion validates this and accepts the request for registration by the provider by registering the entity and responding with an entity API-key.

\item To publish data, the publisher calls the ‘/entity/publish’ API with the data structured as per the data-model provided in the catalogue-item. Vermillion validates the request and publishes it to the corresponding exchange in the broker.
\end{itemize}

\begin{figure}[H]
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{reg-and-pub.png}
\caption{Registration and Publish Workflow}
\label{registration}
\end{figure}

\subsection{Data Access Request Workflow}

As stated earlier, a subscriber is an entity which is interested in datasets belonging to various providers. A subscriber can be an application, a pseudo-sensor, or itself be a publisher. The information about all the the datsets are available in the catalogue. (at the /cat endpoint) This information can be filtered using various search parameters like geo-bounds, providers, device type and so on. Once the subscriber has a list of entities that they are interested in, they can invoke the ‘/entity/follow’ API. This API is meant for expressing interest to get access to datasets. Vermillion responds with a follow-id, which can be used by the subscriber to track the status of the request using the ‘/entity/follow-status’ API. This is illustrated in Figure \ref{follow}

\begin{figure}
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{follow-share.png}
\caption{Data Access Request Workflow}
\label{follow}
\end{figure}

\subsection{Notification of Follow request}

A publisher check for received follow requests using the ‘/entity/follow-requests’ API.  The API responds with a list of subscriber IDs along with a list of entities requested by the respective subscribers. Each follow request can be independently reviewed by the provider and can be approved or rejected. A provider can approve follow requests using the ‘/entity/share’ API and  can reject a follow request using the ‘/entity/reject-follow’ API. Figure \ref{notify} illustrates this workflow

\begin{figure}
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{follow-status.png}
\caption{Notification of Follow request}
\label{notify}
\end{figure}

\subsection{Subscribe for data}

A subscriber who has submitted follow requests can track the status of the requests using the ‘/entity/follow-status’ API by providing the appropriate follow-id. If the follow request has been approved, the subscriber can "bind" with the list of approved entities using the ‘/entity/bind’ API. A ``bind" operation creates a binding between the entity's exchange and the subscriber's queue. This essentially instructs the broker to relay all messages of a certain type received by the entity's exchange, to the subscriber's queue. Once bound, the subscriber can start consuming the data using the '/entity/subscribe' API.

The bind operation is quite straightforward when it comes to dealing with a single broker node, or perhaps even a clustered RabbitMQ setup. In a clustered setup, all peers in the cluster know exactly where a particular queue resides, and routeing messages between nodes becomes easy. However, when it comes to the federated setup, some intervention is needed. All the nodes operate independently of each other. Hence, there needs to be a mechanism to allow for this routeing to happen between broker nodes. We achieve this by using the RabbitMQ shovel plugin. The shovel plugin can be used to move messages from a source on one broker node to a destination in another broker node. Vermillion keeps a track of these shovels and updates or deleted them as and when necessary. Figure  \ref{subscribe} illustrates the above mechanism.

\begin{figure}
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{subscribe.png}
\caption{Subscribe for data}
\label{subscribe}
\end{figure}

\section{Results}

We now present preliminary test results that were performed to evaluate the throughput of Vermillion. The tests were performed on a single node deployment as well as on a multi-node deployment. The test setup consisted of three primary groups of nodes as shown in Fig. \ref{testsetup}: the Vermillion nodes, the test machines (called the controllers), and the subscriber machine. In order to load test Vermillion, we used a tool called Tsung https://github.com/processone/tsung. Tsung is a high-performance benchmarking framework built to test large-scale applications. All the nodes used for testing were high-frequency, compute optimised nodes with 16GB of RAM and 4 vCPU cores. 

\begin{figure}
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{TestSetup.png}
\caption{Test Setup}
\label{testsetup}
\end{figure}

\begin{table*}
\centering
\begin{tabular}{||c c c c c||} 
 \hline
 Configuration & Broker Nodes &  HTTPS Proxy Nodes & Total Nodes & Description\\ [0.5ex] 
 \hline\hline
 1 & - & - & 1 & Single Node test \\
 \hline 
 2 & 2 & 2 & 4 & Two brokers with two proxies \\
 \hline
 3 & 4 & 4 & 8 & Four brokers with four proxies\\
 \hline
 4 & 6 & 6 & 12 & Six brokers with six proxies \\
 \hline
\end{tabular}
\vspace{1em}
\caption{Test Configurations}
\label{configurations}
\end{table*}

The tests were carried out on all three deployment modes of Vermillion, namely, single-node deployment, multi-node federated deployment and multi-node clustered deployment. Table \ref{configurations} shows the configurations that were used to stress test the middleware. For each configuration, we also varied the number of producers from  $10^0$ to $10^3$, and each producer to published $10^4$ messages at a time. We did not go any further, as even for $10^4$ producers, Tsung was not able to spawn all users and manage the load. So we capped the number of producers at $10^3$. Since each producer was configured to publish $10^4$ messages, the total number of messages being published to Vermillion for a given configuration at a time, ranged from $10^4$ to $10^7$  messages\\


\begin{table}[H]
\centering
\begin{tabular}{||c c||} 
 \hline
 Number of Producers & Number of Tsung Controllers \\ [0.5ex] 
 \hline\hline
 1 & 1 \\
 \hline 
 10 & 2 \\
 \hline
 100 & 4 \\
 \hline
 1000 & 6 \\
 \hline
\end{tabular}
\vspace{1em}
\caption{Tsung Controllers per Producer Configuration}
\label{controllers}
\end{table}

Table \ref{controllers} shows the number of Tsung controllers used per producer configuration of the test. All test results conducted were over HTTPS. The throughput numbers would have been much higher with HTTP. However, we deliberately incurred this additional overhead of using TLS over HTTP, since in an actual deployment, HTTPS will likely be used over HTTP.

Furthermore, each test configuration was divided into two sub-tests. The first test measured the throughput of the system in an idealistic situation, where the broker was idle, there were no consumers, no messages in any of the queues and no running shovels. The second test attempted to model a more realistic scenario. The broker was busy catering to multiple subscribers, there were messages in many of the queues and some shovels were running. The number of consumers introduced in the second test was equal to the number of producers used for that test. E.g., if $1000$ simultaneous producers were being used in a certain test configuration, then the second test modelling a realistic load, had $1000$ simultaneously running consumers.

Figure \ref{singlenode} shows the obtained results for a single node deployment. The maximum throughput that we obtained with this was around $23,000$ HTTPS requests per second, using $1000$ producers and no subscribers. There are a few interesting trends that we immediately observe. Firstly, the throughput increases as the number of producers are increased. This is because the HTTPS proxy is capable of handling many concurrent connections. Hence, until a point is reached where increasing the producers or the number of messages does not produce any significant impact on the average throughput, the perceived average throughput is not at its highest limit of the configuration yet. Secondly, we observe that the throughput slightly drops when subscribers are introduced. This can be attributed to the fact that there is an overhead involved in keeping long-lived connections and channels open for subscribers. We also observe that for the first test with $1$ producer and $1$ subscriber, the throughput is slightly better than when no subscribers are introduced. This could be because the number of subscribers is simply not high enough to make an impact on the overall throughput. Nevertheless, the overhead involved in keeping the connections open and their impact on the throughput is evident when the number of producers is higher. The average drop in throughput when subscribers are introduced for this configuration is about $14.6 \%$

\begin{figure}[H]
 \includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{1-node.png}
\caption{Performance of a Single Node deployment}
\label{singlenode}
\end{figure}

For two, four and six nodes, the results obtained for each configuration were compared with the throughput obtained when the respective number of RabbitMQ nodes were clustered internally. Figure \ref{twonodes} shows the results when two broker nodes and two HTTPS proxy were used. At the outset, we notice that the highest average throughput under realistic conditions for the federated mode is around $53,256$ requests per second against $21,189$ requests per second in the clustered mode. The throughput of the federated mode with subscribers is around $151\%$ better than the clustered mode. The average throughput drop in the federated mode is around $16\%$ against $36\%$ drop in the clustered setup.  

\begin{figure}
 \includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{2-nodes.png}
\caption{Performance of a two-node deployment}
\label{twonodes}
\end{figure}

Figure \ref{fournodes} shows the comparison between the two modes when four broker nodes and four HTTPS nodes are used. In this particular case, the difference in the performance of the two modes is much more accentuated. The highest average throughput under realistic conditions for the federated setup is around $99,162$ requests per second against $22792.25$ requests per second in the clustered setup, which is a $335\%$ improvement in the federated mode. The average throughput drop when subscribers are introduced is around $15\%$ in the federated mode against $41\%$ in the clustered setup.  

\begin{figure}
 \includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{4-nodes.png}
\caption{Performance of a four-node deployment}
\label{fournodes}
\end{figure}

When we look at the results of using six broker nodes and six HTTPS nodes, as shown in Figure \ref{sixnodes}, we notice that the throughput when $100$ producers are used, for both federated and clustered set up, is much lower than the results of their respective previous configurations. We also notice that the throughput of their next subsequent tests (when $1000$ producers are used) is much higher than the throughput obtained for their respective previous configurations. So, when using $4$ nodes and $100$ producers gave a throughput of $40,417$ requests per second in the federated setup, using six nodes and $100$ producers gave $26,933$ requests per second. This behaviour also occurs in the clustered setup. This anomaly arises because there are $12$ available nodes but only $100$ producers. Many producers finish their publication well before new producers are spawned, thus reducing the total number of concurrent publications. This causes the overall perceived throughput by Tsung to reduce.  

We notice that the highest average throughput under realistic conditions is $121,058$ requests per second for the federated mode against $31,503$ requests per second for the clustered setup, which is around a $284\%$ improvement in the federated mode. The average throughput drop when subscribers are introduced is around $25\%$ in the federated mode, and around $31\%$ in the clustered setup.

The federated mode consistently outperforms the clustered setup since there are no inter-node synchronisation overheads involved. The routing logic is embedded entirely in the HTTPS proxy. In the clustered setup, there is constant chatter between the nodes to synchronise their states, data, information about connections, channels and so on. Also, all the peers in a clustered setup need to maintain a routeing table that specifies the node to contact in case a request which cannot be served by that particular node is received. For e.g., if node-1 receives a request to subscribe for a queue residing in node-2.  

\begin{figure}
 \includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{6-nodes.png}
\caption{Performance of a six-node deployments}
\label{sixnodes}
\end{figure}

The payload used for the above tests was a sample reading from a flood sensor deployed in Pune, Maharashtra, India. This payload has a message size of around$220$ bytes. In many cases, sensors deployed in a smart city may not directly publish to their middlewares. They first publish to their edge gateways, which, in turn, publish to the middlewares. In such a scenario, a gateway may not publish messages as and when it receives the readings from a sensor. It may accumulate some readings over time and then publish at a certain stipulated time, thus causing the message size to increase. To simulate such a situation, we deployed the $4$ broker node, $4$ HTTPS node federated configuration and tested the setup using a $10$ kB payload. Figure \ref{10kb} shows that the average throughput drop when subscribers are introduced is around $11.5\%$. The highest average throughput obtained under realistic circumstances is $40,104$ requests per second. This throughput figure is much lesser than $99,162$ requests per second for a $220$ byte payload since the message size is much larger.

\begin{figure}
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{10kb-payload.png}
\caption{Performance of a two-node deployment when the payload is 10kB}
\label{10kb}
\end{figure}

\begin{figure*}[!h]
\includegraphics[width=\linewidth, height=\linewidth, keepaspectratio]{map.png}
\caption{Deployment of Vermillion in Pune Smart City serving 2200 sensors ({https://catalogue.iudx.org.in}).}
\label{map}
\end{figure*}

\section{Case Study and Deployment Considerations}
Vermillion has been deployed in the city of Pune, Maharashtra, India. It is a part of the  the Indian Urban Data Exchange \cite{iudx} deployment to provide access to smart city data in an open and secure fashion. This deployment has about $2,200$ sensors, each of them publishing at different intervals. We have set up a single node instance of Vermillion and it has been running smoothly for over two months at the time of writing this paper. The data from Vermillion can be accessed at https://catalogue.iudx.org.in. Figure \ref{map} shows a map interface of the sensors deployed in the Pune Smart City.

The desirable properties needed from a middleware might vary across different cities. So, it becomes very difficult to make a general recommendation that can suit all cities. The results obtained can be used to decide on the deployment strategy needed for a city. E.g. the city of Barcelona, Spain has around $1800$ sensors publishing data at varied periods\cite{barcelona}. For such a kind of deployment, in its current state, a single node deployment with additional customisations should suffice. On the other hand, the city of Santander, Spain has over $12,000$ sensors deployed\cite{esri}. For such a kind of setup, the sensor publish frequency must be taken into account while deploying Vermillion. Typically, the $4$ broker node, $4$ HTTPS node deployment should suffice, but this decision needs to be arrived at only after consideration of a lot of factors, including future sensor deployment plans by city administrators. 

\section{Conclusion}
In this paper, we have introduced Vermillion, a high-performance, scalable IoT middleware for smart cities. We have described the individual sub-systems of this middleware and proposed a formal procedure for data exchange between data producers and consumers in a smart city. We have also proposed the use of a hash function to federate RabbitMQ nodes and distribute load across these nodes using the hash algorithm. Furthermore, we have shown that the performance of this federated mode deployment against the internal cluster setup of RabbitMQ is at least $151\%$ better than using the internal clustering of RabbitMQ. We have also shown that Vermillion's throughput increases with increasing availability unlike the case with internal clustering of RabbitMQ. Finally we discussed a case study where Vermillion was successfully deployed in the city of Pune, Maharashtra, India.

\section{Future Scope}
As stated earlier, Vermillion can be customised and more features can be plugged in as necessary. However, there are a few features internal to Vermillion that can be improved. Firstly, a good hash function needs to be chosen so that the load is uniformly distributed among the various message brokers. The hash function also needs to be consistent so that if nodes are added or deleted from a deployment, it should not affect the functioning of Vermillion. Secondly, proxies for other low-level protocols like AMQP, MQTT, STOMP, CoAP and so on must be developed so that users and devices need not communicate only over HTTPS. Thirdly, the overall availability of Vermillion can be improved if each node in a bucket is clustered, using the RabbitMQ internal clustering, with one other node, and the Docker Swarm service round robins between these two nodes when usernames (or any other parameters) resolve to that particular bucket. E.g., if there are two buckets with one node each, these two nodes can internally cluster with one other node, thus allowing for more nodes per bucket. Docker Swarm can round-robin between the two nodes per bucket. Finally, Vermillion can allow for proper access mechanisms and retention policies for archived data.

\section{Acknowledgements}
We would like to thank the Pune Smart City Development Corporation for their support and the Ministry of Housing and Urban Affairs, Government of India for funding this project. 

%We would also like to thank the Indian Urban Data Exchange (IUDX) team consisting of Abhay Sharma, Rakshit Ramesh, Jishnu Jaykumar, Rohina Naaz and Mukunth Arun. 

\bibliography{bibliography} 

\end{document}

