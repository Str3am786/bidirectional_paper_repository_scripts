\begin{thebibliography}{10}

\bibitem{catoni2007pac}
Olivier Catoni.
\newblock {PAC-Bayesian} supervised classification: the thermodynamics of
  statistical learning.
\newblock {\em arXiv preprint arXiv:0712.0248}, 2007.

\bibitem{russo2016controlling}
Daniel Russo and James Zou.
\newblock Controlling bias in adaptive data analysis using information theory.
\newblock In {\em Artificial Intelligence and Statistics}, pages 1232--1240,
  2016.

\bibitem{xu2017information}
Aolin Xu and Maxim Raginsky.
\newblock Information-theoretic analysis of generalization capability of
  learning algorithms.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2524--2533, 2017.

\bibitem{asadi2018chaining}
Amir~R. Asadi, Emmanuel Abbe, and Sergio Verd{\'u}.
\newblock Chaining mutual information and tightening generalization bounds.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  7234--7243, 2018.

\bibitem{hardt2016identity}
Moritz Hardt and Tengyu Ma.
\newblock Identity matters in deep learning.
\newblock {\em arXiv preprint arXiv:1611.04231}, 2016.

\bibitem{bartlett2018representing}
Peter~L. Bartlett, Steven~N. Evans, and Philip~M. Long.
\newblock Representing smooth functions as compositions of near-identity
  functions with implications for deep network optimization.
\newblock {\em arXiv preprint arXiv:1804.05012}, 2018.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{cesa1999prediction}
Nicol{\'o} Cesa-Bianchi and G{\'a}bor Lugosi.
\newblock On prediction of individual sequences.
\newblock {\em The Annals of Statistics}, 27(6):1865--1895, 1999.

\bibitem{gaillard2015chaining}
Pierre Gaillard and S{\'e}bastien Gerchinovitz.
\newblock A chaining algorithm for online nonparametric regression.
\newblock In {\em Conference on Learning Theory}, pages 764--796, 2015.

\bibitem{cesa2017algorithmic}
Nicol{\`o} Cesa-Bianchi, Pierre Gaillard, Claudio Gentile, and S{\'e}bastien
  Gerchinovitz.
\newblock Algorithmic chaining and the role of partial feedback in online
  nonparametric learning.
\newblock {\em arXiv preprint arXiv:1702.08211}, 2017.

\bibitem{geman1987stochastic}
Stuart Geman and Donald Geman.
\newblock {Stochastic relaxation, Gibbs distributions, and the Bayesian
  restoration of images}.
\newblock In {\em Readings in computer vision}, pages 564--584. Elsevier, 1987.

\bibitem{welling2011bayesian}
Max Welling and Yee~W. Teh.
\newblock Bayesian learning via stochastic gradient {Langevin} dynamics.
\newblock In {\em Proceedings of the 28th International Conference on Machine
  Learning (ICML)}, pages 681--688, 2011.

\bibitem{guedj2019primer}
Benjamin Guedj.
\newblock A primer on {PAC}-bayesian learning.
\newblock {\em arXiv preprint arXiv:1901.05353}, 2019.

\bibitem{audibert2004pac}
Jean-Yves Audibert and Olivier Bousquet.
\newblock {PAC-Bayesian} generic chaining.
\newblock In {\em Advances in neural information processing systems}, pages
  1125--1132, 2004.

\bibitem{raginsky2016information}
Maxim Raginsky, Alexander Rakhlin, Matthew Tsao, Yihong Wu, and Aolin Xu.
\newblock Information-theoretic analysis of stability and bias of learning
  algorithms.
\newblock In {\em 2016 IEEE Information Theory Workshop (ITW)}, pages 26--30.
  IEEE, 2016.

\bibitem{jiao2017dependence}
Jiantao Jiao, Yanjun Han, and Tsachy Weissman.
\newblock Dependence measures bounding the exploration bias for general
  measurements.
\newblock In {\em 2017 IEEE International Symposium on Information Theory
  (ISIT)}, pages 1475--1479. IEEE, 2017.

\bibitem{pensia2018generalization}
Ankit Pensia, Varun Jog, and Po-Ling Loh.
\newblock Generalization error bounds for noisy, iterative algorithms.
\newblock In {\em 2018 IEEE International Symposium on Information Theory
  (ISIT)}, pages 546--550. IEEE, 2018.

\bibitem{bassily2017learners}
Raef Bassily, Shay Moran, Ido Nachum, Jonathan Shafer, and Amir Yehudayoff.
\newblock Learners that use little information.
\newblock {\em arXiv preprint arXiv:1710.05233}, 2017.

\bibitem{bu2019tightening}
Yuheng Bu, Shaofeng Zou, and Venugopal~V. Veeravalli.
\newblock Tightening mutual information based bounds on generalization error.
\newblock {\em arXiv preprint arXiv:1901.04609}, 2019.

\bibitem{dziugaite2017computing}
Gintare~Karolina Dziugaite and Daniel~M. Roy.
\newblock Computing nonvacuous generalization bounds for deep (stochastic)
  neural networks with many more parameters than training data.
\newblock {\em arXiv preprint arXiv:1703.11008}, 2017.

\bibitem{neyshabur2017pac}
Behnam Neyshabur, Srinadh Bhojanapalli, and Nathan Srebro.
\newblock A {PAC-Bayesian} approach to spectrally-normalized margin bounds for
  neural networks.
\newblock {\em arXiv preprint arXiv:1707.09564}, 2017.

\bibitem{zhou2018non}
Wenda Zhou, Victor Veitch, Morgane Austern, Ryan~P. Adams, and Peter Orbanz.
\newblock Non-vacuous generalization bounds at the imagenet scale: a
  {PAC-Bayesian} compression approach.
\newblock {\em arXiv preprint arXiv:1804.05862}, 2018.

\bibitem{dziugaite2018data}
Gintare~Karolina Dziugaite and Daniel~M. Roy.
\newblock Data-dependent {PAC-Bayes} priors via differential privacy.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8430--8441, 2018.

\bibitem{rigollet2012sparse}
Philippe Rigollet and Alexandre~B. Tsybakov.
\newblock Sparse estimation by exponential weighting.
\newblock {\em Statistical Science}, 27(4):558--575, 2012.

\bibitem{zhang1999theoretical}
Tong Zhang.
\newblock Theoretical analysis of a class of randomized regularization methods.
\newblock In {\em Proceedings of the twelfth annual conference on Computational
  learning theory}, pages 156--163. ACM, 1999.

\bibitem{zhang2006e}
Tong Zhang.
\newblock From $\epsilon$-entropy to {KL}-entropy: Analysis of minimum
  information complexity density estimation.
\newblock {\em The Annals of Statistics}, 34(5):2180--2210, 2006.

\bibitem{zhang2006information}
Tong Zhang.
\newblock Information-theoretic upper and lower bounds for statistical
  estimation.
\newblock {\em IEEE Transactions on Information Theory}, 52(4):1307--1321,
  2006.

\bibitem{chaudhari2016entropy}
Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi,
  Christian Borgs, Jennifer Chayes, Levent Sagun, and Riccardo Zecchina.
\newblock Entropy-{SGD}: Biasing gradient descent into wide valleys.
\newblock {\em arXiv preprint arXiv:1611.01838}, 2016.

\bibitem{raginsky2017non}
Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky.
\newblock Non-convex learning via stochastic gradient {Langevin} dynamics: a
  nonasymptotic analysis.
\newblock {\em arXiv preprint arXiv:1702.03849}, 2017.

\bibitem{dziugaite2017entropy}
Gintare~Karolina Dziugaite and Daniel~M. Roy.
\newblock Entropy-{SGD} optimizes the prior of a {PAC-Bayes} bound:
  Generalization properties of entropy-{SGD} and data-dependent priors.
\newblock {\em arXiv preprint arXiv:1712.09376}, 2017.

\bibitem{asadi2017compressing}
Amir~R. Asadi, Emmanuel Abbe, and Sergio Verd{\'u}.
\newblock Compressing data on graphs with clusters.
\newblock In {\em 2017 IEEE International Symposium on Information Theory
  (ISIT)}, pages 1583--1587. IEEE, 2017.

\bibitem{bardenet2017markov}
R{\'e}mi Bardenet, Arnaud Doucet, and Chris Holmes.
\newblock On {Markov chain Monte Carlo} methods for tall data.
\newblock {\em The Journal of Machine Learning Research}, 18(1):1515--1557,
  2017.

\bibitem{Ramon}
Ramon van Handel.
\newblock Probability in high dimension.
\newblock {\em [Online]. Available:
  \url{https://www.princeton.edu/~rvan/APC550.pdf}}, Dec.~21 2016.

\bibitem{Vershynin}
Roman Vershynin.
\newblock {\em High-Dimensional Probability: An Introduction with Applications
  in Data Science}.
\newblock Cambridge Series in Statistical and Probabilistic Mathematics.
  Cambridge University Press, 2018.

\bibitem{talagrand2014upper}
Michel Talagrand.
\newblock {\em Upper and lower bounds for stochastic processes: modern methods
  and classical problems}, volume~60.
\newblock Springer Science \& Business Media, 2014.

\bibitem{Fernique}
Xavier Fernique.
\newblock Evaluations de processus {Gaussiens} composes.
\newblock In {\em Probability in Banach Spaces}, pages 67--83. Springer, 1976.

\bibitem{verdu1998fifty}
Sergio Verd\'{u}.
\newblock Fifty years of {Shannon} theory.
\newblock {\em IEEE Transactions on information theory}, 44(6):2057--2078,
  1998.

\bibitem{ccinlar2011probability}
Erhan {\c{C}}{\i}nlar.
\newblock {\em Probability and stochastics}, volume 261.
\newblock Springer Science \& Business Media, 2011.

\bibitem{bartlett2017spectrally}
Peter~L. Bartlett, Dylan~J. Foster, and Matus~J. Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6240--6249, 2017.

\bibitem{anthony2009neural}
Martin Anthony and Peter~L. Bartlett.
\newblock {\em Neural network learning: Theoretical foundations}.
\newblock Cambridge University Press, 2009.

\bibitem{kuzborskij2019distribution}
Ilja Kuzborskij, Nicol{\`o} Cesa-Bianchi, and Csaba Szepesv{\'a}ri.
\newblock Distribution-dependent analysis of {Gibbs-ERM} principle.
\newblock {\em arXiv preprint arXiv:1902.01846}, 2019.

\bibitem{bercher2012simple}
Jean-Francois Bercher.
\newblock A simple probabilistic construction yielding generalized entropies
  and divergences, escort distributions and q-gaussians.
\newblock {\em Physica A: Statistical Mechanics and its Applications},
  391(19):4460--4469, 2012.

\bibitem{van2014renyi}
Tim Van~Erven and Peter Harremos.
\newblock R{\'e}nyi divergence and {Kullback-Leibler} divergence.
\newblock {\em IEEE Transactions on Information Theory}, 60(7):3797--3820,
  2014.

\bibitem{neal1992bayesian}
Radford~M. Neal.
\newblock Bayesian training of backpropagation networks by the hybrid {Monte
  Carlo} method.
\newblock Technical report, Citeseer, 1992.

\bibitem{chen2014stochastic}
Tianqi Chen, Emily Fox, and Carlos Guestrin.
\newblock Stochastic gradient {Hamiltonian Monte Carlo}.
\newblock In {\em International Conference on Machine Learning}, pages
  1683--1691, 2014.

\bibitem{alquier2016properties}
Pierre Alquier, James Ridgway, and Nicolas Chopin.
\newblock On the properties of variational approximations of {Gibbs}
  posteriors.
\newblock {\em The Journal of Machine Learning Research}, 17(1):8374--8414,
  2016.

\bibitem{Cover}
Thomas~M. Cover and Joy~A. Thomas.
\newblock {\em Elements of Information Theory}.
\newblock John Wiley \& Sons, 2012.

\bibitem{verdu2015alpha}
Sergio Verd{\'u}.
\newblock $\alpha$-mutual information.
\newblock In {\em 2015 Information Theory and Applications Workshop (ITA)},
  pages 1--6. IEEE, 2015.

\bibitem{gao2017properties}
Bolin Gao and Lacra Pavel.
\newblock On the properties of the softmax function with application in game
  theory and reinforcement learning.
\newblock {\em arXiv preprint arXiv:1704.00805}, 2017.

\end{thebibliography}
