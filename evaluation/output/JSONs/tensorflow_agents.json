{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:23:52"}, "code_repository": [{"result": {"value": "https://github.com/tensorflow/agents", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "tensorflow", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2018-11-17T00:29:12Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-12-21T14:28:15Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "license": [{"result": {"value": "https://api.github.com/licenses/apache-2.0", "type": "License", "name": "Apache License 2.0", "url": "https://api.github.com/licenses/apache-2.0", "spdx_id": "Apache-2.0"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Copyright 2020 The TF-Agents Authors.  All rights reserved.\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        https://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2020 The TF-Agents Authors\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       https://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/LICENSE"}], "description": [{"result": {"value": "TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "name": [{"result": {"value": "agents", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "tensorflow/agents", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/tensorflow/agents/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/tensorflow/agents/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 2650, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "bandits, contextual-bandits, dqn, multi-armed-bandits, reinforcement-learning, rl-algorithms, tensorflow, tf-agents", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 717, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/tensorflow/agents/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 5047029}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Shell", "name": "Shell", "type": "Programming_language", "size": 10295}, "confidence": 1, "technique": "GitHub_API"}], "has_script_file": [{"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/tests_release.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/pip_pkg.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "code_of_conduct": [{"result": {"value": "# TensorFlow Code of Conduct\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n*   Using welcoming and inclusive language.\n*   Being respectful of differing viewpoints and experiences.\n*   Gracefully accepting constructive criticism.\n*   Focusing on what is best for the community.\n*   Showing empathy towards other community members.\n\nExamples of unacceptable behavior by participants include:\n\n*   The use of sexualized language or imagery and unwelcome sexual attention or\n    advances.\n*   Trolling, insulting/derogatory comments, and personal or political attacks.\n*   Public or private harassment.\n*   Publishing others' private information, such as a physical or electronic\n    address, without explicit permission.\n*   Conduct which could reasonably be considered inappropriate for the forum in\n    which it occurs.\n\nAll TensorFlow forums and spaces are meant for professional interactions, and any behavior which could reasonably be considered inappropriate in a professional setting is unacceptable.\n\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n\n## Scope\n\nThis Code of Conduct applies to all content on tensorflow.org, TensorFlow\u2019s GitHub organization, or any other official TensorFlow web presence allowing for community interactions, as well as at all official TensorFlow events, whether offline or online.\n\nThe Code of Conduct also applies within project spaces and in public spaces whenever an individual is representing TensorFlow or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed or de facto representative at an online or offline event.\n\n\n## Conflict Resolution\n\nConflicts in an open source project can take many forms, from someone having a bad day and using harsh and hurtful language in the issue queue, to more serious instances such as sexist/racist statements or threats of violence, and everything in between.\n\nIf the behavior is threatening or harassing, or for other reasons requires immediate escalation, please see below.\n\nHowever, for the vast majority of issues, we aim to empower individuals to first resolve conflicts themselves, asking for help when needed, and only after that fails to escalate further. This approach gives people more control over the outcome of their dispute.\n\nIf you are experiencing or witnessing conflict, we ask you to use the following escalation strategy to address the conflict:\n\n1.  Address the perceived conflict directly with those involved, preferably in a\n    real-time medium.\n2.  If this fails, get a third party (e.g. a mutual friend, and/or someone with\n    background on the issue, but not involved in the conflict) to intercede.\n3.  If you are still unable to resolve the conflict, and you believe it rises to\n    harassment or another code of conduct violation, report it.\n\n## Reporting Violations\n\nViolations of the Code of Conduct can be reported to TensorFlow\u2019s Project Stewards, Edd Wilder-James (ewj@google.com) and Sarah Novotny (sarahnovotny@google.com). The Project Steward will determine whether the Code of Conduct was violated, and will issue an appropriate sanction, possibly including a written warning or expulsion from the project, project sponsored spaces, or project forums. We ask that you make a good-faith effort to resolve your conflict via the conflict resolution policy before submitting a report.\n\nViolations of the Code of Conduct can occur in any setting, even those unrelated to the project. We will only consider complaints about conduct that has occurred within one year of the report.\n\n\n## Enforcement\n\nIf the Project Stewards receive a report alleging a violation of the Code of Conduct, the Project Stewards will notify the accused of the report, and provide them an opportunity to discuss the report before a sanction is issued. The Project Stewards will do their utmost to keep the reporter anonymous. If the act is ongoing (such as someone engaging in harassment), or involves a threat to anyone's safety (e.g. threats of violence), the Project Stewards may issue sanctions without notice.\n\n\n## Attribution\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://contributor-covenant.org/version/1/4, and includes some aspects of the Geek Feminism Code of Conduct and the Drupal Code of Conduct.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/CODE_OF_CONDUCT.md"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "contributing_guidelines": [{"result": {"value": "# Contributing\n\nInterested in contributing to TF Agents? We appreciate all kinds\nof help!\n\n## Pull Requests\n\nWe gladly welcome [pull requests](\nhttps://help.github.com/articles/about-pull-requests/).\n\nBefore making any changes, we recommend opening an issue (if it\ndoesn't already exist) and discussing your proposed changes. This will\nlet us give you advice on the proposed changes. If the changes are\nminor, then feel free to make them without discussion.\n\nWant to contribute but not sure of what? Here are a few suggestions:\n\n1. Add a new example, colab, or tutorial.  These are a great way to familiarize\n   yourself and others with TF Agents.\n\n\n2. Solve an [existing issue](https://github.com/tensorflow/agents/issues).\n  These range from low-level software bugs to higher-level design problems.\n  Check out the label [good first issue](\n  https://github.com/tensorflow/agents/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22).\n\nAll submissions, including submissions by project members, require review. After\na pull request is approved, we merge it. Note our merging process differs\nfrom GitHub in that we pull and submit the change into an internal version\ncontrol system. This system automatically pushes a git commit to the GitHub\nrepository (with credit to the original author) and closes the pull request.\n\n## Style\n\nSee the [TF Agents style guide](STYLE_GUIDE.md).\n\n## Unit tests\n\nAll TF Agents code-paths must be unit-tested.  See existing unit tests for\nrecommended test setup.\n\nUnit tests ensure new features (a) work correctly and (b) guard against future\nbreaking changes (thus lower maintenance costs).\n\nTo run existing unit-tests, use the command:\n\n\n```shell\npython setup.py test\n```\n\nfrom the root of the `tf_agents` repository, ideally inside a virtualenv.\nThe tests will run with CPU or GPU, depending on which version of TensorFlow\nyou have installed.\n\n\n## Contributor License Agreement\n\nContributions to this project must be accompanied by a Contributor License\nAgreement. You (or your employer) retain the copyright to your contribution;\nthis simply gives us permission to use and redistribute your contributions as\npart of the project. Head over to <https://cla.developers.google.com/> to see\nyour current agreements on file or to sign a new one.\n\nYou generally only need to submit a CLA once, so if you've already submitted one\n(even if it was for a different project), you probably don't need to do it\nagain.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/CONTRIBUTING.md"}, {"result": {"value": "We're eager to collaborate with you! See [`CONTRIBUTING.md`](CONTRIBUTING.md)\nfor a guide on how to contribute. This project adheres to TensorFlow's\n[code of conduct](CODE_OF_CONDUCT.md). By participating, you are expected to\nuphold this code.\n\n<a id='Releases'></a>\n", "type": "Text_excerpt", "original_header": "Contributing", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}], "documentation": [{"result": {"value": "https://github.com/tensorflow/agents/tree/master/docs", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "executable_example": [{"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/2_environments_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/2_environments_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/intro_bandit.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/intro_bandit.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/8_networks_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/8_networks_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/per_arm_bandits_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/per_arm_bandits_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/1_dqn_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/1_dqn_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/bandits_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/bandits_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/ranking_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/ranking_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/0_intro_rl.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/0_intro_rl.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/4_drivers_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/4_drivers_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/6_reinforce_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/6_reinforce_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/5_replay_buffers_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/5_replay_buffers_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/3_policies_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/3_policies_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/9_c51_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/9_c51_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/10_checkpointer_policysaver_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/10_checkpointer_policysaver_tutorial.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/7_SAC_minitaur_tutorial.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/docs/tutorials/7_SAC_minitaur_tutorial.ipynb"}], "usage": [{"result": {"value": "[![PyPI tf-agents](https://badge.fury.io/py/tf-agents.svg)](https://badge.fury.io/py/tf-agents)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/tf-agents)\n\n[TF-Agents](https://github.com/tensorflow/agents) makes implementing, deploying,\nand testing new Bandits and RL algorithms easier. It provides well tested and\nmodular components that can be modified and extended. It enables fast code\niteration, with good test integration and benchmarking.\n\nTo get started, we recommend checking out one of our Colab tutorials. If you\nneed an intro to RL (or a quick recap),\n[start here](docs/tutorials/0_intro_rl.ipynb). Otherwise, check out our\n[DQN tutorial](docs/tutorials/1_dqn_tutorial.ipynb) to get an agent up and\nrunning in the Cartpole environment. API documentation for the current stable\nrelease is on\n[tensorflow.org](https://www.tensorflow.org/agents/api_docs/python/tf_agents).\n\nTF-Agents is under active development and interfaces may change at any time.\nFeedback and comments are welcome.\n", "type": "Text_excerpt", "original_header": "TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "<a href='#Agents'>Agents</a><br>\n<a href='#Tutorials'>Tutorials</a><br>\n<a href='#Multi-Armed Bandits'>Multi-Armed Bandits</a><br>\n<a href='#Examples'>Examples</a><br>\n<a href='#Installation'>Installation</a><br>\n<a href='#Contributing'>Contributing</a><br>\n<a href='#Releases'>Releases</a><br>\n<a href='#Principles'>Principles</a><br>\n<a href='#Contributors'>Contributors</a><br>\n<a href='#Citation'>Citation</a><br>\n<a href='#Disclaimer'>Disclaimer</a><br>\n\n<a id='Agents'></a>\n", "type": "Text_excerpt", "original_header": "Table of contents", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "In TF-Agents, the core elements of RL algorithms are implemented as `Agents`. An\nagent encompasses two main responsibilities: defining a Policy to interact with\nthe Environment, and how to learn/train that Policy from collected experience.\n\nCurrently the following algorithms are available under TF-Agents:\n\n*   [DQN: __Human level control through deep reinforcement learning__ Mnih et\n    al., 2015](https://deepmind.com/research/dqn/)\n*   [DDQN: __Deep Reinforcement Learning with Double Q-learning__ Hasselt et\n    al., 2015](https://arxiv.org/abs/1509.06461)\n*   [DDPG: __Continuous control with deep reinforcement learning__ Lillicrap et\n    al., 2015](https://arxiv.org/abs/1509.02971)\n*   [TD3: __Addressing Function Approximation Error in Actor-Critic Methods__\n    Fujimoto et al., 2018](https://arxiv.org/abs/1802.09477)\n*   [REINFORCE: __Simple Statistical Gradient-Following Algorithms for\n    Connectionist Reinforcement Learning__ Williams,\n    1992](https://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)\n*   [PPO: __Proximal Policy Optimization Algorithms__ Schulman et al., 2017](https://arxiv.org/abs/1707.06347)\n*   [SAC: __Soft Actor Critic__ Haarnoja et al., 2018](https://arxiv.org/abs/1812.05905)\n\n<a id='Tutorials'></a>\n", "type": "Text_excerpt", "original_header": "Agents", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "See [`docs/tutorials/`](docs/tutorials) for tutorials on the major components\nprovided.\n\n<a id='Multi-Armed Bandits'></a>\n", "type": "Text_excerpt", "original_header": "Tutorials", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "The TF-Agents library contains a comprehensive Multi-Armed Bandits suite,\nincluding Bandits environments and agents. RL agents can also be used on Bandit\nenvironments. There is a tutorial in\n[`bandits_tutorial.ipynb`](https://github.com/tensorflow/agents/tree/master/docs/tutorials/bandits_tutorial.ipynb).\nand ready-to-run examples in\n[`tf_agents/bandits/agents/examples/v2`](https://github.com/tensorflow/agents/tree/master/tf_agents/bandits/agents/examples/v2).\n\n<a id='Examples'></a>\n", "type": "Text_excerpt", "original_header": "Multi-Armed Bandits", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "End-to-end examples training agents can be found under each agent directory.\ne.g.:\n\n*   DQN:\n    [`tf_agents/agents/dqn/examples/v2/train_eval.py`](https://github.com/tensorflow/agents/tree/master/tf_agents/agents/dqn/examples/v2/train_eval.py)\n\n<a id='Installation'></a>\n", "type": "Text_excerpt", "original_header": "Examples", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "Run the commands below to install the most recent stable release. API\ndocumentation for the release is on\n[tensorflow.org](https://www.tensorflow.org/agents/api_docs/python/tf_agents).\n\n```shell\n$ pip install --user tf-agents[reverb]\n\n# Use keras-2\n$ export TF_USE_LEGACY_KERAS=1\n# Use this tag get the matching examples and colabs.\n$ git clone https://github.com/tensorflow/agents.git\n$ cd agents\n$ git checkout v0.18.0\n```\n\nIf you want to install TF-Agents with versions of Tensorflow or\n[Reverb](https://github.com/deepmind/reverb) that are flagged as not compatible\nby the pip dependency check, use the following pattern below at your own risk.\n\n```shell\n$ pip install --user tensorflow\n$ pip install --user tf-keras\n$ pip install --user dm-reverb\n$ pip install --user tf-agents\n```\n\nIf you want to use TF-Agents with TensorFlow 1.15 or 2.0, install version 0.3.0:\n\n```shell\n# Newer versions of tensorflow-probability require newer versions of TensorFlow.\n$ pip install tensorflow-probability==0.8.0\n$ pip install tf-agents==0.3.0\n```\n", "type": "Text_excerpt", "original_header": "Stable", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.", "Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "Nightly builds include newer features, but may be less stable than the versioned\nreleases. The nightly build is pushed as `tf-agents-nightly`. We suggest\ninstalling nightly versions of TensorFlow (`tf-nightly`) and TensorFlow\nProbability (`tfp-nightly`) as those are the versions TF-Agents nightly are\ntested against.\n\nTo install the nightly build version, run the following:\n\n```shell\n# Use keras-2\n$ export TF_USE_LEGACY_KERAS=1\n\n# `--force-reinstall helps guarantee the right versions.\n$ pip install --user --force-reinstall tf-nightly\n$ pip install --user --force-reinstall tf-keras-nightly\n$ pip install --user --force-reinstall tfp-nightly\n$ pip install --user --force-reinstall dm-reverb-nightly\n\n# Installing with the `--upgrade` flag ensures you'll get the latest version.\n$ pip install --user --upgrade tf-agents-nightly\n```\n", "type": "Text_excerpt", "original_header": "Nightly", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.", "Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "After cloning the repository, the dependencies can be installed by running `pip\ninstall -e .[tests]`. TensorFlow needs to be installed independently: `pip\ninstall --user tf-nightly`.\n\n<a id='Contributing'></a>\n", "type": "Text_excerpt", "original_header": "From GitHub", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.", "Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "TF Agents has stable and nightly releases. The nightly releases are often fine\nbut can have issues due to upstream libraries being in flux. The table below\nlists the version(s) of TensorFlow that align with each TF Agents' release.\nRelease versions of interest:\n\n  * 0.19.0 supports tensorflow-2.15.0.\n  * 0.18.0 dropped Python 3.8 support.\n  * 0.16.0 is the first version to support Python 3.11.\n  * 0.15.0 is the last release compatible with Python 3.7.\n  * If using numpy < 1.19, then use TF-Agents 0.15.0 or earlier.\n  * 0.9.0 is the last release compatible with Python 3.6.\n  * 0.3.0 is the last release compatible with Python 2.x.\n\nRelease | Branch / Tag                                               | TensorFlow Version | dm-reverb Version\n------- | ---------------------------------------------------------- | ------------------ | -----------\nNightly | [master](https://github.com/tensorflow/agents)             | tf-nightly         | dm-reverb-nightly\n0.19.0  | [v0.19.0](https://github.com/tensorflow/agents/tree/v0.19.0) | 2.15.0           | 0.14.0\n0.18.0  | [v0.18.0](https://github.com/tensorflow/agents/tree/v0.18.0) | 2.14.0           | 0.13.0\n0.17.0  | [v0.17.0](https://github.com/tensorflow/agents/tree/v0.17.0) | 2.13.0           | 0.12.0\n0.16.0  | [v0.16.0](https://github.com/tensorflow/agents/tree/v0.16.0) | 2.12.0           | 0.11.0\n0.15.0  | [v0.15.0](https://github.com/tensorflow/agents/tree/v0.15.0) | 2.11.0           | 0.10.0\n0.14.0  | [v0.14.0](https://github.com/tensorflow/agents/tree/v0.14.0) | 2.10.0           | 0.9.0\n0.13.0  | [v0.13.0](https://github.com/tensorflow/agents/tree/v0.13.0) | 2.9.0            | 0.8.0\n0.12.0  | [v0.12.0](https://github.com/tensorflow/agents/tree/v0.12.0) | 2.8.0            | 0.7.0\n0.11.0  | [v0.11.0](https://github.com/tensorflow/agents/tree/v0.11.0) | 2.7.0            | 0.6.0\n0.10.0  | [v0.10.0](https://github.com/tensorflow/agents/tree/v0.10.0) | 2.6.0            |\n0.9.0   | [v0.9.0](https://github.com/tensorflow/agents/tree/v0.9.0) | 2.6.0              |\n0.8.0   | [v0.8.0](https://github.com/tensorflow/agents/tree/v0.8.0) | 2.5.0              |\n0.7.1   | [v0.7.1](https://github.com/tensorflow/agents/tree/v0.7.1) | 2.4.0              |\n0.6.0   | [v0.6.0](https://github.com/tensorflow/agents/tree/v0.6.0) | 2.3.0              |\n0.5.0   | [v0.5.0](https://github.com/tensorflow/agents/tree/v0.5.0) | 2.2.0              |\n0.4.0   | [v0.4.0](https://github.com/tensorflow/agents/tree/v0.4.0) | 2.1.0              |\n0.3.0   | [v0.3.0](https://github.com/tensorflow/agents/tree/v0.3.0) | 1.15.0 and 2.0.0.  |\n\n<a id='Principles'></a>\n", "type": "Text_excerpt", "original_header": "Releases", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "This project adheres to [Google's AI principles](PRINCIPLES.md). By\nparticipating, using or contributing to this project you are expected to adhere\nto these principles.\n\n\n<a id='Contributors'></a>\n", "type": "Text_excerpt", "original_header": "Principles", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "This is not an official Google product.\n", "type": "Text_excerpt", "original_header": "Disclaimer", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}], "installation": [{"result": {"value": "TF-Agents publishes nightly and stable builds. For a list of releases read the\n<a href='#Releases'>Releases</a> section. The commands below cover installing\nTF-Agents stable and nightly from [pypi.org](https://pypi.org) as well as from a\nGitHub clone.\n\n> :warning: If using Reverb (replay buffer), which is very common,\nTF-Agents will only work with Linux.\n\n> Note: Python 3.11 requires pygame 2.1.3+.\n", "type": "Text_excerpt", "original_header": "Installation", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "Run the commands below to install the most recent stable release. API\ndocumentation for the release is on\n[tensorflow.org](https://www.tensorflow.org/agents/api_docs/python/tf_agents).\n\n```shell\n$ pip install --user tf-agents[reverb]\n\n# Use keras-2\n$ export TF_USE_LEGACY_KERAS=1\n# Use this tag get the matching examples and colabs.\n$ git clone https://github.com/tensorflow/agents.git\n$ cd agents\n$ git checkout v0.18.0\n```\n\nIf you want to install TF-Agents with versions of Tensorflow or\n[Reverb](https://github.com/deepmind/reverb) that are flagged as not compatible\nby the pip dependency check, use the following pattern below at your own risk.\n\n```shell\n$ pip install --user tensorflow\n$ pip install --user tf-keras\n$ pip install --user dm-reverb\n$ pip install --user tf-agents\n```\n\nIf you want to use TF-Agents with TensorFlow 1.15 or 2.0, install version 0.3.0:\n\n```shell\n# Newer versions of tensorflow-probability require newer versions of TensorFlow.\n$ pip install tensorflow-probability==0.8.0\n$ pip install tf-agents==0.3.0\n```\n", "type": "Text_excerpt", "original_header": "Stable", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.", "Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "Nightly builds include newer features, but may be less stable than the versioned\nreleases. The nightly build is pushed as `tf-agents-nightly`. We suggest\ninstalling nightly versions of TensorFlow (`tf-nightly`) and TensorFlow\nProbability (`tfp-nightly`) as those are the versions TF-Agents nightly are\ntested against.\n\nTo install the nightly build version, run the following:\n\n```shell\n# Use keras-2\n$ export TF_USE_LEGACY_KERAS=1\n\n# `--force-reinstall helps guarantee the right versions.\n$ pip install --user --force-reinstall tf-nightly\n$ pip install --user --force-reinstall tf-keras-nightly\n$ pip install --user --force-reinstall tfp-nightly\n$ pip install --user --force-reinstall dm-reverb-nightly\n\n# Installing with the `--upgrade` flag ensures you'll get the latest version.\n$ pip install --user --upgrade tf-agents-nightly\n```\n", "type": "Text_excerpt", "original_header": "Nightly", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.", "Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "After cloning the repository, the dependencies can be installed by running `pip\ninstall -e .[tests]`. TensorFlow needs to be installed independently: `pip\ninstall --user tf-nightly`.\n\n<a id='Contributing'></a>\n", "type": "Text_excerpt", "original_header": "From GitHub", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.", "Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}], "contributors": [{"result": {"value": "\nWe would like to recognize the following individuals for their code\ncontributions, discussions, and other work to make the TF-Agents library.\n\n* James Davidson\n* Ethan Holly\n* Toby Boyd\n* Summer Yue\n* Robert Ormandi\n* Kuang-Huei Lee\n* Alexa Greenberg\n* Amir Yazdanbakhsh\n* Yao Lu\n* Gaurav Jain\n* Christof Angermueller\n* Mark Daoust\n* Adam Wood\n\n\n<a id='Citation'></a>\n", "type": "Text_excerpt", "original_header": "Contributors", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}], "citation": [{"result": {"value": "If you use this code, please cite it as:\n\n```\n@misc{TFAgents,\n  title = {{TF-Agents}: A library for Reinforcement Learning in TensorFlow},\n  author = {Sergio Guadarrama and Anoop Korattikara and Oscar Ramirez and\n     Pablo Castro and Ethan Holly and Sam Fishman and Ke Wang and\n     Ekaterina Gonina and Neal Wu and Efi Kokiopoulou and Luciano Sbaiz and\n     Jamie Smith and G\u00e1bor Bart\u00f3k and Jesse Berent and Chris Harris and\n     Vincent Vanhoucke and Eugene Brevdo},\n  howpublished = {\\url{https://github.com/tensorflow/agents}},\n  url = \"https://github.com/tensorflow/agents\",\n  year = 2018,\n  note = \"[Online; accessed 25-June-2019]\"\n}\n```\n\n<a id='Disclaimer'></a>\n", "type": "Text_excerpt", "original_header": "Citation", "parent_header": ["TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"value": "@misc{TFAgents,\n  title = {{TF-Agents}: A library for Reinforcement Learning in TensorFlow},\n  author = {Sergio Guadarrama and Anoop Korattikara and Oscar Ramirez and\n     Pablo Castro and Ethan Holly and Sam Fishman and Ke Wang and\n     Ekaterina Gonina and Neal Wu and Efi Kokiopoulou and Luciano Sbaiz and\n     Jamie Smith and G\u00e1bor Bart\u00f3k and Jesse Berent and Chris Harris and\n     Vincent Vanhoucke and Eugene Brevdo},\n  howpublished = {\\url{https://github.com/tensorflow/agents}},\n  url = \"https://github.com/tensorflow/agents\",\n  year = 2018,\n  note = \"[Online; accessed 25-June-2019]\"\n}", "type": "Text_excerpt", "format": "bibtex"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}], "application_domain": [{"result": {"type": "String", "value": "Reinforcement Learning"}, "confidence": 0.996295676707309, "technique": "supervised_classification"}], "full_title": [{"result": {"type": "String", "value": "TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}], "related_papers": [{"result": {"type": "Url", "value": "https://arxiv.org/abs/1812.05905"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1802.09477"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1509.02971"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1509.06461"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1707.06347"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"}]}