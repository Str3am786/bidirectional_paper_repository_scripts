{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 18:48:02"}, "code_repository": [{"result": {"value": "https://github.com/tensorflow/tensor2tensor", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "tensorflow", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2017-06-15T16:57:39Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-12-21T17:30:11Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "license": [{"result": {"value": "https://api.github.com/licenses/apache-2.0", "type": "License", "name": "Apache License 2.0", "url": "https://api.github.com/licenses/apache-2.0", "spdx_id": "Apache-2.0"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/LICENSE"}], "description": [{"result": {"value": "Library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research.", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Here's a walkthrough training a good English-to-German translation\nmodel using the Transformer model from [*Attention Is All You\nNeed*](https://arxiv.org/abs/1706.03762) on WMT data.\n\n```\npip install tensor2tensor\n\n# See what problems, models, and hyperparameter sets are available.\n# You can easily swap between them (and add new ones).\nt2t-trainer --registry_help\n\nPROBLEM=translate_ende_wmt32k\nMODEL=transformer\nHPARAMS=transformer_base_single_gpu\n\nDATA_DIR=$HOME/t2t_data\nTMP_DIR=/tmp/t2t_datagen\nTRAIN_DIR=$HOME/t2t_train/$PROBLEM/$MODEL-$HPARAMS\n\nmkdir -p $DATA_DIR $TMP_DIR $TRAIN_DIR\n\n# Generate data\nt2t-datagen \\\n  --data_dir=$DATA_DIR \\\n  --tmp_dir=$TMP_DIR \\\n  --problem=$PROBLEM\n\n# Train\n# *  If you run out of memory, add --hparams='batch_size=1024'.\nt2t-trainer \\\n  --data_dir=$DATA_DIR \\\n  --problem=$PROBLEM \\\n  --model=$MODEL \\\n  --hparams_set=$HPARAMS \\\n  --output_dir=$TRAIN_DIR\n\n# Decode\n\nDECODE_FILE=$DATA_DIR/decode_this.txt\necho \"Hello world\" >> $DECODE_FILE\necho \"Goodbye world\" >> $DECODE_FILE\necho -e 'Hallo Welt\\nAuf Wiedersehen Welt' > ref-translation.de\n\nBEAM_SIZE=4\nALPHA=0.6\n\nt2t-decoder \\\n  --data_dir=$DATA_DIR \\\n  --problem=$PROBLEM \\\n  --model=$MODEL \\\n  --hparams_set=$HPARAMS \\\n  --output_dir=$TRAIN_DIR \\\n  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n  --decode_from_file=$DECODE_FILE \\\n  --decode_to_file=translation.en\n\n# See the translations\ncat translation.en\n\n# Evaluate the BLEU score\n# Note: Report this BLEU score in papers, not the internal approx_bleu metric.\nt2t-bleu --translation=translation.en --reference=ref-translation.de\n```\n", "type": "Text_excerpt", "original_header": "Walkthrough", "parent_header": ["Tensor2Tensor", "Basics"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"value": "* Many state of the art and baseline models are built-in and new models can be\n  added easily (open an issue or pull request!).\n* Many datasets across modalities - text, audio, image - available for\n  generation and use, and new ones can be added easily (open an issue or pull\n  request for public datasets!).\n* Models can be used with any dataset and input mode (or even multiple); all\n  modality-specific processing (e.g. embedding lookups for text tokens) is done\n  with `bottom` and `top` transformations, which are specified per-feature in the\n  model.\n* Support for multi-GPU machines and synchronous (1 master, many workers) and\n  asynchronous (independent workers synchronizing through a parameter server)\n  [distributed training](https://tensorflow.github.io/tensor2tensor/distributed_training.html).\n* Easily swap amongst datasets and models by command-line flag with the data\n  generation script `t2t-datagen` and the training script `t2t-trainer`.\n* Train on [Google Cloud ML](https://tensorflow.github.io/tensor2tensor/cloud_mlengine.html) and [Cloud TPUs](https://tensorflow.github.io/tensor2tensor/cloud_tpu.html).\n", "type": "Text_excerpt", "original_header": "Features", "parent_header": ["Tensor2Tensor", "Basics"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "[Tensor2Tensor](https://github.com/tensorflow/tensor2tensor), or\n[T2T](https://github.com/tensorflow/tensor2tensor) for short, is a library\nof deep learning models and datasets designed to make deep learning more\naccessible and [accelerate ML\nresearch](https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html). \n\nT2T was developed by researchers and engineers in the\n[Google Brain team](https://research.google.com/teams/brain/) and a community\nof users. It is now deprecated &mdash; we keep it running and welcome\nbug-fixes, but encourage users to use the successor library [Trax](https://github.com/google/trax).\n \n", "original_header": "Tensor2Tensor"}, "confidence": 0.9540967699018195, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "Below we list a number of tasks that can be solved with T2T when\nyou train the appropriate model on the appropriate problem.\nWe give the problem and model below and we suggest a setting of\nhyperparameters that we know works well in our setup. We usually\nrun either on Cloud TPUs or on 8-GPU machines; you might need\nto modify the hyperparameters if you run on a different setup.\n \n", "original_header": "Suggested Datasets and Models"}, "confidence": 0.8672090136426871, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "For evaluating mathematical expressions at the character level involving addition, subtraction and multiplication of both positive and negative decimal numbers with variable digits assigned to symbolic variables, use \nYou can try solving the problem with different transformer models and hyperparameters as described in the [paper](https://arxiv.org/abs/1812.02825):\n* Standard transformer:\n`--model=transformer`\n`--hparams_set=transformer_tiny`\n* Universal transformer:\n`--model=universal_transformer`\n`--hparams_set=universal_transformer_tiny`\n* Adaptive universal transformer:\n`--model=universal_transformer`\n`--hparams_set=adaptive_universal_transformer_tiny`\n \n", "original_header": "Mathematical Language Understanding"}, "confidence": 0.9043281621935009, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "For image classification, we have a number of standard data-sets: \nFor ImageNet, we suggest to use the ResNet or Xception, i.e.,\nuse `--model=resnet --hparams_set=resnet_50` or\n`--model=xception --hparams_set=xception_base`.\nResnet should get to above 76% top-1 accuracy on ImageNet. \nFor CIFAR and MNIST, we suggest to try the shake-shake model:\n`--model=shake_shake --hparams_set=shakeshake_big`.\nThis setting trained for `--train_steps=700000` should yield\nclose to 97% accuracy on CIFAR-10.\n \n", "original_header": "Image Classification"}, "confidence": 0.9119337465326735, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "We suggest to use the Image Transformer, i.e., `--model=imagetransformer`, or\nthe Image Transformer Plus, i.e., `--model=imagetransformerpp` that uses\ndiscretized mixture of logistics, or variational auto-encoder, i.e.,\n`--model=transformer_ae`.\nFor CIFAR-10, using `--hparams_set=imagetransformer_cifar10_base` or\n`--hparams_set=imagetransformer_cifar10_base_dmol` yields 2.90 bits per\ndimension. For Imagenet-32, using\n`--hparams_set=imagetransformer_imagenet32_base` yields 3.77 bits per dimension.\n \n", "original_header": "Image Generation"}, "confidence": 0.9479341933523853, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "For language modeling, we have these data-sets in T2T: \nWe suggest to start with `--model=transformer` on this task and use\n`--hparams_set=transformer_small` for PTB and\n`--hparams_set=transformer_base` for LM1B.\n \n", "original_header": "Language Modeling"}, "confidence": 0.964942189325614, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "For the task of recognizing the sentiment of a sentence, use \nWe suggest to use `--model=transformer_encoder` here and since it is\na small data-set, try `--hparams_set=transformer_tiny` and train for\nfew steps (e.g., `--train_steps=2000`).\n \n", "original_header": "Sentiment Analysis"}, "confidence": 0.9228830004469937, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "For summarizing longer text into shorter one we have these data-sets: \n* CNN/DailyMail articles summarized into a few sentences:\n  `--problem=summarize_cnn_dailymail32k` \nWe suggest to use `--model=transformer` and\n`--hparams_set=transformer_prepend` for this task.\nThis yields good ROUGE scores.\n \n", "original_header": "Summarization"}, "confidence": 0.8737233731212958, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "There are a number of translation data-sets in T2T: \nFor all translation problems, we suggest to try the Transformer model:\n`--model=transformer`. At first it is best to try the base setting,\n`--hparams_set=transformer_base`. When trained on 8 GPUs for 300K steps\nthis should reach a BLEU score of about 28 on the English-German data-set,\nwhich is close to state-of-the art. If training on a single GPU, try the\n`--hparams_set=transformer_base_single_gpu` setting. For very good results\nor larger data-sets (e.g., for English-French), try the big model\nwith `--hparams_set=transformer_big`. \nSee this [example](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/Transformer_translate.ipynb) to know how the translation works.\n \n", "original_header": "Translation"}, "confidence": 0.9130723379685591, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "**`T2TModel`s** define the core tensor-to-tensor computation. They apply a\ndefault transformation to each input and output so that models may deal with\nmodality-independent tensors (e.g. embeddings at the input; and a linear\ntransform at the output to produce logits for a softmax over classes). All\nmodels are imported in the\n[`models` subpackage](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/models/__init__.py),\ninherit from [`T2TModel`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/t2t_model.py),\nand are registered with\n[`@registry.register_model`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/registry.py).\n \n", "original_header": "Models"}, "confidence": 0.9801717780984365, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "The **trainer** binary is the entrypoint for training, evaluation, and\ninference. Users can easily switch between problems, models, and hyperparameter\nsets by using the `--model`, `--problem`, and `--hparams_set` flags. Specific\nhyperparameters can be overridden with the `--hparams` flag. `--schedule` and\nrelated flags control local and distributed training/evaluation\n([distributed training documentation](https://github.com/tensorflow/tensor2tensor/tree/master/docs/distributed_training.md)).\n \n", "original_header": "Trainer"}, "confidence": 0.977906718271724, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "To add a new dataset, subclass\n[`Problem`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/problem.py)\nand register it with `@registry.register_problem`. See\n[`TranslateEndeWmt8k`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/translate_ende.py)\nfor an example. Also see the [data generators\nREADME](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/README.md).\n \n", "original_header": "Adding a dataset"}, "confidence": 0.9630382004612211, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "Tensor2Tensor was used to develop a number of state-of-the-art models\nand deep learning methods. Here we list some papers that were based on T2T\nfrom the start and benefited from its features and architecture in ways\ndescribed in the [Google Research Blog post introducing\nT2T](https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html). \n*NOTE: This is not an official Google product.*\n \n", "original_header": "Papers"}, "confidence": 0.9529811568456275, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "name": [{"result": {"value": "tensor2tensor", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "tensorflow/tensor2tensor", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/tensorflow/tensor2tensor/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/tensorflow/tensor2tensor/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 14424, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "deep-learning, machine-learning, machine-translation, reinforcement-learning, tpu", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 3394, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/tensorflow/tensor2tensor/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 5109591}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Jupyter Notebook", "name": "Jupyter Notebook", "type": "Programming_language", "size": 2859453}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "JavaScript", "name": "JavaScript", "type": "Programming_language", "size": 78408}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "HTML", "name": "HTML", "type": "Programming_language", "size": 34684}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "C++", "name": "C++", "type": "Programming_language", "size": 32584}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Shell", "name": "Shell", "type": "Programming_language", "size": 11941}, "confidence": 1, "technique": "GitHub_API"}], "releases": [{"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/27648928", "tag": "v1.15.7", "name": "v1.15.7", "author": {"name": "afrozenator", "type": "User"}, "description": " * Multistep Adam Optimizer many thanks to @AgoloCuongHoang for contributing in #1773 !\r\n * Residual Shuffle-Exchange Network thanks to @EmilsOzolins in #1805 !\r\n * Not pinning the gym version.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.15.7", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.15.7", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.15.7", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/27648928", "release_id": 27648928, "date_created": "2020-06-17T08:19:05Z", "date_published": "2020-06-17T16:10:01Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/27140820", "tag": "v1.15.6", "name": "v1.15.6", "author": {"name": "afrozenator", "type": "User"}, "description": "Added basic support for TF2 modeling in f65b5e4e0be50b284f9b21d56d3d2a46792cdecf thanks to @rjpower !\r\n\r\nOther misc fixes:\r\n - Fixing feature encoder for tf.string variable length features.\r\n - adding hparam to make encoder self-attention optional.\r\n - Documentation update, thanks @w-hat \r\n\r\n", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.15.6", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.15.6", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.15.6", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/27140820", "release_id": 27140820, "date_created": "2020-06-02T14:49:04Z", "date_published": "2020-06-02T15:03:13Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/25643178", "tag": "v1.15.5", "name": "v1.15.5", "author": {"name": "afrozenator", "type": "User"}, "description": "PRs:\r\n* #1788 by @mzilinec adding an option to select different TPU zone.\r\n\r\nSome more code cleanups, regarding tf.compat.v1", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.15.5", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.15.5", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.15.5", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/25643178", "release_id": 25643178, "date_created": "2020-04-18T16:32:14Z", "date_published": "2020-04-18T18:14:22Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/22758499", "tag": "v1.15.4", "name": "v1.15.4", "author": {"name": "afrozenator", "type": "User"}, "description": "* Flush out some more contrib remnants.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.15.4", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.15.4", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.15.4", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/22758499", "release_id": 22758499, "date_created": "2020-01-11T00:46:04Z", "date_published": "2020-01-11T01:06:45Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/22756882", "tag": "v1.15.3", "name": "v1.15.3", "author": {"name": "afrozenator", "type": "User"}, "description": "* Some changes to handle 1.x to 2.x for tf contrib\r\n* TODO(afrozm): Write more", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.15.3", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.15.3", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.15.3", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/22756882", "release_id": 22756882, "date_created": "2020-01-10T19:55:58Z", "date_published": "2020-01-10T22:39:54Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/21704661", "tag": "v1.15.2", "name": "v1.15.2", "author": {"name": "afrozenator", "type": "User"}, "description": "Some changes needed to be able to import problems with TF 2.0", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.15.2", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.15.2", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.15.2", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/21704661", "release_id": 21704661, "date_created": "2019-11-23T08:17:59Z", "date_published": "2019-11-23T08:52:29Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/21704523", "tag": "v1.15.1", "name": "v1.15.1", "author": {"name": "afrozenator", "type": "User"}, "description": "* Move away from tf.flags to absl-py's flags.\r\n* Move away from std::string to tensorflow::string", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.15.1", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.15.1", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.15.1", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/21704523", "release_id": 21704523, "date_created": "2019-11-22T23:40:34Z", "date_published": "2019-11-23T08:19:30Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/21690842", "tag": "v1.15.0", "name": "v1.15.0", "author": {"name": "afrozenator", "type": "User"}, "description": "# Final T2T major release\r\nIt is now in maintenance mode \u2014 we keep it running and welcome bug-fixes, but encourage users to use the successor library [Trax](https://github.com/google/trax).\r\n\r\n# PRs Merged\r\n - #1724 by @Separius - use batch_size in _test_img2img_transformer thanks!\r\n - #1726 by @senarvi  - Fix decoding in prepend mode thanks!\r\n - #1733 by @prasastoadi - En-Id untokenized parallel corpora thanks!\r\n - #1748 by @gabegrand adding a Text2RealProblem class -- thanks a lot @gabegrand \r\n\r\n# Bug Fixes\r\n - Fix features and decoding on TPUs by @mts42000 \r\n - @iansimon and Kristy Choi around shape assertions and modalities\r\n - @superbobry fixed cases where tf.TensorShape was constructed with float dimensions\r\n\r\n# Misc\r\n - Trax was moved into its own repo: https://github.com/google/trax", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.15.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.15.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.15.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/21690842", "release_id": 21690842, "date_created": "2019-11-22T04:54:16Z", "date_published": "2019-11-22T16:15:10Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/20458954", "tag": "v1.14.1", "name": "v1.14.1", "author": {"name": "afrozenator", "type": "User"}, "description": "## PRs Merged\r\n* #1720 thanks @przemb \r\n* #1698 #1699 test/util file fixes thanks to @Vooblin \r\n* Fix serving response from Cloud ML Engine (#1688) thanks to @evalphobia \r\n* Refine automatic mixed precision support via hyper param (#1681) thanks @vinhngx \r\n* correct return shape of rel_pos2abs_pos() (#1686) thanks to @Separius \r\n* save attention weights for relative attention v2 (#1682) thanks to @Ghostvv \r\n* Update generator_utils.py (#1674) thanks to @TanguyUrvoy \r\n\r\n## Docs\r\n* Transformer tutorial (#1675) many thanks to @Styleoshin \r\n\r\n## Problems\r\n* 4 new dialog problems by @ricsinaruto in #1642 \r\n\r\n## Models\r\n* Extend NeuralStack to support Dequeu by reading/writing in both directions, thanks @narphorium \r\n\r\n## TRAX\r\n* Lots of work on SimPLe tuning hyperparameters by @koz4k , @lukaszkaiser and @afrozenator \r\n* async data collection for RL in TRAX\r\n* New memory efficient Transformer using Reversible layers, thanks to Nikita Kitaev, @lukaszkaiser and Anselm Levskaya\r\n* Losses and metrics are layers now in trax, thanks to @lukaszkaiser \r\n* Activations in TRAX thanks to @joaogui1 in #1684 and #1666 \r\n", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.14.1", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.14.1", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.14.1", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/20458954", "release_id": 20458954, "date_created": "2019-10-03T19:37:40Z", "date_published": "2019-10-03T21:04:09Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/19450403", "tag": "v1.14.0", "name": "v1.14.0", "author": {"name": "afrozenator", "type": "User"}, "description": "# Models / Layers:\r\n* NeuralStack and NeuralQueue added, in https://github.com/tensorflow/tensor2tensor/commit/838aca4960f851cd759307481ea904038c1a1ab5 - thanks @narphorium !\r\n* Open Sourcing the Search Space used in EvolvedTransformer - https://github.com/tensorflow/tensor2tensor/commit/4ce366131ce69d1005f035e14677609f7dfdb580\r\n* Masked local n-D attention added in - https://github.com/tensorflow/tensor2tensor/commit/2da59d24eb9367cbed20c98df559beccd11b7582\r\n\r\n# Problems:\r\n* Add English-Spanish translation problem (#1626) thanks @voluntadpear !\r\n* MovingMNist added in https://github.com/tensorflow/tensor2tensor/commit/121ee60a3b57a092264aa5b5bf69ad194cafb118 thanks @MechCoder !\r\n\r\n# Bug Fixes:\r\n* Loss twice multiplied with loss_coef (#1627) by @davidmrau - thanks a lot David!\r\n* Fix log_prob accumulation during decoding, thanks @lmthang !\r\n* Fixed high usage of TPU HBM \"Arguments\" during serving \r\n in https://github.com/tensorflow/tensor2tensor/commit/d38f3435ded822e585d1fc7136f3ece857a41c8d thanks @ziy !\r\n* Should not generate summary during decoding in dot_product_relative_atention (#1618) thanks @phamthuonghai !\r\n\r\n# Misc changes:\r\n* Implement sequence packing as a tf.data.Dataset transformation - https://github.com/tensorflow/tensor2tensor/commit/560c008f7d87502174765fac5ae3d822bbf6b243 thanks @robieta !\r\n* Lots of work on t2t_distill and model exporting by @ziy - thanks @ziy !\r\n\r\n# RL:\r\nIntroduce Rainbow. (#1607) by @konradczechowski in #1607 \r\nChanges to MBRL by @konradczechowski , @koz4k in multiple PRs.\r\n\r\n# PRs:\r\n* Adding automatic mixed precision support (#1637) thanks a lot to @vinhngx !\r\n* Documentation for creating own model #1589 thanks @hbrylkowski !\r\n* Adding extra linear to semantic hashing discretization bottleneck. #1578 thanks @martiansideofthemoon !\r\n* Using partial targets at inference time. (#1596) thanks @EugKar !\r\n* Updated link to DeepMind Math dataset (#1583) thanks @MaxSobolMark !\r\n* Only strip end of line (#1577) thanks @funtion !\r\n* correct typo in add_timing_signal_nd (#1651) many thanks to @Separius !\r\n* fix decode bug (#1645) many thanks to @dong-s !\r\n* Change confusing function name (#1669) thanks @lazylife7157 !\r\n\r\n# TRAX:\r\n\r\n## Base\r\n* Forked optimizers from JAX and make them objects in https://github.com/tensorflow/tensor2tensor/commit/1c7c10c60abc31308b40ae6c850e5c9e363dd4a9\r\n* Trax layers are now stateful and support custom gradients. \r\n* Multi-device capability added.\r\n* Memory efficient trainer added in https://github.com/tensorflow/tensor2tensor/commit/b2615aab938af99418ac0d1318338bf3030357fa ! Thanks Nikita Kitaev!\r\n* Adafactor optimizer added in TRAX - https://github.com/tensorflow/tensor2tensor/commit/63c015f964c1166d181d8efd232abd856574fd83\r\n* Demo Colab added in https://github.com/tensorflow/tensor2tensor/commit/cec26dbd782ea7e4c07377e8d1f9391eb0c5a65c thanks @levskaya\r\n* Demo colab for trax layers - https://github.com/tensorflow/tensor2tensor/commit/7632ed01e739cd124c8bac85f121f0f49ddd86cf\r\n* Transformer, TransformerLM, [Reversible Transformer](https://github.com/tensorflow/tensor2tensor/commit/8c23cbb2f3634d7ba2d9ade1c88b935e07197218), PositionLookupTransformer and Resnet50 are some of the models that TRAX now supports.\r\n\r\n## RL\r\n* Many PPO changes to be able to work on Atari.\r\n* Distributed PPO where the envs can run in multiple parallel machines using gRPC\r\n* SimulatedEnvProblem by @koz4k - a gym env that simulates a step taken by a trainer of a Neural Network in https://github.com/tensorflow/tensor2tensor/commit/2c761783a7aacd6800d445d10ad3676a56365514\r\n* Implement SerializedSequenceSimulatedEnvProblem \r\n by @koz4k \r\n - https://github.com/tensorflow/tensor2tensor/commit/f7f8549a6421723154b366996b2c6559048ac3fb\r\n* Transformer can be used as a policy now, thanks to @koz4k in https://github.com/tensorflow/tensor2tensor/commit/33783fd63bd0debe2138c5569698b31d9af350f6 !", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.14.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.14.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.14.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/19450403", "release_id": 19450403, "date_created": "2019-08-21T21:59:02Z", "date_published": "2019-08-21T22:03:23Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/17226479", "tag": "v1.13.4", "name": "v1.13.4", "author": {"name": "afrozenator", "type": "User"}, "description": "Minor fix to 1.13.3, please see release notes there.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.13.4", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.13.4", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.13.4", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/17226479", "release_id": 17226479, "date_created": "2019-05-08T15:50:20Z", "date_published": "2019-05-08T16:04:02Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/17210590", "tag": "v1.13.3", "name": "v1.13.3", "author": {"name": "afrozenator", "type": "User"}, "description": "TODO(afrozm): Document more.\r\n\r\n* Various PRs.\r\n* Development on TRAX", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.13.3", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.13.3", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.13.3", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/17210590", "release_id": 17210590, "date_created": "2019-05-08T00:46:00Z", "date_published": "2019-05-08T01:23:49Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/16629247", "tag": "v1.13.2", "name": "v1.13.2", "author": {"name": "afrozenator", "type": "User"}, "description": "* jax, jaxlib moved to extras in setup.py\r\n\r\nPRs:\r\nfixed get_standardized_layers spelling, thanks @cbockman in #1529 \r\nserving utils fixes - Thanks @Drunkar ! in #1495 \r\nFixing a checkpoint name bug in #1487, thanks @lzhang10 \r\n\r\nEnhancements:\r\n* [DeepMind Math dataset](https://github.com/tensorflow/tensor2tensor/commit/9dc3d1274ce8cb25513adb071262cadb4ba7e5d3).\r\n* [VideoGlow paper added to T2T Papers.](https://github.com/tensorflow/tensor2tensor/commit/b6a9bbbd7c04e69ccfbf8f8d9c4b5b8947729bea)\r\n* [Mixture Transformer](https://github.com/tensorflow/tensor2tensor/commit/151dc27eb1b9f169c7e08e9e1b660f011ea99796)\r\n* A very basic PPO implementation in TRAX.\r\n* More TRAX and RL changes.\r\n\r\nBugs:\r\n[Correct flat CIFAR modality to not consider 0 as padding](https://github.com/tensorflow/tensor2tensor/commit/2d2d160c4773e38ecdac03d9862b2a90e0170ef6)", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.13.2", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.13.2", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.13.2", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/16629247", "release_id": 16629247, "date_created": "2019-04-08T18:08:24Z", "date_published": "2019-04-08T19:03:21Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/16273189", "tag": "v1.13.1", "name": "v1.13.1", "author": {"name": "afrozenator", "type": "User"}, "description": "Bug Fixes:\r\n* RL fixes for Model Based RL in #1505 - thanks @koz4k \r\n* Serving util corrections in #1495 by @Drunkar -- thanks!\r\n* Fix step size extraction in checkpoints by @lzhang10 in #1487 -- thanks!", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.13.1", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.13.1", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.13.1", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/16273189", "release_id": 16273189, "date_created": "2019-03-21T23:02:40Z", "date_published": "2019-03-22T00:35:08Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/15986536", "tag": "v1.13.0", "name": "v1.13.0", "author": {"name": "afrozenator", "type": "User"}, "description": "** Modalities refactor: Thanks to Dustin, all modalities are now an enum and just functions, making it easier to understand what's happening in the model. Thanks Dustin!\r\n\r\n**[Model-Based Reinforcement Learning for Atari](https://arxiv.org/abs/1903.00374)** using T2T, please find a nice writeup in at https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/rl/README.md -- thanks a lot to all the authors! @lukaszkaiser @mbz @piotrmilos @blazejosinski Roy Campbell @konradczechowski @doomie Chelsea Finn @koz4k Sergey Levine @rsepassi George Tucker and @henrykmichalewski !\r\n\r\n**[TRAX](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/trax) = T2T + [JAX]**(https://github.com/google/jax) - please try out and give us feedback at #1478 \r\n\r\nNew Models:\r\n* Evolved Transformer, thanks @stefan-it for adding the paper in #1426 \r\n* textCNN model by @ybbaigo in #1421 \r\n\r\nDocumentation and Logging:\r\n* MultiProblem by @cwbeitel in #1399 \r\n* ML Enginge logging in #1390 by @lgeiger \r\n\r\nThanks again @cwbeitel and @lgeiger -- good docs and logging goes a long way for understandability.\r\n\r\nBugs fixed:\r\n* t2t_decoder checkpoint fix in #1471 by @wanqizhu \r\n* xrange fix for py3 by in #1468 @lgeiger \r\n* Fixing COCO dataset in #1466 by @hbrylkowski \r\n* Fix math problems by @artitw \r\n* Decoding rev problems enzh by @googlehjx on #1389 \r\n* And honourable mentions to @qixiuai , #1440 \r\n\r\nMany many thanks @wanqizhu @lgeiger @hbrylkowski @artitw @googlehjx and @qixiuai for finding and fixing these and sorry for missing anyone else -- this is really really helpful.\r\n\r\nCode Cleanups:\r\n* Registry refactor and optimizer registry by @jackd in #1410 and #1401 \r\n* Numerous very nice cleanup PRs ex: #1454 #1451 #1446 #1444 #1424 #1411 #1350 by @lgeiger \r\n\r\nMany thanks for the cleanups @jackd and @lgeiger -- and sorry if I missed anyone else.\r\n", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.13.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.13.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.13.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/15986536", "release_id": 15986536, "date_created": "2019-03-07T22:34:14Z", "date_published": "2019-03-22T01:00:29Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/14937259", "tag": "v.1.12.0", "name": "v.1.12.0", "author": {"name": "afrozenator", "type": "User"}, "description": "Summary of changes:\r\n\r\nPRs:\r\n* A lot of code cleanup thanks a ton to @lgeiger ! This goes a long way with regards to code maintainability and is much appreciated. Ex: PR #1361 , #1350 , #1344 , #1346 , #1345 , #1324 \r\n* Fixing LM decode, thanks @mikeymezher - PR #1282 \r\n* More fast decoding by @gcampax, thanks! - PR #999 \r\n* Avoid error on beam search - PR #1302 by @aeloyq , thanks!\r\n* Fix invalid list comprehension, unicode simplifications, py3 fixes #1343, #1318 , #1321, #1258   thanks @cclauss !\r\n* Fix is_generate_per_split hard to spot bug, thanks a lot to @kngxscn in PR #1322 \r\n* Fix py3 compatibility issues in PR #1300 by @ywkim , thanks a lot again!\r\n* Separate train and test data in MRPC and fix broken link in PR #1281 and #1247  by @ywkim - thanks for the hawk eyed change!\r\n* Fix universal transformer decoding by @artitw in PR #1257 \r\n* Fix babi generator by @artitw in PR #1235 \r\n* Fix transformer moe in #1233 by @twilightdema - thanks!\r\n* Universal Transformer bugs corrected in #1213 by @cfiken - thanks!\r\n* Change beam decoder stopping condition, makes decode faster in #965 by @mirkobronzi - many thanks!\r\n* Bug fix, problem_0_steps variable by @senarvi in #1273 \r\n* Fixing a typo, by @hsm207 in PR #1329 , thanks a lot!\r\n\r\nNew Model and Problems:\r\n* New problem and model by @artitw in PR #1290 - thanks!\r\n* New model for scalar regression in PR #1332 thanks to @Kotober \r\n* Text CNN for classification in PR #1271 by @ybbaigo - thanks a lot!\r\n* en-ro translation by @lukaszkaiser !\r\n* CoNLL2002 Named Entity Recognition problem added in #1253 by @ybbaigo - thanks!\r\n\r\nNew Metrics:\r\n* Pearson Correlation metrics in #1274 by @luffy06 - thanks a lot!\r\n* Custom evaluation metrics, this was one of the most asked features, thanks a lot @ywkim in PR #1336 \r\n* Word Error Rate metric by @stefan-falk in PR #1242 , many thanks!\r\n* SARI score for paraphrasing added.\r\n\r\nEnhancements:\r\n* Fast decoding !! Huge thanks to @aeloyq in #1295 \r\n* Fast GELU unit\r\n* Relative dot product visualization PR #1303 thanks @aeloyq !\r\n* New MTF models and enhacements, thanks to Noam, Niki and the MTF team\r\n* Custom eval hooks in PR #1284 by @theorm - thanks a lot !\r\n\r\nRL:\r\nLots of commits to Model Based Reinforcement Learning code by @konradczechowski @koz4k @blazejosinski @piotrmilos - thanks all !", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v.1.12.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v.1.12.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v.1.12.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/14937259", "release_id": 14937259, "date_created": "2019-01-11T23:04:57Z", "date_published": "2019-01-11T23:46:06Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/14014226", "tag": "v1.11.0", "name": "v1.11.0", "author": {"name": "afrozenator", "type": "User"}, "description": "PRs:\r\n* Bug fixes in the insight server thanks to @haukurb !\r\n* Fix weights initialization in #1196 by @mikeymezher - thanks !\r\n* Fix Universal Transformer convergence by @MostafaDehghani and @rllin-fathom in #1194 and #1192  - thanks !\r\n* Fix add problem hparams after parsing the overrides in #1053 thanks @gcampax !\r\n* Fixing error of passing wrong dir in #1185 by @stefan-falk , thanks !\r\n\r\nNew Problems:\r\n* Wikipedia Multiproblems by @urvashik - thanks !\r\n* New LM problems in de, fr, ro by @lukaszkaiser - thanks !\r\n\r\nRL:\r\n* Continual addition to Model Based RL by @piotrmilos , @konradczechowski @koz4k and @blazejosinski !\r\n\r\nVideo Models:\r\n* Many continual updates thanks to @mbz and @MechCoder - thanks all !", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.11.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.11.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.11.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/14014226", "release_id": 14014226, "date_created": "2018-11-15T06:12:27Z", "date_published": "2018-11-15T06:16:44Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/13724768", "tag": "v1.10.0", "name": "v1.10.0", "author": {"name": "afrozenator", "type": "User"}, "description": "NOTE:\r\n - MTF code in Tensor2Tensor has been moved to github.com/tensorflow/mesh - thanks @dustinvtran \r\n\r\nNew Problems:\r\n - English-Setswana translation problem, thanks @jaderabbit \r\n\r\nNew layers, models, etc:\r\n - Add Bayesian feedforward layer, thanks @dustinvtran \r\n - Lots of changes to the RL pipeline, thanks @koz4k , @blazejosinski , @piotrmilos , @lukaszkaiser , @konradczechowski \r\n - Lots of work on video mdoels, thanks @mbz , @MechCoder \r\n - Image transformer with local1d and local 2d spatial partitioning, thanks @nikiparmar @vaswani \r\n\r\nUsability:\r\n - Support DistributionStrategy in Tensor2Tensor for multi-GPU, thanks @smit-hinsu !\r\n - Pass data_dir to feature_encoders, thanks @stefan-falk \r\n - variable_scope wrapper for avg_checkpoints, thanks @Mehrad0711 \r\n - Modalities cleanup, thanks @dustinvtran \r\n - Avoid NaN while adding sinusoidal timing signals, thanks @peakji \r\n - Avoid a ascii codec error in CNN/DailyMail, thanks @shahzeb1 \r\n - Allow exporting T2T models as tfhub modules, thanks @cyfra ", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.10.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.10.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.10.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/13724768", "release_id": 13724768, "date_created": "2018-10-30T05:30:48Z", "date_published": "2018-10-30T06:48:48Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/12795098", "tag": "v1.9.0", "name": "v1.9.0", "author": {"name": "afrozenator", "type": "User"}, "description": "PRs accepted:\r\nCleaning up the code for gru/lstm as transition function for universal transformer. Thanks @MostafaDehghani !\r\nClipwrapper by @piotrmilos !\r\nCorrected transformer spelling mistake - Thanks @jurasofish!\r\nFix to universal transformer update weights - Thanks @cbockman and @cyvius96 !\r\nCommon Voice problem fixes and refactoring - Thanks @tlatkowski !\r\nInfer observation datatype and shape from the environment - Thanks @koz4k !\r\n\r\nNew Problems / Models:\r\n * Added a simple discrete autoencoder video model. Thanks @lukaszkaiser !\r\n * DistributedText2TextProblem, a base class for Text2TextProblem for large-datasets. Thanks @afrozenator!\r\n * Stanford Natural Language Inference problem added `StanfordNLI` in [stanford_nli.py](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/stanford_nli.py). Thanks @urvashik !\r\n * `Text2TextRemotedir` added for problems with a persistent remote directory. Thanks @rsepassi !\r\n * Add a separate binary for vocabulary file generation for subclasses of Text2TextProblem. Thanks @afrozenator!\r\n * Added support for non-deterministic ATARI modes and sticky keys. Thanks @mbz !\r\n * Pretraining schedule added to MultiProblem and reweighting losses. Thanks @urvashik !\r\n * `SummarizeWikiPretrainSeqToSeq32k` and `Text2textElmo` added.\r\n * `AutoencoderResidualVAE` added, thanks @lukaszkaiser !\r\n* Discriminator changes by @lukaszkaiser  and @aidangomez \r\n * Allow scheduled sampling in basic video model, simplify default video modality. Thanks @lukaszkaiser !\r\n\r\nCode Cleanups:\r\n * Use standard vocab naming and fixing translate data generation. Thanks @rsepassi !\r\n * Replaced manual ops w/ dot_product_attention in masked_local_attention_1d. Thanks @dustinvtran !\r\n * Eager tests! Thanks @dustinvtran !\r\n * Separate out a [video/](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/models/video) directory in models/. Thanks @lukaszkaiser !\r\n * Speed up RL test - thanks @lukaszkaiser !\r\n\r\nBug Fixes:\r\n * Don't daisy-chain variables in Universal Transformer. Thanks @lukaszkaiser !\r\n * Corrections to mixing, dropout and sampling in autoencoders. Thanks @lukaszkaiser ! \r\n * WSJ parsing only to use 1000 examples for building vocab.\r\n * Fixed scoring crash on empty targets. Thanks David Grangier!\r\n * Bug fix in transformer_vae.py\r\n\r\nEnhancements to MTF, Video Models and much more!", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.9.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.9.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.9.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/12795098", "release_id": 12795098, "date_created": "2018-09-07T23:46:12Z", "date_published": "2018-09-08T01:30:08Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/12486593", "tag": "v1.8.0", "name": "v1.8.0", "author": {"name": "afrozenator", "type": "User"}, "description": "Introducing [**MeshTensorFlow**](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/mesh_tensorflow/README.md) - this enables training really big models O(Billions) of parameters.\r\n\r\nModels/Layers:\r\n* Layers Added: NAC and NALU from https://arxiv.org/abs/1808.00508 Thanks @lukaszkaiser !\r\n* Added a [sparse graph neural net message passing layer]((https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_layers.py)) to tensor2tensor. \r\n* Targeted dropout added to ResNet. Thanks @aidangomez !\r\n* Added VQA models in `models/research/vqa_*`\r\n* Added [`Weight Normalization`](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_layers.py) layer from https://arxiv.org/abs/1602.07868.\r\n\r\nDatasets/Problems:\r\n* MSCoCo paraphrase problem added by @tlatkowski - many thanks!\r\n* `VideoBairRobotPushingWithActions` by @mbz !\r\n\r\nUsability:\r\n* Code cleaup in autoencoder, works both on image and text. Thanks @lukaszkaiser \r\n* Set the default value of Text2TextProblem.max_subtoken_length to 200, this prevents very long vocabulary generation times. Thanks @afrozenator \r\n* Add examples to distributed_training.md, update support for async training, and simplify run_std_server codepath. Thanks @rsepassi !\r\n* Store variable scopes in T2TModel; add T2TModel.initialize_from_ckpt. Thanks @rsepassi !\r\n* Undeprecate exporting the model from the trainer Thanks @gcampax !\r\n* Doc fixes, thanks to @stefan-it :) \r\n* Added t2t_prune: simple magnitude-based pruning script for T2T Thanks @aidangomez !\r\n* Added task sampling support for more than two tasks. Thanks @urvashik !\r\n\r\nBug Fixes:\r\n* Override serving_input_fn for video problems.\r\n* `StackWrapper` eliminates problem with repeating actions. Thanks @blazejosinski !\r\n* Calculated lengths of sequences using _raw in lstm.py\r\n* Update universal_transformer_util.py to fix TypeError Thanks @zxqchat !\r\n\r\nTesting:\r\n* Serving tests re-enabled on Travis using Docker. Thanks @rsepassi !\r\n\r\nMany more fixes, tests and work on RL, Glow, SAVP, Video and other models and problems.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.8.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.8.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.8.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/12486593", "release_id": 12486593, "date_created": "2018-08-20T17:33:13Z", "date_published": "2018-08-20T17:36:29Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/12252218", "tag": "v1.7.0", "name": "v1.7.0", "author": {"name": "afrozenator", "type": "User"}, "description": "* Added a MultiProblem class for Multitask Learning. Thanks @urvashik !\r\n* Added decoding option to pass through the features dictionary to predictions. Thanks @rsepassi !\r\n* Enabled MLEngine path to use Cloud TPUs. Thanks @rsepassi !\r\n* Added a simple One-Hot Symbol modality. Thanks @mbz !\r\n* Added Cleverhans integration. Thanks @aidangomez !\r\n\r\n* Problem definitions added for:\r\n  * Allen Brain Atlas problems. Thanks @cwbeitel !\r\n  * [LSUN Bedrooms](http://lsun.cs.princeton.edu/2017/) dataset.\r\n  * Added various NLP datasets. Thanks @urvashik ! \r\n    * [MSR Paraphrase Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52398),\r\n    * [Quora Question Pairs](https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs),\r\n    * [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/treebank.html),\r\n    * [Question Answering NLI classification problems](https://gluebenchmark.com/tasks),\r\n    * [Recognizing Textual Entailment](https://gluebenchmark.com/tasks),\r\n    * [Corpus of Linguistic Acceptability](https://gluebenchmark.com/tasks),\r\n    * [Winograd NLI](https://gluebenchmark.com/tasks).\r\n  * Added a data generator for WSJ parsing.\r\n\r\n* Model additions:\r\n  * Implemented Targeted Dropout for Posthoc Pruning. Thanks @aidangomez !\r\n  * Added self attention to VQA attention model.\r\n  * Added fast block parallel transformer model\r\n  * Implemented auxiliary losses from [Stochastic Activation Pruning for Robust Adversarial Defense](https://arxiv.org/abs/1803.00144). Thanks @alexyku !\r\n  * Added probability based scheduled sampling for SV2P problem. Thanks @mbz !\r\n  * Reimplementated Autoencoder and Eval. Thanks @piotrmilos !\r\n  * Relative memory efficient unmasked self-attention.\r\n\r\n* Notable bug fixes:\r\n  * bug with data_gen in style transfer problem Thanks @tlatkowski !\r\n  * wmt_enfr dataset should not use vocabulary based on \"small\" dataset. Thanks @nshazeer ! \r\n\r\n* **Many more fixes, tests and work on Model based RL, Transfomer, Video and other models and problems.**", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.7.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.7.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.7.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/12252218", "release_id": 12252218, "date_created": "2018-08-03T18:30:09Z", "date_published": "2018-08-10T03:54:48Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/11661694", "tag": "v1.6.6", "name": "v1.6.6", "author": {"name": "lukaszkaiser", "type": "User"}, "description": "* added Mozilla common voice as Problem and style transfer one others!\r\n* improvements to ASR data preprocessing (thanks to jarfo)\r\n* decoding works for Transformer on TPUs and for timeseries problems\r\n* corrections and refactoring of the RL part\r\n* Removed deprecated Experiment API code, and support SessionRunHooks on TPU.\r\n* many other corrections and work on video problems, latent variables and other\r\n\r\nGreat thanks to everyone!", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.6.6", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.6.6", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.6.6", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/11661694", "release_id": 11661694, "date_created": "2018-06-26T21:15:37Z", "date_published": "2018-06-26T21:42:37Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/11508210", "tag": "v1.6.5", "name": "v1.6.5", "author": {"name": "rsepassi", "type": "User"}, "description": "* `registry.hparams` now returns an `HParams` object instead of a function that returns an `HParams` object\r\n* New `MultistepAdamOptimizer` thanks to @fstahlberg\r\n* New video models and problems and improvements to `VideoProblem`\r\n* Added `pylintrc` and lint tests to Travis CI\r\n* Various fixes, improvements, and additions", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.6.5", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.6.5", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.6.5", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/11508210", "release_id": 11508210, "date_created": "2018-06-15T20:43:42Z", "date_published": "2018-06-15T20:49:49Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/11104286", "tag": "v1.6.3", "name": "v1.6.3", "author": {"name": "rsepassi", "type": "User"}, "description": "* `--random_seed` is unset by default now. Set it to an integer value to get reproducible results.\r\n* [bAbI text understanding tasks added](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/babi_qa.py)\r\n* Have the ML Engine and TPU codepaths use TF 1.8\r\n* Various cloud-related bug fixes\r\n* `WikisumWeb` data generation fixes\r\n* Various other fixes", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.6.3", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.6.3", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.6.3", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/11104286", "release_id": 11104286, "date_created": "2018-05-21T22:53:52Z", "date_published": "2018-05-21T23:18:34Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10893272", "tag": "v1.6.2", "name": "v1.6.2", "author": {"name": "lukaszkaiser", "type": "User"}, "description": "* Lambada and wikitext103 datasets.\r\n* ASR model with Transformer and iPython notebook.\r\n* Many other improvements including RL code, autoencoders, the latent transformer (transformer_vae) and more.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.6.2", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.6.2", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.6.2", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10893272", "release_id": 10893272, "date_created": "2018-05-08T03:16:32Z", "date_published": "2018-05-08T03:23:02Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10746269", "tag": "v1.6.1", "name": "v1.6.1", "author": {"name": "rsepassi", "type": "User"}, "description": "* Release [scripts](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/wikisum) to generate the data for [Generating Wikipedia by Summarizing Long Sequences](https://arxiv.org/abs/1801.10198)\r\n* New [`RTransformer`](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/research/r_transformer.py) model, a recurrent Transformer\r\n* New [English-Estonian translation dataset](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/translate_enet.py) thanks to @stefan-it \r\n* New `ROC_AUC` metric thanks to @jjtan \r\n* Various fixes, improvements, additions, etc.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.6.1", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.6.1", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.6.1", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10746269", "release_id": 10746269, "date_created": "2018-04-26T23:34:46Z", "date_published": "2018-04-26T23:43:26Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10652730", "tag": "v1.6.0", "name": "v1.6.0", "author": {"name": "rsepassi", "type": "User"}, "description": "* `--problems` command-line flag renamed to `--problem`\r\n* `hparams.problems` renamed to `hparams.problem_hparams` and `hparams.problem_instances` renamed to `hparams.problem` (and neither are lists now)\r\n* Dropped support for TensorFlow 1.4\r\n* Various additions, fixes, etc.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.6.0", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.6.0", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.6.0", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10652730", "release_id": 10652730, "date_created": "2018-04-20T22:42:45Z", "date_published": "2018-04-20T22:59:30Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10542995", "tag": "v1.5.7", "name": "v1.5.7", "author": {"name": "rsepassi", "type": "User"}, "description": "* Distillation codepath added\r\n* Improved support for serving language models\r\n* New `TransformerScorer` model which return log prob of targets on `infer`\r\n* Support for `bfloat16` weights and activations on TPU\r\n* SRU gate added to `common_layers`\r\n* `--checkpoint_path` supported in interactive decoding\r\n* Improved support for multiple outputs\r\n* `VideoProblem` base class\r\n* Various fixes, additions, etc.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.5.7", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.5.7", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.5.7", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10542995", "release_id": 10542995, "date_created": "2018-04-13T21:22:40Z", "date_published": "2018-04-13T21:29:38Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10417805", "tag": "v1.5.6", "name": "v1.5.6", "author": {"name": "rsepassi", "type": "User"}, "description": "* Scalar summary support on TPUs\r\n* New `Squad` and `SquadConcat` problem for question answering (and relevant base class)\r\n* New video problems\r\n* `bfloat16` support for `Transformer` on TPUs\r\n* New `SigmoidClassLabelModality` for binary classification\r\n* Support batch prediction with Cloud ML Engine\r\n* Various fixes, improvements, additions", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.5.6", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.5.6", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.5.6", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10417805", "release_id": 10417805, "date_created": "2018-04-05T19:18:10Z", "date_published": "2018-04-05T20:47:48Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10026280", "tag": "v1.5.5", "name": "v1.5.5", "author": {"name": "rsepassi", "type": "User"}, "description": "* Updates to experimental RL codebase\r\n* `ImageTransformer` on TPU\r\n* Various updates, fixes, additions, etc.", "tarball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/tarball/v1.5.5", "zipball_url": "https://api.github.com/repos/tensorflow/tensor2tensor/zipball/v1.5.5", "html_url": "https://github.com/tensorflow/tensor2tensor/releases/tag/v1.5.5", "url": "https://api.github.com/repos/tensorflow/tensor2tensor/releases/10026280", "release_id": 10026280, "date_created": "2018-03-10T01:54:00Z", "date_published": "2018-03-10T02:16:11Z"}, "confidence": 1, "technique": "GitHub_API"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "contributing_guidelines": [{"result": {"value": "# How to Contribute\n\n# Issues\n\n* Please tag your issue with `bug`, `feature request`, or `question` to help us\n  effectively respond.\n* Please include the versions of TensorFlow and Tensor2Tensor you are running\n  (run `pip list | grep tensor`)\n* Please provide the command line you ran as well as the log output.\n\n# Pull Requests\n\nWe'd love to accept your patches and contributions to this project. There are\njust a few small guidelines you need to follow.\n\n## Contributor License Agreement\n\nContributions to this project must be accompanied by a Contributor License\nAgreement. You (or your employer) retain the copyright to your contribution,\nthis simply gives us permission to use and redistribute your contributions as\npart of the project. Head over to <https://cla.developers.google.com/> to see\nyour current agreements on file or to sign a new one.\n\nYou generally only need to submit a CLA once, so if you've already submitted one\n(even if it was for a different project), you probably don't need to do it\nagain.\n\n## Code reviews\n\nAll submissions, including submissions by project members, require review. We\nuse GitHub pull requests for this purpose. Consult\n[GitHub Help](https://help.github.com/articles/about-pull-requests/) for more\ninformation on using pull requests.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/CONTRIBUTING.md"}], "documentation": [{"result": {"value": "https://github.com/tensorflow/tensor2tensor/tree/master/docs", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "executable_example": [{"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/visualization/TransformerVisualization.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/visualization/TransformerVisualization.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/asr_transformer.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/asr_transformer.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/t2t_problem.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/t2t_problem.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/hello_t2t.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/hello_t2t.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/hello_t2t-rl.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/hello_t2t-rl.ipynb"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/Transformer_translate.ipynb", "type": "Url", "format": "jupyter_notebook"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/notebooks/Transformer_translate.ipynb"}], "has_script_file": [{"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/utils/get_ende_bleu.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/utils/get_cnndm_rouge.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/tensor2tensor/data_generators/wikisum/delete_instances.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/oss_scripts/oss_pip_install.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/oss_scripts/oss_integration_test.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/oss_scripts/oss_tests.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/oss_scripts/oss_release.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "usage": [{"result": {"value": "[This iPython notebook](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb)\nexplains T2T and runs in your browser using a free VM from Google,\nno installation needed. Alternatively, here is a one-command version that\ninstalls T2T, downloads MNIST, trains a model and evaluates it:\n\n```\npip install tensor2tensor && t2t-trainer \\\n  --generate_data \\\n  --data_dir=~/t2t_data \\\n  --output_dir=~/t2t_train/mnist \\\n  --problem=image_mnist \\\n  --model=shake_shake \\\n  --hparams_set=shake_shake_quick \\\n  --train_steps=1000 \\\n  --eval_steps=100\n```\n", "type": "Text_excerpt", "original_header": "Quick Start", "parent_header": ["Tensor2Tensor"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "acknowledgement": [{"result": {"value": "For speech-to-text, we have these data-sets in T2T:\n\n* Librispeech (US English): `--problem=librispeech` for\n    the whole set and `--problem=librispeech_clean` for a smaller\n    but nicely filtered part.\n\n* Mozilla Common Voice (US English): `--problem=common_voice` for the whole set\n    `--problem=common_voice_clean` for a quality-checked subset.\n", "type": "Text_excerpt", "original_header": "Speech Recognition", "parent_header": ["Tensor2Tensor", "Suggested Datasets and Models"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "installation": [{"result": {"value": "\n```\n# Assumes tensorflow or tensorflow-gpu installed\npip install tensor2tensor\n\n# Installs with tensorflow-gpu requirement\npip install tensor2tensor[tensorflow_gpu]\n\n# Installs with tensorflow (cpu) requirement\npip install tensor2tensor[tensorflow]\n```\n\nBinaries:\n\n```\n# Data generator\nt2t-datagen\n\n# Trainer\nt2t-trainer --registry_help\n```\n\nLibrary usage:\n\n```\npython -c \"from tensor2tensor.models.transformer import Transformer\"\n```\n", "type": "Text_excerpt", "original_header": "Installation", "parent_header": ["Tensor2Tensor", "Basics"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"value": "**Hyperparameter sets** are encoded in\n[`HParams`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/hparam.py)\nobjects, and are registered with\n[`@registry.register_hparams`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/registry.py).\nEvery model and problem has a `HParams`. A basic set of hyperparameters are\ndefined in\n[`common_hparams.py`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/layers/common_hparams.py)\nand hyperparameter set functions can compose other hyperparameter set functions.\n", "type": "Text_excerpt", "original_header": "Hyperparameter Sets", "parent_header": ["Tensor2Tensor", "T2T overview"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "[![PyPI\nversion](https://badge.fury.io/py/tensor2tensor.svg)](https://badge.fury.io/py/tensor2tensor)\n[![GitHub\nIssues](https://img.shields.io/github/issues/tensorflow/tensor2tensor.svg)](https://github.com/tensorflow/tensor2tensor/issues)\n[![Contributions\nwelcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)\n[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg)](https://gitter.im/tensor2tensor/Lobby)\n[![License](https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Travis](https://img.shields.io/travis/tensorflow/tensor2tensor.svg)](https://travis-ci.org/tensorflow/tensor2tensor)\n[![Run on FH](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run) \n", "original_header": "Tensor2Tensor"}, "confidence": 0.8555767720175267, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "Below we list a number of tasks that can be solved with T2T when\nyou train the appropriate model on the appropriate problem.\nWe give the problem and model below and we suggest a setting of\nhyperparameters that we know works well in our setup. We usually\nrun either on Cloud TPUs or on 8-GPU machines; you might need\nto modify the hyperparameters if you run on a different setup.\n \n", "original_header": "Suggested Datasets and Models"}, "confidence": 0.8079183679379082, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "You can get translations in the other direction by appending `_rev` to\nthe problem name, e.g., for German-English use\n`--problem=translate_ende_wmt32k_rev`\n(note that you still need to download the original data with t2t-datagen\n`--problem=translate_ende_wmt32k`). \n", "original_header": "Translation"}, "confidence": 0.9301759795737844, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "faq": [{"result": {"value": "**Problems** consist of features such as inputs and targets, and metadata such\nas each feature's modality (e.g. symbol, image, audio) and vocabularies. Problem\nfeatures are given by a dataset, which is stored as a `TFRecord` file with\n`tensorflow.Example` protocol buffers. All\nproblems are imported in\n[`all_problems.py`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/all_problems.py)\nor are registered with `@registry.register_problem`. Run\n[`t2t-datagen`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/bin/t2t-datagen)\nto see the list of available problems and download them.\n", "type": "Text_excerpt", "original_header": "Problems", "parent_header": ["Tensor2Tensor", "T2T overview"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "run": [{"result": {"value": "[![Run on FloydHub](https://static.floydhub.com/button/button.svg)](https://floydhub.com/run)\n\nClick this button to open a [Workspace](https://blog.floydhub.com/workspaces/) on [FloydHub](https://www.floydhub.com/?utm_medium=readme&utm_source=tensor2tensor&utm_campaign=jul_2018). You can use the workspace to develop and test your code on a fully configured cloud GPU machine.\n\nTensor2Tensor comes preinstalled in the environment, you can simply open a [Terminal](https://docs.floydhub.com/guides/workspace/#using-terminal) and run your code.\n\n```bash\n# Test the quick-start on a Workspace's Terminal with this command\nt2t-trainer \\\n  --generate_data \\\n  --data_dir=./t2t_data \\\n  --output_dir=./t2t_train/mnist \\\n  --problem=image_mnist \\\n  --model=shake_shake \\\n  --hparams_set=shake_shake_quick \\\n  --train_steps=1000 \\\n  --eval_steps=100\n```\n\nNote: Ensure compliance with the FloydHub [Terms of Service](https://www.floydhub.com/about/terms).\n", "type": "Text_excerpt", "original_header": "Run on FloydHub", "parent_header": ["Tensor2Tensor"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "application_domain": [{"result": {"type": "String", "value": "Natural Language Processing"}, "confidence": 0.9001352037030934, "technique": "supervised_classification"}], "citation": [{"result": {"value": "@article{tensor2tensor,\n  author    = {Ashish Vaswani and Samy Bengio and Eugene Brevdo and\n    Francois Chollet and Aidan N. Gomez and Stephan Gouws and Llion Jones and\n    \\L{}ukasz Kaiser and Nal Kalchbrenner and Niki Parmar and Ryan Sepassi and\n    Noam Shazeer and Jakob Uszkoreit},\n  title     = {Tensor2Tensor for Neural Machine Translation},\n  journal   = {CoRR},\n  volume    = {abs/1803.07416},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1803.07416},\n}", "type": "Text_excerpt", "format": "bibtex"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "full_title": [{"result": {"type": "String", "value": "Tensor2Tensor"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "image": [{"result": {"type": "Url", "value": "https://static.floydhub.com/button/button-small.svg"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://static.floydhub.com/button/button.svg"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}], "related_papers": [{"result": {"type": "Url", "value": "https://arxiv.org/abs/1801.09797"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1802.05751"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1706.05137"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1804.04235"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1803.02155"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1901.11117"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1706.03059"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1807.03819"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1812.02825"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1903.01434"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1804.00247"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1801.10198"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1803.07416"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1803.03382"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1903.00374"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1706.03762"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/tensorflow/tensor2tensor/master/README.md"}]}