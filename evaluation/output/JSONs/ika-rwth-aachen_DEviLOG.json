{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:25:46"}, "code_repository": [{"result": {"value": "https://github.com/ika-rwth-aachen/DEviLOG", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "ika-rwth-aachen", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2022-10-02T13:36:01Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-02-08T12:24:37Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "license": [{"result": {"value": "https://api.github.com/licenses/mit", "type": "License", "name": "MIT License", "url": "https://api.github.com/licenses/mit", "spdx_id": "MIT"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "MIT License\n\nCopyright (c) 2022 Institut f\u00fcr Kraftfahrzeuge, RWTH Aachen, ika\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/LICENSE"}], "name": [{"result": {"value": "DEviLOG", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "ika-rwth-aachen/DEviLOG", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/ika-rwth-aachen/DEviLOG/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/ika-rwth-aachen/DEviLOG/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 6, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 0, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/ika-rwth-aachen/DEviLOG/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 132438}, "confidence": 1, "technique": "GitHub_API"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "installation": [{"result": {"value": "We suggest to create a new **[conda](https://docs.conda.io/) environment** with all required packages. This will automatically install the GPU version of TensorFlow with CUDA and cuDNN if an NVIDIA GPU is available. It is also necessary to fix some system paths in order for TensorFlow to correctly locate CUDA. Afterwards the environment must be re-activated.\n\n```bash\n# DEviLOG/\nconda env create -f environment.yml\nconda activate devilog\nconda env config vars set LD_PRELOAD=\"$CONDA_PREFIX/lib/libcudart.so:$CONDA_PREFIX/lib/libcublas.so:$CONDA_PREFIX/lib/libcublasLt.so:$CONDA_PREFIX/lib/libcufft.so:$CONDA_PREFIX/lib/libcurand.so:$CONDA_PREFIX/lib/libcusolver.so:$CONDA_PREFIX/lib/libcusparse.so:$CONDA_PREFIX/lib/libcudnn.so\"\nconda activate devilog\n```\n\n<u>Alternatively</u>, it is possible to install all package dependencies in a **Python 3.8** environment (e.g. by using _virtualenv_) with _pip_. Note that *CMake* must be installed to build the `point-pillars` package.\n\n```bash\n# DEviLOG/\npip install -r requirements.txt\n```\n", "type": "Text_excerpt", "original_header": "Installation", "parent_header": ["DEviLOG: Dynamic Evidential Lidar Occupancy Grid Mapping"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "The nuScenes dataset can be downloaded from [here](https://www.nuscenes.org/nuscenes#download) (registration required). You will need the \"full dataset\", the \"map expansion pack\" and the \"lidar-panoptic\" package. For testing purposes, you can just download the \"mini\" splits instead of the full \"trainval\" split. The extracted folder must be placed in the manual installation directory for TensorFlow Datasets, e.g. `~/tensorflow_datasets/downloads/manual/v1.0-mini`. After extracting all archives you should have the following directories:\n```bash\ntensorflow_datasets/downloads/manual/\n  v1.0-mini/  # or 'v1.0-trainval'\n    maps/\n      basemap/\n      expansion/\n      prediction/\n    panoptic/\n    samples/\n    sweeps/\n    v1.0-mini/  # or 'v1.0-trainval'\n```\n \n", "original_header": "Data"}, "confidence": 0.9233393257806252, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}], "acknowledgement": [{"result": {"value": ">This research is accomplished within the project \u201dUNICARagil\u201d (FKZ 16EMO0284K). We acknowledge the financial support for the project by the Federal Ministry of Education and Research of Germany (BMBF).\n", "type": "Text_excerpt", "original_header": "Acknowledgement", "parent_header": ["DEviLOG: Dynamic Evidential Lidar Occupancy Grid Mapping"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}], "description": [{"result": {"type": "Text_excerpt", "value": "This repository provides the dataset as well as the training pipeline that was used in our paper: \n> **Data-Driven Occupancy Grid Mapping using Synthetic and Real-World Data**\n> [IEEE Xplore](https://ieeexplore.ieee.org/document/9988605), [arXiv](https://arxiv.org/abs/2211.08278)\n>\n> [Raphael van Kempen](https://www.ika.rwth-aachen.de/en/institute/staff/raphael-van-kempen-msc.html), [Bastian Lampe](https://www.ika.rwth-aachen.de/en/institute/staff/bastian-lampe-m-sc.html), [Lennart Reiher](https://www.ika.rwth-aachen.de/en/institute/staff/lennart-reiher-msc.html), [Timo Woopen](https://www.ika.rwth-aachen.de/en/institute/management/timo-woopen-msc.html), [Till Beemelmanns](https://www.ika.rwth-aachen.de/en/institute/staff/till-beemelmanns-msc.html), and [Lutz Eckstein](https://www.ika.rwth-aachen.de/en/institute/management/univ-prof-dr-ing-lutz-eckstein.html)  \n> [Institute for Automotive Engineering (ika), RWTH Aachen University](https://www.ika.rwth-aachen.de/en/)\n>\n> _**Abstract**_ \u2014  In perception tasks of automated vehicles (AVs) data-driven have often outperformed conventional approaches. This motivated us to develop a data-driven methodology to compute occupancy grid maps (OGMs) from lidar measurements. Our approach extends previous work such that the estimated environment representation now contains an additional layer for cells occupied by dynamic objects. Earlier solutions could only distinguish between free and occupied cells. The information whether an obstacle could move plays an important role for planning the behavior of an AV. We present two approaches to generating training data. One approach extends our previous work on using synthetic training data so that OGMs with the three aforementioned cell states are generated. The other approach uses manual annotations from the nuScenes [1] dataset to create training data. We compare the performance of both models in a quantitative analysis on unseen data from the real-world\ndataset. Next, we analyze the ability of both approaches to cope with a domain shift, i.e. when presented with lidar measurements from a different sensor on a different vehicle. We propose using information gained from evaluation on real-world data to further close the reality gap and create better synthetic data that can be used to train occupancy grid mapping models for arbitrary sensor configurations. \n", "original_header": "DEviLOG: Dynamic Evidential Lidar Occupancy Grid Mapping"}, "confidence": 0.9743860728514964, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "This repository contains a [TensorFlow Datasets](https://www.tensorflow.org/datasets) wrapper for the nuScenes dataset. Samples consisting of lidar point clouds and occupancy grid maps will automatically be generated in the training pipeline. \n", "original_header": "Data"}, "confidence": 0.9181831062993602, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}], "invocation": [{"result": {"type": "Text_excerpt", "value": "You can train a model to predict occupancy grid maps from lidar point clouds using training data created from the nuScenes dataset. \nStart training the model by passing the provided [config file](model/config.yml) to the [training script](model/train.py).\n```bash\n# DEviLOG/model/\nexport TF_FORCE_GPU_ALLOW_GROWTH=true  # try this if cuDNN fails to initialize\n./train.py -c config.yml\n```\n \nYou can visualize training progress by pointing *TensorBoard* to the output directory (`model/output` by default). Training metrics will also be printed to `stdout`.\n \n", "original_header": "Training"}, "confidence": 0.8624012829964328, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "Before evaluating your trained model on the test data, set the parameter `model-weights` to point to the `best_weights.hdf5` file in the `Checkpoints` folder of its model directory.\n```bash\n# DEviLOG/model/\n./evaluate.py -c config.yml --model-weights output/<YOUR-TIMESTAMP>/Checkpoints/best_weights.hdf5\n```\n \n", "original_header": "Evaluation"}, "confidence": 0.8881575640408419, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}], "full_title": [{"result": {"type": "String", "value": "DEviLOG: Dynamic Evidential Lidar Occupancy Grid Mapping"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}], "image": [{"result": {"type": "Url", "value": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/./assets/TODO.gif"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}], "related_papers": [{"result": {"type": "Url", "value": "https://arxiv.org/abs/2211.08278"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/ika-rwth-aachen/DEviLOG/main/README.md"}]}