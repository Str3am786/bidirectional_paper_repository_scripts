{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:25:21"}, "code_repository": [{"result": {"value": "https://github.com/StanfordHCI/ContentModAudit_CodeRelease", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "StanfordHCI", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2022-08-23T21:51:29Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-09-26T22:30:52Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "description": [{"result": {"value": "Measuring the Prevalence of Anti-Social Behavior in Online Communities", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Text_excerpt", "value": "This repository accompanies our CSCW'22 paper, \"Measuring the Prevalence of Anti-Social Behavior in Online Communities,\" by Joon Sung Park, Joseph Seering, and Michael S. Bernstein. In it, we measured how much of the comments on Reddit are \"macro-norm\" violating and thus likely should have been moderated, and how much of them were actually moderated. We find that around 1 in 20 comments on the 97 most popular subreddits violate at least one of the macro norms, and only 5% of those violating comments are actually moderated.  \nThis repository includes two ingridients that could help you conduct such measurement studies yourself: 1) the code for gathering the moderated comments and their content from Reddit subcommunities, and 2) the model for classifying \"macro-norm\" violating comments that are historically moderated in a majority of 100 most popular subreddits (please note that our content moderation classification scheme is meant to only \"flag\" potentially violating comments, and not to be used as the final say in the moderation process). We will layout how to run the code and model included in this README page. Please consider checking out our paper in the CSCW proceeding or the abstract below to learn more about our work and the method we used:  \n> Paper abstract: With increasing attention to online anti-social behaviors such as personal attacks and bigotry, it is critical to have an accurate accounting of how widespread anti-social behaviors are. In this paper, we empirically measure the prevalence of anti-social behavior in one of the world's most popular online community platforms. We operationalize this goal as measuring the proportion of unmoderated comments in the 97 most popular communities on Reddit that violate eight widely accepted platform norms. To achieve this goal, we contribute a human-AI pipeline for identifying these violations and a bootstrap sampling method to quantify measurement uncertainty. We find that 6.25% (95% Confidence Interval [5.36%, 7.13%]) of all comments in 2016, and 4.28% (95% CI [2.50%, 6.26%]) in 2020-2021, are violations of these norms. Most anti-social behaviors remain unmoderated: moderators only removed one in twenty violating comments in 2016, and one in ten violating comments in 2020. Personal attacks were the most prevalent category of norm violation; pornography and bigotry were the most likely to be moderated, while politically inflammatory comments and misogyny/vulgarity were the least likely to be moderated. This paper offers a method and set of empirical results for tracking these phenomena as both the social practices (e.g., moderation) and technical practices (e.g., design) evolve.\n \n", "original_header": "Background"}, "confidence": 0.9953470542507278, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/StanfordHCI/ContentModAudit_CodeRelease/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "Observing what sorts of content get moderated on various subreddits is important for understanding the moderation norms of these communities, and for building tools that can support their moderation efforts. The code in moderated-comment-collection folder will help you collect the content of these moderated comments, following the general scheme that Eshwar Chandrasekharan et al. used in their [2018 CSCW paper](http://www.eshwarchandrasekharan.com/uploads/3/8/0/4/38043045/eshwar-norms-cscw2018.pdf): 1) we live-stream all comments from the target subreddits to a server we own, and 2) individually verify which of the comments are moderated by querying Reddit's server via praw a day later.  \nIn moderated-comment-collection folder, there are two subfolders, collector and verifier that are meant to be run on different processes that collectively implements the scheme above: \n* \"collector\" live-streams all comments to a cloud (S3 AWS) server.\n* \"verifier\" individually checks each of the comments a day later.  \n", "original_header": "Collecting Moderated Comments From Reddit"}, "confidence": 0.9850516972065664, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/StanfordHCI/ContentModAudit_CodeRelease/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "We define a comment to be macro-norm violating if most communities will choose to moderate it. To reflect this, we imeplement 97 classifers that are each trained on the moderation data of the 97 largest subreddits. You can find the models and their embeddings in the Google Drive here: \nhttps://drive.google.com/drive/folders/1MYdPMYpUtM4VKNmK5AaCbxS-u3t6QT9Y?usp=sharing \n", "original_header": "Classifying Comments for Macro-Norm Violations"}, "confidence": 0.8705945591488413, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/StanfordHCI/ContentModAudit_CodeRelease/main/README.md"}], "name": [{"result": {"value": "ContentModAudit_CodeRelease", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "StanfordHCI/ContentModAudit_CodeRelease", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/StanfordHCI/ContentModAudit_CodeRelease/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/StanfordHCI/ContentModAudit_CodeRelease/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 1, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 1, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/StanfordHCI/ContentModAudit_CodeRelease/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 31922}, "confidence": 1, "technique": "GitHub_API"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/StanfordHCI/ContentModAudit_CodeRelease/main/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "application_domain": [{"result": {"type": "String", "value": "Computer Vision"}, "confidence": 0.8312746084944841, "technique": "supervised_classification"}], "installation": [{"result": {"type": "Text_excerpt", "value": "To start run these code, take the following steps:  \n", "original_header": "Collecting Moderated Comments From Reddit"}, "confidence": 0.951419195447602, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/StanfordHCI/ContentModAudit_CodeRelease/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "We shared the virtual environment folder as well in this release to make sure some of the libraries are still accessible for you (some of them are deprecated as of now so pip installing them might not get you what you need). Please feel free to download the entire package including the virtual environment, or only download the \"src\" folder and manually build the environment using the requirements.txt file.  \n", "original_header": "Classifying Comments for Macro-Norm Violations"}, "confidence": 0.9670698167230979, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/StanfordHCI/ContentModAudit_CodeRelease/main/README.md"}], "invocation": [{"result": {"type": "Text_excerpt", "value": "To classify comments, place your input comments in the \"input\" folder in \"src\" (I left an example input csv file in there to show how it should be formatted) and run teh \"output_classification\" function in the classify.py file. Your output will be put in the \"output\" folder. \n \n", "original_header": "Classifying Comments for Macro-Norm Violations"}, "confidence": 0.9586760269135658, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/StanfordHCI/ContentModAudit_CodeRelease/main/README.md"}], "full_title": [{"result": {"type": "String", "value": ""}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/StanfordHCI/ContentModAudit_CodeRelease/main/README.md"}]}