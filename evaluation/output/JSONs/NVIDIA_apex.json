{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:10:13"}, "code_repository": [{"result": {"value": "https://github.com/NVIDIA/apex", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "NVIDIA", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2018-04-23T16:28:52Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-12-21T14:45:51Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "license": [{"result": {"value": "https://api.github.com/licenses/bsd-3-clause", "type": "License", "name": "BSD 3-Clause \"New\" or \"Revised\" License", "url": "https://api.github.com/licenses/bsd-3-clause", "spdx_id": "BSD-3-Clause"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "All rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/LICENSE"}], "description": [{"result": {"value": "A PyTorch Extension:  Tools for easy mixed precision and distributed training in Pytorch", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "This repository holds NVIDIA-maintained utilities to streamline mixed precision and distributed training in Pytorch.\nSome of the code here will be included in upstream Pytorch eventually.\nThe intent of Apex is to make up-to-date utilities available to users as quickly as possible.\n", "type": "Text_excerpt", "original_header": "Introduction"}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "`apex.amp` is a tool to enable mixed precision training by changing only 3 lines of your script.\nUsers can easily experiment with different pure and mixed precision training modes by supplying\ndifferent flags to `amp.initialize`. \n[Moving to the new Amp API](https://nvidia.github.io/apex/amp.html#transition-guide-for-old-api-users) (for users of the deprecated \"Amp\" and \"FP16_Optimizer\" APIs)\n \n", "original_header": "1. Amp:  Automatic Mixed Precision"}, "confidence": 0.9675485121521845, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "`apex.parallel.SyncBatchNorm` extends `torch.nn.modules.batchnorm._BatchNorm` to\nsupport synchronized BN.\nIt allreduces stats across processes during multiprocess (DistributedDataParallel) training.\nSynchronous BN has been used in cases where only a small\nlocal minibatch can fit on each GPU.\nAllreduced stats increase the effective batch size for the BN layer to the\nglobal batch size across all processes (which, technically, is the correct\nformulation).\nSynchronous BN has been observed to improve converged accuracy in some of our research models.\n \n", "original_header": "Synchronized Batch Normalization"}, "confidence": 0.9680572805735592, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "To properly save and load your `amp` training, we introduce the `amp.state_dict()`, which contains all `loss_scalers` and their corresponding unskipped steps,\nas well as `amp.load_state_dict()` to restore these attributes. \nIn order to get bitwise accuracy, we recommend the following workflow:\n```python\n# Initialization\nopt_level = 'O1'\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n\n# Train your model\n...\nwith amp.scale_loss(loss, optimizer) as scaled_loss:\n    scaled_loss.backward()\n...\n\n# Save checkpoint\ncheckpoint = {\n    'model': model.state_dict(),\n    'optimizer': optimizer.state_dict(),\n    'amp': amp.state_dict()\n}\ntorch.save(checkpoint, 'amp_checkpoint.pt')\n...\n\n# Restore\nmodel = ...\noptimizer = ...\ncheckpoint = torch.load('amp_checkpoint.pt')\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\nmodel.load_state_dict(checkpoint['model'])\noptimizer.load_state_dict(checkpoint['optimizer'])\namp.load_state_dict(checkpoint['amp'])\n\n# Continue training\n...\n``` \nNote that we recommend restoring the model using the same `opt_level`. Also note that we recommend calling the `load_state_dict` methods after `amp.initialize`.\n \n", "original_header": "Checkpointing"}, "confidence": 0.9031757781311386, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}], "name": [{"result": {"value": "apex", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "NVIDIA/apex", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/NVIDIA/apex/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/NVIDIA/apex/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 7755, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 1297, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/NVIDIA/apex/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 2105723}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Cuda", "name": "Cuda", "type": "Programming_language", "size": 1155259}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "C++", "name": "C++", "type": "Programming_language", "size": 1003037}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "C", "name": "C", "type": "Programming_language", "size": 34183}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Shell", "name": "Shell", "type": "Programming_language", "size": 14877}, "confidence": 1, "technique": "GitHub_API"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "has_script_file": [{"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/apex/contrib/sparsity/permutation_tests/unstructured_study.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/apex/contrib/sparsity/permutation_tests/runtime_table.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/apex/contrib/sparsity/permutation_tests/ablation_studies.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/tests/distributed/DDP/run_race_test.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/tests/distributed/amp_master_params/run.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/tests/distributed/synced_batchnorm/unit_test.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/tests/docker_extension_builds/run.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/tests/L1/common/run_test.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/tests/L1/cross_product_distributed/run.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/tests/L1/cross_product/run.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/examples/simple/distributed/run.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "has_build_file": [{"result": {"value": "https://raw.githubusercontent.com/NVIDIA/apex/master/examples/docker/Dockerfile", "type": "Url", "format": "dockerfile"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/examples/docker/Dockerfile"}], "installation": [{"result": {"value": "Each [`apex.contrib`](./apex/contrib) module requires one or more install options other than `--cpp_ext` and `--cuda_ext`.\nNote that contrib modules do not necessarily support stable PyTorch releases.\n", "type": "Text_excerpt", "original_header": "Installation"}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}, {"result": {"value": "NVIDIA PyTorch Containers are available on NGC: https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch.\nThe containers come with all the custom extensions available at the moment. \n\nSee [the NGC documentation](https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/index.html) for details such as:\n- how to pull a container\n- how to run a pulled container\n- release notes\n", "type": "Text_excerpt", "original_header": "Containers", "parent_header": ["Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}, {"result": {"value": "To install Apex from source, we recommend using the nightly Pytorch obtainable from https://github.com/pytorch/pytorch.\n\nThe latest stable release obtainable from https://pytorch.org should also work.\n\nWe recommend installing [`Ninja`](https://ninja-build.org/) to make compilation faster.\n", "type": "Text_excerpt", "original_header": "From Source", "parent_header": ["Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}, {"result": {"value": "For performance and full functionality, we recommend installing Apex with\nCUDA and C++ extensions via\n```bash\ngit clone https://github.com/NVIDIA/apex\ncd apex\n# if pip >= 23.1 (ref: https://pip.pypa.io/en/stable/news/#v23-1) which supports multiple `--config-settings` with the same key... \npip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings \"--build-option=--cpp_ext\" --config-settings \"--build-option=--cuda_ext\" ./\n# otherwise\npip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n```\n\nAPEX also supports a Python-only build via\n```bash\npip install -v --disable-pip-version-check --no-build-isolation --no-cache-dir ./\n```\nA Python-only build omits:\n- Fused kernels required to use `apex.optimizers.FusedAdam`.\n- Fused kernels required to use `apex.normalization.FusedLayerNorm` and `apex.normalization.FusedRMSNorm`.\n- Fused kernels that improve the performance and numerical stability of `apex.parallel.SyncBatchNorm`.\n- Fused kernels that improve the performance of `apex.parallel.DistributedDataParallel` and `apex.amp`.\n`DistributedDataParallel`, `amp`, and `SyncBatchNorm` will still be usable, but they may be slower.\n\n", "type": "Text_excerpt", "original_header": "Linux", "parent_header": ["Installation", "From Source"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}, {"result": {"value": "`pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings \"--build-option=--cpp_ext\" --config-settings \"--build-option=--cuda_ext\" .` may work if you were able to build Pytorch from source\non your system. A Python-only build via `pip install -v --no-cache-dir .` is more likely to work.  \nIf you installed Pytorch in a Conda environment, make sure to install Apex in that same environment.\n\n", "type": "Text_excerpt", "original_header": "[Experimental] Windows", "parent_header": ["Installation", "From Source"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}, {"result": {"value": "If a requirement of a module is not met, then it will not be built.\n\n|  Module Name  |  Install Option  |  Misc  |\n|---------------|------------------|--------|\n|  `apex_C`     |  `--cpp_ext`     | |\n|  `amp_C`      |  `--cuda_ext`    | |\n|  `syncbn`     |  `--cuda_ext`    | |\n|  `fused_layer_norm_cuda`  |  `--cuda_ext`  | [`apex.normalization`](./apex/normalization) |\n|  `mlp_cuda`   |  `--cuda_ext`    | |\n|  `scaled_upper_triang_masked_softmax_cuda`  |  `--cuda_ext`  | |\n|  `generic_scaled_masked_softmax_cuda`  |  `--cuda_ext`  | |\n|  `scaled_masked_softmax_cuda`  |  `--cuda_ext`  | |\n|  `fused_weight_gradient_mlp_cuda`  |  `--cuda_ext`  | Requires CUDA>=11 |\n|  `permutation_search_cuda`  |  `--permutation_search`  | [`apex.contrib.sparsity`](./apex/contrib/sparsity)  |\n|  `bnp`        |  `--bnp`         |  [`apex.contrib.groupbn`](./apex/contrib/groupbn) |\n|  `xentropy`   |  `--xentropy`    |  [`apex.contrib.xentropy`](./apex/contrib/xentropy)  |\n|  `focal_loss_cuda`  |  `--focal_loss`  |  [`apex.contrib.focal_loss`](./apex/contrib/focal_loss)  |\n|  `fused_index_mul_2d`  |  `--index_mul_2d`  |  [`apex.contrib.index_mul_2d`](./apex/contrib/index_mul_2d)  |\n|  `fused_adam_cuda`  |  `--deprecated_fused_adam`  |  [`apex.contrib.optimizers`](./apex/contrib/optimizers)  |\n|  `fused_lamb_cuda`  |  `--deprecated_fused_lamb`  |  [`apex.contrib.optimizers`](./apex/contrib/optimizers)  |\n|  `fast_layer_norm`  |  `--fast_layer_norm`  |  [`apex.contrib.layer_norm`](./apex/contrib/layer_norm). different from `fused_layer_norm` |\n|  `fmhalib`    |  `--fmha`        |  [`apex.contrib.fmha`](./apex/contrib/fmha)  |\n|  `fast_multihead_attn`  |  `--fast_multihead_attn`  |  [`apex.contrib.multihead_attn`](./apex/contrib/multihead_attn)  |\n|  `transducer_joint_cuda`  |  `--transducer`  |  [`apex.contrib.transducer`](./apex/contrib/transducer)  |\n|  `transducer_loss_cuda`   |  `--transducer`  |  [`apex.contrib.transducer`](./apex/contrib/transducer)  |\n|  `cudnn_gbn_lib`  |  `--cudnn_gbn`  | Requires cuDNN>=8.5, [`apex.contrib.cudnn_gbn`](./apex/contrib/cudnn_gbn) |\n|  `peer_memory_cuda`  |  `--peer_memory`  |  [`apex.contrib.peer_memory`](./apex/contrib/peer_memory)  |\n|  `nccl_p2p_cuda`  |  `--nccl_p2p`  | Requires NCCL >= 2.10, [`apex.contrib.nccl_p2p`](./apex/contrib/nccl_p2p)  |\n|  `fast_bottleneck`  |  `--fast_bottleneck`  |  Requires `peer_memory_cuda` and `nccl_p2p_cuda`, [`apex.contrib.bottleneck`](./apex/contrib/bottleneck) |\n|  `fused_conv_bias_relu`  |  `--fused_conv_bias_relu`  | Requires cuDNN>=8.4, [`apex.contrib.conv_bias_relu`](./apex/contrib/conv_bias_relu) |\n", "type": "Text_excerpt", "original_header": "Custom C++/CUDA Extensions and Install Options", "parent_header": ["Installation"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}], "invocation": [{"result": {"type": "Text_excerpt", "value": "In order to get bitwise accuracy, we recommend the following workflow:\n```python\n# Initialization\nopt_level = 'O1'\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n\n# Train your model\n...\nwith amp.scale_loss(loss, optimizer) as scaled_loss:\n    scaled_loss.backward()\n...\n\n# Save checkpoint\ncheckpoint = {\n    'model': model.state_dict(),\n    'optimizer': optimizer.state_dict(),\n    'amp': amp.state_dict()\n}\ntorch.save(checkpoint, 'amp_checkpoint.pt')\n...\n\n# Restore\nmodel = ...\noptimizer = ...\ncheckpoint = torch.load('amp_checkpoint.pt')\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\nmodel.load_state_dict(checkpoint['model'])\noptimizer.load_state_dict(checkpoint['optimizer'])\namp.load_state_dict(checkpoint['amp'])\n\n# Continue training\n...\n``` \n", "original_header": "Checkpointing"}, "confidence": 0.8161584027498412, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}], "full_title": [{"result": {"type": "String", "value": "Introduction"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/NVIDIA/apex/master/README.md"}]}