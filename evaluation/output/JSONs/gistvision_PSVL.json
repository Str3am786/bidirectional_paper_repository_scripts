{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:18:35"}, "code_repository": [{"result": {"value": "https://github.com/gistvision/PSVL", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "gistvision", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2021-08-17T12:07:02Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-12-20T04:05:22Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "description": [{"result": {"value": "Code for the paper \"Zero-shot Natural Language Video Localization\" (ICCV2021, Oral).", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Text_excerpt", "value": "This repository is for [Zero-shot Natural Language Video Localization](https://openaccess.thecvf.com/content/ICCV2021/papers/Nam_Zero-Shot_Natural_Language_Video_Localization_ICCV_2021_paper.pdf). (ICCV 2021, Oral) \n\nWe first propose a novel task of zero-shot natural language video localization. The proposed task setup does not require any paired annotation cost for NLVL task but only requires easily available text corpora, off-the-shelf object detector, and a collection of videos to localize. To address the task, we propose a **P**seudo-**S**upervised **V**ideo **L**ocalization method, called **PSVL**, that can generate pseudo-supervision for training an NLVL model. Benchmarked on two widely used NLVL datasets, the proposed method exhibits competitive performance and performs on par or outperforms the models trained with stronger supervision. \n", "original_header": "Zero-shot Natural Language Video Localization (ZSNLVL) by Pseudo-Supervised Video Localization (PSVL)"}, "confidence": 0.9817851830479594, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "This repository is implemented base on [PyTorch](http://pytorch.org/) with Anaconda.</br>\nRefer to below instruction or use **Docker** (dcahn/psvl:latest). </br> \n", "original_header": "Environment"}, "confidence": 0.9321560132012386, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}], "name": [{"result": {"value": "PSVL", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "gistvision/PSVL", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/gistvision/PSVL/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/gistvision/PSVL/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 45, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 7, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/gistvision/PSVL/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 97399}, "confidence": 1, "technique": "GitHub_API"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "usage": [{"result": {"value": "- Clone this repo with git, please use:\n```bash\ngit clone https://github.com/gistvision/PSVL.git\n```\n\n- Make your own environment (If you use docker envronment, you just clone the code and execute it.)\n```bashz\nconda create --name PSVL --file requirements.txt\nconda activate PSVL\n```\n", "type": "Text_excerpt", "original_header": "Get the code", "parent_header": ["Zero-shot Natural Language Video Localization (ZSNLVL) by Pseudo-Supervised Video Localization (PSVL)", "Environment"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}, {"result": {"value": "- RTX2080Ti (11G)\n- Ubuntu 18.04.5\n- pytorch 1.5.1\n", "type": "Text_excerpt", "original_header": "Working environment", "parent_header": ["Zero-shot Natural Language Video Localization (ZSNLVL) by Pseudo-Supervised Video Localization (PSVL)", "Environment", "Get the code"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}], "download": [{"result": {"value": "- This [link](https://drive.google.com/file/d/1Vjgm2XA3TYcc4h9IWR5k5efU-bXNir5f/view?usp=sharing) is connected for downloading video features used in this paper. </br>\n: After downloading the video feature, you need to set the `data path` in a config file. </br> \n\n- This [link](https://drive.google.com/file/d/1M2FX2qkEvyked50LSc9Y5r87GBnpohSX/view?usp=sharing) is connected for downloading pre-trained model.\n\nFor ActivityNet-Captions, check Activinet-Captions section of this document.\n", "type": "Text_excerpt", "original_header": "Dataset &amp; Pretrained model", "parent_header": ["Zero-shot Natural Language Video Localization (ZSNLVL) by Pseudo-Supervised Video Localization (PSVL)", "Download"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}], "citation": [{"result": {"value": "If you use this code, please cite:\n```\n@inproceedings{nam2021zero,\n  title={Zero-shot Natural Language Video Localization},\n  author={Nam, Jinwoo and Ahn, Daechul and Kang, Dongyeop and Ha, Seong Jong and Choi, Jonghyun},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={1470-1479},\n  year={2021}\n}\n```\n", "type": "Text_excerpt", "original_header": "Citation", "parent_header": ["Zero-shot Natural Language Video Localization (ZSNLVL) by Pseudo-Supervised Video Localization (PSVL)"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}, {"result": {"value": "@inproceedings{nam2021zero,\n  title={Zero-shot Natural Language Video Localization},\n  author={Nam, Jinwoo and Ahn, Daechul and Kang, Dongyeop and Ha, Seong Jong and Choi, Jonghyun},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={1470-1479},\n  year={2021}\n}", "type": "Text_excerpt", "format": "bibtex"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}], "contact": [{"result": {"value": "If you have any questions, please send e-mail to me (skaws2012@gmail.com, daechulahn@gm.gist.ac.kr)\n", "type": "Text_excerpt", "original_header": "Contact", "parent_header": ["Zero-shot Natural Language Video Localization (ZSNLVL) by Pseudo-Supervised Video Localization (PSVL)"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}], "invocation": [{"result": {"type": "Text_excerpt", "value": "<img src=\"media/task-1.png\" alt=\"task_nlvl\" width=\"400\" style=\"margin-left: auto; margin-right: auto; display: block;\"/> \n", "original_header": "Zero-shot Natural Language Video Localization (ZSNLVL) by Pseudo-Supervised Video Localization (PSVL)"}, "confidence": 0.843512661185382, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "If you want to evaluate the pre-trained model, you can use below command.\n```bash\npython inference.py --model CrossModalityTwostageAttention --config \"YOUR CONFIG PATH\" --pre_trained \"YOUR MODEL PATH\"\n```\n \n", "original_header": "Evaluating pre-trained models"}, "confidence": 0.8166188716501623, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "To train PSVL, run `train.py` with below command.\n```bash\n# Training from scratch\npython train.py --model CrossModalityTwostageAttention --config \"YOUR CONFIG PATH\"\n# Evaluation\npython inference.py --model CrossModalityTwostageAttention --config \"YOUR CONFIG PATH\" --pre_trained \"YOUR MODEL PATH\"\n```\n \n", "original_header": "Training models from scratch"}, "confidence": 0.926878724505308, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "Please download the file, unzip it, and type followings to train/inference with the data. \nTo train the model, please run:\n```bash\npython train.py --model CrossModalityTwostageAttention --config configs/anet_simple_model/simplemodel_anet_BS256_two-stage_attention.yml --dataset anet\n``` \nTo inference with test set, please run:\n```bash\npython inference.py --model CrossModalityTwostageAttention --config configs/anet_simple_model/simplemodel_anet_BS256_two-stage_attention.yml --pre_trained anet_pretrained_best.pth\n```\n \n", "original_header": "Activinet-Captions"}, "confidence": 0.8647124199995685, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}], "full_title": [{"result": {"type": "String", "value": "Zero-shot Natural Language Video Localization (ZSNLVL) by Pseudo-Supervised Video Localization (PSVL)"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}], "image": [{"result": {"type": "Url", "value": "https://raw.githubusercontent.com/gistvision/PSVL/main/media/task-1.png"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/gistvision/PSVL/main/README.md"}]}