{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:18:05"}, "code_repository": [{"result": {"value": "https://github.com/BramVanroy/spacy_conll", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "BramVanroy", "type": "User"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2018-12-19T08:53:05Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-12-20T03:37:10Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "license": [{"result": {"value": "https://api.github.com/licenses/bsd-2-clause", "type": "License", "name": "BSD 2-Clause \"Simplified\" License", "url": "https://api.github.com/licenses/bsd-2-clause", "spdx_id": "BSD-2-Clause"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "BSD 2-Clause License\n\nCopyright (c) 2018-2021, Bram Vanroy, Raquel G. Alhama\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/LICENSE"}], "description": [{"result": {"value": "Pipeline component for spaCy (and other spaCy-wrapped parsers such as spacy-stanza and spacy-udpipe) that adds CoNLL-U properties to a Doc and its sentences and tokens. Can also be used as a command-line tool.", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Text_excerpt", "value": "This module allows you to parse text into CoNLL-U format. You can use it as a command line tool, or embed it in your\n own scripts by adding it as a custom pipeline component to a spaCy, `spacy-stanza`, or `spacy-udpipe` pipeline. It \n also provides an easy-to-use function to quickly initialize a parser as well as a ConllParser class with built-in \n functionality to parse files or text. \nNote that the module simply takes a parser's output and puts it in a formatted string adhering to the linked ConLL-U \n format. The output tags depend on the spaCy model used. If you want Universal Depencies tags as output, I advise you \n to use this library in combination with [spacy-stanza](https://github.com/explosion/spacy-stanza), which is a spaCy \n interface using `stanza` and its models behind the scenes. Those models use the Universal Dependencies formalism and \n yield state-of-the-art performance. `stanza` is a new and improved version of `stanfordnlp`. As an alternative to the \n Stanford models, you can use the spaCy wrapper for `UDPipe`, [spacy-udpipe](https://github.com/TakeLab/spacy-udpipe), \n which is slightly less accurate than `stanza` but much faster. \n", "original_header": "Parsing to CoNLL with spaCy, spacy-stanza, and spacy-udpipe"}, "confidence": 0.9098334126386276, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md"}], "name": [{"result": {"value": "spacy_conll", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "BramVanroy/spacy_conll", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/BramVanroy/spacy_conll/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/BramVanroy/spacy_conll/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 71, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "conll, conll-u, data-science, machine-learning, natural-language-processing, nlp, pandas, parser, python, spacy, spacy-extension, spacy-pipeline, stanford-machine-learning, stanford-nlp, stanza, udpipe", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 13, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/BramVanroy/spacy_conll/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 51359}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Makefile", "name": "Makefile", "type": "Programming_language", "size": 379}, "confidence": 1, "technique": "GitHub_API"}], "releases": [{"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/98568013", "tag": "v3.4.0", "name": "Update default field names and allow custom ones", "author": {"name": "BramVanroy", "type": "User"}, "description": "## What's Changed\r\n* improve CoNLL-U fields by @BramVanroy in https://github.com/BramVanroy/spacy_conll/pull/25\r\n\r\n\r\n**Full Changelog**: https://github.com/BramVanroy/spacy_conll/compare/v3.3.0...v3.4.0", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v3.4.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v3.4.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v3.4.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/98568013", "release_id": 98568013, "date_created": "2023-04-02T14:03:15Z", "date_published": "2023-04-07T13:21:07Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/89216656", "tag": "v3.3.0", "name": "Changes to input format of pretokenized text", "author": {"name": "BramVanroy", "type": "User"}, "description": "Since spaCy 3.2.0, the data that is passed to a spaCy pipeline has become more strict. This means that passing \r\na list of pretokenized tokens (`[\"This\", \"is\", \"a\", \"pretokenized\", \"sentence\"]`) is not accepted anymore. Therefore,\r\nthe `is_tokenized` option needed to be adapted to reflect this. It is still possible to pass a string where tokens\r\nare separated by whitespaces, e.g. `\"This is a pretokenized sentence\"`, which will continue to work for spaCy and\r\nstanza. Support for pretokenized data has been dropped for UDPipe.\r\n\r\nSpecific changes:\r\n\r\n- **[conllparser]** Breaking change: `is_tokenized` is not a valid argument to `ConllParser` any more.\r\n- **[utils/conllparser]** Breaking change: when using UDPipe, pretokenized data is not supported any more.\r\n- **[utils]** Breaking change: `SpacyPretokenizedTokenizer.__call__` does not support a list of tokens any more.\r\n", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v3.3.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v3.3.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v3.3.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/89216656", "release_id": 89216656, "date_created": "2023-01-17T10:02:58Z", "date_published": "2023-01-17T10:03:57Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/63516244", "tag": "v3.2.0", "name": "Entry points and quality of life improvements", "author": {"name": "BramVanroy", "type": "User"}, "description": "- **[conllformatter]** Fixed an issue where `SpaceAfter=No` was not added correctly to tokens\r\n- **[conllformatter]** Added `ConllFormatter` as an entry point, which means that you do not have to import \r\n  `spacy_conll` anymore when you want to add the pipe to a parser! spaCy will know where to look for the CoNLL \r\n  formatter when you use `nlp.add_pipe(\"conll_formatter\")` without you having to import the component manually\r\n- **[conllformatter]** Now adds the component constructor on a construction function rather than directly on the class\r\n  as recommended by spacy. The formatter has also been re-written as a dataclass\r\n- **[conllformatter/utils]** Moved `merge_dicts_strict` to utils, outside the formatter class\r\n- **[conllparser]** Make ConllParser directly importable from the root of the library, i.e.,\r\n  `from spacy_conll import ConllParser`\r\n- **[init_parser]** Allow users to exclude pipeline components when using the spaCy parser with the \r\n  `exclude_spacy_components` argument\r\n- **[init_parser]** Fixed an issue where disabling sentence segmentation would not work if your model does\r\n  not have a parser\r\n- **[init_parser]** Enable more options when using stanza in terms of pre-segmented text. Now you can also disable\r\n  sentence segmentation for stanza (but still do tokenization) with the `disable_sbd` option\r\n- **[utils]** Added SpacyDisableSentenceSegmentation as an entry-point custom component so that you can use it in your\r\n  own code, by calling `nlp.add_pipe(\"disable_sbd\", before=\"parser\")`", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v3.2.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v3.2.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v3.2.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/63516244", "release_id": 63516244, "date_created": "2022-04-04T12:15:30Z", "date_published": "2022-04-04T12:16:48Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/46195663", "tag": "v3.0.2", "name": "Fix no_split_on_newline", "author": {"name": "BramVanroy", "type": "User"}, "description": "* **[conllparser]** Fix: fixed an issue with no_split_on_newline in combination with nlp.pipe", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v3.0.2", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v3.0.2", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v3.0.2", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/46195663", "release_id": 46195663, "date_created": "2021-07-14T15:14:56Z", "date_published": "2021-07-14T15:16:13Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/46164727", "tag": "v3.0.1", "name": "Bugfix for ConllParser: do not require stanza and udpipe", "author": {"name": "BramVanroy", "type": "User"}, "description": "* **[conllparser]** Fix: make sure the parser also runs if stanza and UDPipe are not installed\r\n", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v3.0.1", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v3.0.1", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v3.0.1", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/46164727", "release_id": 46164727, "date_created": "2021-07-14T05:47:55Z", "date_published": "2021-07-14T05:50:07Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/46047191", "tag": "v3.0.0", "name": "Release for spaCy v3", "author": {"name": "BramVanroy", "type": "User"}, "description": "This release makes `spacy_conll` compatible with spaCy's new v3 release. On top of that some improvements were made to make the project easier to maintain.\r\n\r\n* **[general]** Breaking change: spaCy v3 required (closes https://github.com/BramVanroy/spacy_conll/issues/8)\r\n* **[init_parser]** Breaking change: in all cases, `is_tokenized` now disables sentence segmentation\r\n* **[init_parser]** Breaking change: no more default values for parser or model anywhere. Important to note here that\r\n  spaCy does not work with short-hand codes such as ``en`` any more. You have to provide the full model name, e.g.\r\n  ``en_core_web_sm``\r\n* **[init_parser]** Improvement: models are automatically downloaded for Stanza and UDPipe\r\n* **[cli]** Reworked the position of the CLI script in the directory structure as well as the arguments. Run\r\n  `parse-as-conll -h` for more information.\r\n* **[conllparser]** Made the [ConllParser](spacy_conll/parser.py) class available as a utility to easily create a wrapper for a spaCy-like\r\n  parser which can return the parsed CoNLL output of a given file or text\r\n* **[conllparser,cli]** Improvements to usability of `n_process`. Will try to figure out whether multiprocessing\r\n  is available for your platform and if not, tell you so. Such a priori error messages can be disabled, with\r\n  `ignore_pipe_errors`, both on the command line as in ConllParser's parse methods\r\n\r\n", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v3.0.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v3.0.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v3.0.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/46047191", "release_id": 46047191, "date_created": "2021-07-12T10:13:30Z", "date_published": "2021-07-12T10:17:47Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/45096703", "tag": "v2.1.0", "name": "Preparing for v3 release", "author": {"name": "BramVanroy", "type": "User"}, "description": "* Last version to support spaCy v2. New versions will require spaCy v3\r\n* Last version to support ``spacy-stanfordnlp``. ``spacy-stanza`` is still supported", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v2.1.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v2.1.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v2.1.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/45096703", "release_id": 45096703, "date_created": "2021-06-23T09:38:19Z", "date_published": "2021-06-23T13:00:27Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/26388883", "tag": "v2.0.0", "name": "Stanza and UDPipe support, easy-to-use utility function, Token-attributes, and more", "author": {"name": "BramVanroy", "type": "User"}, "description": "**Fully reworked version!**\r\n\r\n* Tested support for both [`spacy-stanza`](https://github.com/explosion/spacy-stanza) and [`spacy-udpipe`](https://github.com/TakeLab/spacy-udpipe)! (Not included as a dependency, install manually)\r\n* Added a useful utility function `init_parser` that can easily initialise a parser together with the custom\r\n  pipeline component. (See the README or [examples](examples/))\r\n* Added the `disable_pandas` flag the the formatter class in case you would want to disable setting the pandas\r\n  attribute even when pandas is installed.\r\n* Added custom properties for Tokens as well. So now a Doc, its sentence Spans as well as Tokens have custom attributes\r\n* Reworked datatypes of output. In version 2.0.0 the data types are as follows:\r\n    - `._.conll`: raw CoNLL format\r\n        - in `Token`: a dictionary containing all the expected CoNLL fields as keys and the parsed properties as\r\n          values.\r\n        - in sentence `Span`: a list of its tokens' `._.conll` dictionaries (list of dictionaries).\r\n        - in a `Doc`: a list of its sentences' `._.conll` lists (list of list of dictionaries).\r\n    - `._.conll_str`: string representation of the CoNLL format\r\n        - in `Token`: tab-separated representation of the contents of the CoNLL fields ending with a newline.\r\n        - in sentence `Span`: the expected CoNLL format where each row represents a token. When\r\n          `ConllFormatter(include_headers=True)` is used, two header lines are included as well, as per the\r\n          `CoNLL format`_.\r\n        - in `Doc`: all its sentences' `._.conll_str` combined and separated by new lines.\r\n    - `._.conll_pd`: ``pandas`` representation of the CoNLL format\r\n        - in `Token`: a `Series` representation of this token's CoNLL properties.\r\n        - in sentence `Span`: a `DataFrame` representation of this sentence, with the CoNLL names as column\r\n          headers.\r\n        - in `Doc`: a concatenation of its sentences' `DataFrame`'s, leading to a new a `DataFrame` whose\r\n          index is reset.\r\n* `field_names` has been removed, assuming that you do not need to change the column names of the CoNLL properties\r\n* Removed the `Spacy2ConllParser` class\r\n* Many doc changes, added tests, and a few examples", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v2.0.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v2.0.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v2.0.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/26388883", "release_id": 26388883, "date_created": "2020-05-11T17:32:56Z", "date_published": "2020-05-11T17:36:11Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/25952530", "tag": "v1.3.0", "name": "Add SpaceAfter=No property", "author": {"name": "BramVanroy", "type": "User"}, "description": "* **IMPORTANT**: This will be the last release that supports the deprecated `Spacy2ConllParser` class!\r\n* Community addition: add SpaceAfter=No to the Misc field when applicable (https://github.com/BramVanroy/spacy_conll/pull/6). *Thanks* @KoichiYasuoka!\r\n* Fixed failing tests", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v1.3.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v1.3.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v1.3.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/25952530", "release_id": 25952530, "date_created": "2020-04-28T08:25:49Z", "date_published": "2020-04-28T08:29:17Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/23319444", "tag": "v1.2.0", "name": "Documentation spacy-stanfordnlp, custom tagset map", "author": {"name": "BramVanroy", "type": "User"}, "description": "The documentation has been greatly expanded. The most important addition to the README is the mention and explanation of using `spacy-stanfordnlp`. `spacy_conll` can be used together with this spaCy wrapper around `stanfordnlp`. The benefit is that we can use Stanford models, with a spaCy interface. From a user perspective, this means better models, **guaranteed Universal Dependencies tagsets**, and an easy API through spaCy. (The cost is that Stanford NLP models are significantly slower than spaCy's models.) Small tests for `spacy_stanfordnlp` have been added.\r\n\r\nA new feature is that you can now add a custom tagset map (`conversion_maps`). The idea is that you, as a user, have more control over the output tags. You can for instance specify that all `deprel` tags `nsubj` should be renamed to `subj`. This is useful if your model uses a different tagset than you want. See the advanced example in the README for more information.\r\n\r\nThis release closes:\r\n\r\n- \"The dependency relations aren't transformed to universal dependencies\" (https://github.com/BramVanroy/spacy_conll/issues/4)", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v1.2.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v1.2.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v1.2.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/23319444", "release_id": 23319444, "date_created": "2020-02-02T13:23:41Z", "date_published": "2020-02-02T13:31:10Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/22997486", "tag": "v1.1.0", "name": "Add dependencies to setup.py", "author": {"name": "BramVanroy", "type": "User"}, "description": "This small release adds the dependencies to `setup.py`, solving potential issues (e.g. https://github.com/BramVanroy/spacy_conll/issues/3).\r\n\r\nCurrent dependencies are:\r\n- packaging\r\n- spacy\r\n", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v1.1.0", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v1.1.0", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v1.1.0", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/22997486", "release_id": 22997486, "date_created": "2020-01-21T09:16:07Z", "date_published": "2020-01-21T09:19:04Z"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Release", "value": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/22860449", "tag": "v1.0.1", "name": "spaCy pipeline component, improved command line script with multiprocessing", "author": {"name": "BramVanroy", "type": "User"}, "description": "This small repo has been overhauled so that users can integrate it directly in their spaCy scripts. You can now use it as a spaCy component. Three custom attributes have been added to `Doc._.` and a `Doc`'s sentences. You can find more information in the README as well as example usage.\r\n\r\nThe command line script has been improved as well, now using the pipeline component instead of `Spacy2ConllParser`. The latter has been deprecated (but is still accessible for now). Multiprocessing via the command line script is now possible, too.\r\n", "tarball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/tarball/v1.0.1", "zipball_url": "https://api.github.com/repos/BramVanroy/spacy_conll/zipball/v1.0.1", "html_url": "https://github.com/BramVanroy/spacy_conll/releases/tag/v1.0.1", "url": "https://api.github.com/repos/BramVanroy/spacy_conll/releases/22860449", "release_id": 22860449, "date_created": "2020-01-15T14:16:27Z", "date_published": "2020-01-15T14:22:21Z"}, "confidence": 1, "technique": "GitHub_API"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "contributing_guidelines": [{"result": {"value": "# Contributing to `spacy_conll`\n\nIf you are solving a bug, please first create [an issue](https://github.com/BramVanroy/spacy_conll/issues)\n and mention that you are working on it. This way, other people with the same issue know that it is being worked on.\n\nIf you want to implement a new feature, let's first discuss how to best approach it in the \n [Discussions](https://github.com/BramVanroy/spacy_conll/discussions). \n\nIf you want to contribute to `spacy_conll`, it is recommended that you clone and install the repository with\n the `dev` option, which will install all required dependencies.\n\n```bash\ngit clone https://github.com/BramVanroy/spacy_conll.git\ncd spacy_conll\npip install -e .[dev]\n```\n\nYou'll also need to install the basic English spaCy model to successfully run the tests.\n\n```bash\npython -m spacy download en_core_web_sm\n```\n\nYou are now ready to start working on your issue. You can begin your\n [pull request](https://github.com/BramVanroy/spacy_conll/pulls) from your cloned branch while still working on it\n (add `[WIP]` to the front of the title of the PR in that case) - or you can submit the PR once you're done.\n\n## Important notes\n- Do your pull request against the `dev` branch, not master!\n- If you are still working on a PR, add `[WIP]` to the front of the title of the PR!\n- If your PR solves an issue, add `closes <link to the issue>` to the PR text so that the issue is closed automatically\n- Run the tests before finalizing the PR to make sure that everything is running as expected with `pytest tests/`\n- Ensure style is as expected with `make style` and `make quality`. We use black and isort for formatting.\n- When your PR is ready to be reviewed, remove `[WIP]` from the title. If you have not received any response *after a\n  week*, feel free to tag me on Github.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/CONTRIBUTING.md"}], "installation": [{"result": {"value": "By default, this package automatically installs only [spaCy](https://spacy.io/usage/models#section-quickstart) as \n dependency. Because [spaCy's models](https://spacy.io/usage/models) are not necessarily trained on Universal \n Dependencies conventions, their output labels are not UD either. By using `spacy-stanza` or `spacy-udpipe`, we get \n the easy-to-use interface of spaCy as a wrapper around `stanza` and `UDPipe` respectively, including their models that\n *are* trained on UD data.\n\n**NOTE**: `spacy-stanza` and `spacy-udpipe` are not installed automatically as a dependency for this library, because \n it might be too much overhead for those who don't need UD. If you wish to use their functionality, you have to install\nthem manually or use one of the available options as described  below.\n\nIf you want to retrieve CoNLL info as a `pandas` DataFrame, this library will automatically export it if it detects \n that `pandas` is installed. See the Usage section for more.\n\nTo install the library, simply use pip.\n\n```shell\n# only includes spacy by default\npip install spacy_conll\n```\n\nA number of options are available to make installation of additional dependencies easier:\n\n```shell\n# include spacy-stanza and spacy-udpipe\npip install spacy_conll[parsers]\n# include pandas\npip install spacy_conll[pd]\n# include pandas, spacy-stanza and spacy-udpipe\npip install spacy_conll[all]\n# include pandas, spacy-stanza and spacy-udpipe and additional libaries for testing and formatting\npip install spacy_conll[dev]\n```\n\n", "type": "Text_excerpt", "original_header": "Installation", "parent_header": ["Parsing to CoNLL with spaCy, spacy-stanza, and spacy-udpipe"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md"}], "usage": [{"result": {"value": "When the ConllFormatter is added to a spaCy pipeline, it adds CoNLL properties for `Token`, sentence `Span` and `Doc`.\n Note that arbitrary Span's are not included and do not receive these properties.\n\nOn all three of these levels, two custom properties are exposed by default, `._.conll` and its string \n representation `._.conll_str`. However, if you have `pandas` installed, then `._.conll_pd` will\n be added automatically, too!\n\n-   `._.conll`: raw CoNLL format  \n    -   in Token: a dictionary containing all the expected CoNLL fields as keys and the parsed properties as values.\n    -   in sentence Span: a list of its tokens' `._.conll` dictionaries (list of dictionaries).\n    -   in a Doc: a list of its sentences' `._.conll` lists (list of list of dictionaries).\n\n-   `._.conll_str`: string representation of the CoNLL format  \n    -   in Token: tab-separated representation of the contents of the CoNLL fields ending with a newline.\n    -   in sentence Span: the expected CoNLL format where each row represents a token. When \n        `ConllFormatter(include_headers=True)` is used, two header lines are included as well, as per the\n        [CoNLL format](https://universaldependencies.org/format.html#sentence-boundaries-and-comments).\n    -   in Doc: all its sentences' `._.conll_str` combined and separated by new lines.\n\n-   `._.conll_pd`: `pandas` representation of the CoNLL format  \n    -   in Token: a Series representation of this token's CoNLL properties.\n    -   in sentence Span: a DataFrame representation of this sentence, with the CoNLL names as column headers.\n    -   in Doc: a concatenation of its sentences' DataFrame's, leading to a new a DataFrame whose index is reset.\n\nYou can use `spacy_conll` in your own Python code as a custom pipeline component, or you can use the built-in\n command-line script which offers typically needed functionality. See the following section for more.\n\n", "type": "Text_excerpt", "original_header": "Usage", "parent_header": ["Parsing to CoNLL with spaCy, spacy-stanza, and spacy-udpipe"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md"}, {"result": {"value": "This library offers the ConllFormatter class which serves as a custom spaCy pipeline component. It can be instantiated\n as follows. It is important that you import `spacy_conll` before adding the pipe!\n\n```python\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\nnlp.add_pipe(\"conll_formatter\", last=True)\n```\n\nBecause this library supports different spaCy wrappers (`spacy`, `stanza`, and `udpipe`), a convenience function is\n available as well. With `utils.init_parser` you can easily instantiate a parser with a single line. You can\n find the function's signature below. Have a look at the [source code](spacy_conll/utils.py) to read more about all the\n possible arguments or try out the [examples](examples/).\n\n**NOTE**: `is_tokenized` does not work for `spacy-udpipe`. Using `is_tokenized` for `spacy-stanza` also affects sentence\n segmentation, effectively *only* splitting on new lines. With `spacy`, `is_tokenized` disables sentence splitting completely.\n\n```python\ndef init_parser(\n    model_or_lang: str,\n    parser: str,\n    *,\n    is_tokenized: bool = False,\n    disable_sbd: bool = False,\n    exclude_spacy_components: Optional[List[str]] = None,\n    parser_opts: Optional[Dict] = None,\n    **kwargs,\n)\n```\n\nFor instance, if you want to load a Dutch `stanza` model in silent mode with the CoNLL formatter already attached, you\n can simply use the following snippet. `parser_opts` is passed to the `stanza` pipeline initialisation automatically. \n Any other keyword arguments (`kwargs`), on the other hand, are passed to the `ConllFormatter` initialisation.\n\n```python\nfrom spacy_conll import init_parser\n\nnlp = init_parser(\"nl\", \"stanza\", parser_opts={\"verbose\": False})\n```\n\nThe `ConllFormatter` allows you to customize the extension names, and you can also specify conversion maps for the\noutput properties.\n\nTo illustrate, here is an advanced example, showing the more complex options:\n\n- `ext_names`: changes the attribute names to a custom key by using a dictionary.\n-  `conversion_maps`: a two-level dictionary that looks like `{field_name: {tag_name: replacement}}`. In \n   other words, you can specify in which field a certain value should be replaced by another. This is especially useful\n   when you are not satisfied with the tagset of a model and wish to change some tags to an alternative0. \n- `field_names`: allows you to change the default CoNLL-U field names to your own custom names. Similar to the \n   conversion map above, you should use any of the default field names as keys and add your own key as value. \n   Possible keys are : \"ID\", \"FORM\", \"LEMMA\", \"UPOS\", \"XPOS\", \"FEATS\", \"HEAD\", \"DEPREL\", \"DEPS\", \"MISC\".\n\nThe example below\n\n- shows how to manually add the component;\n- changes the custom attribute `conll_pd` to pandas (`conll_pd` only availabe if `pandas` is installed);\n- converts any `nsubj` deprel tag to `subj`.\n\n```python\nimport spacy\n\n\nnlp = spacy.load(\"en_core_web_sm\")\nconfig = {\"ext_names\": {\"conll_pd\": \"pandas\"},\n          \"conversion_maps\": {\"deprel\": {\"nsubj\": \"subj\"}}}\nnlp.add_pipe(\"conll_formatter\", config=config, last=True)\ndoc = nlp(\"I like cookies.\")\nprint(doc._.pandas)\n```\n\nThis is the same as:\n\n```python\nfrom spacy_conll import init_parser\n\nnlp = init_parser(\"en_core_web_sm\",\n                  \"spacy\",\n                  ext_names={\"conll_pd\": \"pandas\"},\n                  conversion_maps={\"deprel\": {\"nsubj\": \"subj\"}})\ndoc = nlp(\"I like cookies.\")\nprint(doc._.pandas)\n```\n\n\nThe snippets above will output a pandas DataFrame by using `._.pandas` rather than the standard\n`._.conll_pd`, and all occurrences of `nsubj` in the deprel field are replaced by `subj`.\n\n```\n   ID     FORM   LEMMA    UPOS    XPOS                                       FEATS  HEAD DEPREL DEPS           MISC\n0   1        I       I    PRON     PRP  Case=Nom|Number=Sing|Person=1|PronType=Prs     2   subj    _              _\n1   2     like    like    VERB     VBP                     Tense=Pres|VerbForm=Fin     0   ROOT    _              _\n2   3  cookies  cookie    NOUN     NNS                                 Number=Plur     2   dobj    _  SpaceAfter=No\n3   4        .       .   PUNCT       .                              PunctType=Peri     2  punct    _  SpaceAfter=No\n```\n\nAnother initialization example that would replace the column names \"UPOS\" with \"upostag\" amd \"XPOS\" with \"xpostag\":\n\n```python\nimport spacy\n\n\nnlp = spacy.load(\"en_core_web_sm\")\nconfig = {\"field_names\": {\"UPOS\": \"upostag\", \"XPOS\": \"xpostag\"}}\nnlp.add_pipe(\"conll_formatter\", config=config, last=True)\n```\n", "type": "Text_excerpt", "original_header": "In Python", "parent_header": ["Parsing to CoNLL with spaCy, spacy-stanza, and spacy-udpipe", "Usage"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md"}, {"result": {"value": "It is possible to read a CoNLL string or text file and parse it as a spaCy object. This can be useful if you have raw\nCoNLL data that you wish to process in different ways. The process is straightforward.\n\n```python\nfrom spacy_conll import init_parser\nfrom spacy_conll.parser import ConllParser\n\n\nnlp = ConllParser(init_parser(\"en_core_web_sm\", \"spacy\"))\n\ndoc = nlp.parse_conll_file_as_spacy(\"path/to/your/conll-sample.txt\")\n'''\nor straight from raw text:\nconllstr = \"\"\"\n# text = From the AP comes this story :\n1\tFrom\tfrom\tADP\tIN\t_\t3\tcase\t3:case\t_\n2\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t3\tdet\t3:det\t_\n3\tAP\tAP\tPROPN\tNNP\tNumber=Sing\t4\tobl\t4:obl:from\t_\n4\tcomes\tcome\tVERB\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t0:root\t_\n5\tthis\tthis\tDET\tDT\tNumber=Sing|PronType=Dem\t6\tdet\t6:det\t_\n6\tstory\tstory\tNOUN\tNN\tNumber=Sing\t4\tnsubj\t4:nsubj\t_\n\"\"\"\ndoc = nlp.parse_conll_text_as_spacy(conllstr)\n'''\n\n# Multiple CoNLL entries (separated by two newlines) will be included as different sentences in the resulting Doc\nfor sent in doc.sents:\n    for token in sent:\n        print(token.text, token.dep_, token.pos_)\n```\n", "type": "Text_excerpt", "original_header": "Reading CoNLL into a spaCy object", "parent_header": ["Parsing to CoNLL with spaCy, spacy-stanza, and spacy-udpipe", "Usage", "In Python"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md"}, {"result": {"value": "Upon installation, a command-line script is added under tha alias `parse-as-conll`. You can use it to parse a\nstring or file into CoNLL format given a number of options.\n\n```shell\nparse-as-conll -h\nusage: parse-as-conll [-h] [-f INPUT_FILE] [-a INPUT_ENCODING] [-b INPUT_STR] [-o OUTPUT_FILE]\n                  [-c OUTPUT_ENCODING] [-s] [-t] [-d] [-e] [-j N_PROCESS] [-v]\n                  [--ignore_pipe_errors] [--no_split_on_newline]\n                  model_or_lang {spacy,stanza,udpipe}\n\nParse an input string or input file to CoNLL-U format using a spaCy-wrapped parser. The output\ncan be written to stdout or a file, or both.\n\npositional arguments:\n  model_or_lang         Model or language to use. SpaCy models must be pre-installed, stanza\n                        and udpipe models will be downloaded automatically\n  {spacy,stanza,udpipe}\n                        Which parser to use. Parsers other than 'spacy' need to be installed\n                        separately. For 'stanza' you need 'spacy-stanza', and for 'udpipe' the\n                        'spacy-udpipe' library is required.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -f INPUT_FILE, --input_file INPUT_FILE\n                        Path to file with sentences to parse. Has precedence over 'input_str'.\n                        (default: None)\n  -a INPUT_ENCODING, --input_encoding INPUT_ENCODING\n                        Encoding of the input file. Default value is system default. (default:\n                        cp1252)\n  -b INPUT_STR, --input_str INPUT_STR\n                        Input string to parse. (default: None)\n  -o OUTPUT_FILE, --output_file OUTPUT_FILE\n                        Path to output file. If not specified, the output will be printed on\n                        standard output. (default: None)\n  -c OUTPUT_ENCODING, --output_encoding OUTPUT_ENCODING\n                        Encoding of the output file. Default value is system default. (default:\n                        cp1252)\n  -s, --disable_sbd     Whether to disable spaCy automatic sentence boundary detection. In\n                        practice, disabling means that every line will be parsed as one\n                        sentence, regardless of its actual content. When 'is_tokenized' is\n                        enabled, 'disable_sbd' is enabled automatically (see 'is_tokenized').\n                        Only works when using 'spacy' as 'parser'. (default: False)\n  -t, --is_tokenized    Whether your text has already been tokenized (space-seperated). Setting\n                        this option has as an important consequence that no sentence splitting\n                        at all will be done except splitting on new lines. So if your input is\n                        a file, and you want to use pretokenised text, make sure that each line\n                        contains exactly one sentence. (default: False)\n  -d, --include_headers\n                        Whether to include headers before the output of every sentence. These\n                        headers include the sentence text and the sentence ID as per the CoNLL\n                        format. (default: False)\n  -e, --no_force_counting\n                        Whether to disable force counting the 'sent_id', starting from 1 and\n                        increasing for each sentence. Instead, 'sent_id' will depend on how\n                        spaCy returns the sentences. Must have 'include_headers' enabled.\n                        (default: False)\n  -j N_PROCESS, --n_process N_PROCESS\n                        Number of processes to use in nlp.pipe(). -1 will use as many cores as\n                        available. Might not work for a 'parser' other than 'spacy' depending\n                        on your environment. (default: 1)\n  -v, --verbose         Whether to always print the output to stdout, regardless of\n                        'output_file'. (default: False)\n  --ignore_pipe_errors  Whether to ignore a priori errors concerning 'n_process' By default we\n                        try to determine whether processing works on your system and stop\n                        execution if we think it doesn't. If you know what you are doing, you\n                        can ignore such pre-emptive errors, though, and run the code as-is,\n                        which will then throw the default Python errors when applicable.\n                        (default: False)\n  --no_split_on_newline\n                        By default, the input file or string is split on newlines for faster\n                        processing of the split up parts. If you want to disable that behavior,\n                        you can use this flag. (default: False)\n```\n\n\nFor example, parsing a single line, multi-sentence string:\n\n```shell\nparse-as-conll en_core_web_sm spacy --input_str \"I like cookies. What about you?\" --include_headers\n\n# sent_id = 1\n# text = I like cookies.\n1       I       I       PRON    PRP     Case=Nom|Number=Sing|Person=1|PronType=Prs      2       nsubj   _       _\n2       like    like    VERB    VBP     Tense=Pres|VerbForm=Fin 0       ROOT    _       _\n3       cookies cookie  NOUN    NNS     Number=Plur     2       dobj    _       SpaceAfter=No\n4       .       .       PUNCT   .       PunctType=Peri  2       punct   _       _\n\n# sent_id = 2\n# text = What about you?\n1       What    what    PRON    WP      _       2       dep     _       _\n2       about   about   ADP     IN      _       0       ROOT    _       _\n3       you     you     PRON    PRP     Case=Acc|Person=2|PronType=Prs  2       pobj    _       SpaceAfter=No\n4       ?       ?       PUNCT   .       PunctType=Peri  2       punct   _       SpaceAfter=No\n```\n\nFor example, parsing a large input file and writing output to a given output file, using four processes:\n\n```shell\nparse-as-conll en_core_web_sm spacy --input_file large-input.txt --output_file large-conll-output.txt --include_headers --disable_sbd -j 4\n```\n\n", "type": "Text_excerpt", "original_header": "Command line", "parent_header": ["Parsing to CoNLL with spaCy, spacy-stanza, and spacy-udpipe", "Usage"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md"}], "citation": [{"result": {"value": "The first version of this library was inspired by initial work by [rgalhama](https://github.com/rgalhama/spaCy2CoNLLU)\n and has evolved a lot since then.\n", "type": "Text_excerpt", "original_header": "Credits", "parent_header": ["Parsing to CoNLL with spaCy, spacy-stanza, and spacy-udpipe"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md"}], "full_title": [{"result": {"type": "String", "value": "Parsing to CoNLL with spaCy, spacy-stanza, and spacy-udpipe"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/BramVanroy/spacy_conll/master/README.md"}]}