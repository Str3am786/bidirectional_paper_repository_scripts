{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:20:40"}, "code_repository": [{"result": {"value": "https://github.com/hpclab/efficient_nn_for_ltr", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "hpclab", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2022-02-15T10:59:58Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-06-17T16:19:20Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "license": [{"result": {"value": "https://api.github.com/licenses/mit", "type": "License", "name": "MIT License", "url": "https://api.github.com/licenses/mit", "spdx_id": "MIT"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "MIT License\n\nCopyright (c) 2022 HPC Laboratory @ ISTI - CNR\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/LICENSE"}], "description": [{"result": {"value": "This is the official repository of F. M. Nardini, C. Rulli, S. Trani, R. Venturini, \"Distilled Neural Networks for Efficient Learning to Rank\". IEEE TKDE. 2022.", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Text_excerpt", "value": "This is the official repository of F. M. Nardini, C. Rulli, S. Trani, R. Venturini, [\"Distilled Neural Networks for Efficient Learning to Rank\"](https://ieeexplore.ieee.org/abstract/document/9716821). IEEE TKDE. 2022 \n", "original_header": "DistillMLPToRank"}, "confidence": 0.9829485998860817, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "The script ```train.py``` allows to train a model by distillation from a pre-trained ensemble of regression trees. We provide the tree-based models, thus you do not have to it on your own.\nThe pre-trained model for MSN30k is avaialble in this repo (BASH2*). The model for I-stella is avaialble here https://www.dropbox.com/sh/b5fo04eoczu4qe0/AADkTvvrYWLZq3rYoBVo-NaJa?dl=0.  \nto see all the training options.  \n \n", "original_header": "Training a model"}, "confidence": 0.8848302141955392, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md"}], "name": [{"result": {"value": "efficient_nn_for_ltr", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "hpclab/efficient_nn_for_ltr", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/hpclab/efficient_nn_for_ltr/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/hpclab/efficient_nn_for_ltr/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 7, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 0, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/hpclab/efficient_nn_for_ltr/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 50509}, "confidence": 1, "technique": "GitHub_API"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "requirements": [{"result": {"value": "This code has been tested with python 3.7 and PyTorch 1.6. In this PyTorch version, there was not a native way to implement pruning, so we rely on the [distiller](https://github.com/IntelLabs/distiller/) library. This amy cause some difficultier during the installation as Distiller's dependencies are now broken. \n__To install distiller__, clone its repository, type ```cd distiller``` and then comment the following dependencies in ```requirements.txt.```\n\n- torch\n- tensorflow\n- pretrainedmodels \n\nTo install the other dependencies, simply type \n```\npip install -r requirements\n```\n", "type": "Text_excerpt", "original_header": "Requirements", "parent_header": ["DistillMLPToRank"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md"}], "download": [{"result": {"value": "Download link for the datasets:\n- MSN30k [here](https://www.microsoft.com/en-us/research/project/mslr/)\n- Istella-S [here](http://quickrank.isti.cnr.it/istella-dataset/)\n\nOn MSN30K, experiments will be conducted on Fold1 by defaut. ", "type": "Text_excerpt", "original_header": "Download Dataset", "parent_header": ["DistillMLPToRank"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md"}], "usage": [{"result": {"value": "```python train.py --dataset-name msn30k --original-model LM600_msn --original-model-path msn30k_256leaves_ensemble.xml --name sample_model```\n\nInside the folder ```logs``` you will find a subfolder named \"sample_model\" that contains the logs file.\n\n\n", "type": "Text_excerpt", "original_header": "Example", "parent_header": ["DistillMLPToRank", "Compressing a model"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md"}], "invocation": [{"result": {"type": "Text_excerpt", "value": "Run \n```python train.py --help```\n \n", "original_header": "Training a model"}, "confidence": 0.9487369153149185, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md"}, {"result": {"type": "Text_excerpt", "value": "### Example \n```python distiller_compression.py --dataset-name msn30k --original-model LM600_msn --original-model-path msn30k_256leaves_ensemble.xml --name sample_compression --compress compress_MLP.yaml ```\n \n", "original_header": "Compressing a model"}, "confidence": 0.9336312021766846, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md"}], "full_title": [{"result": {"type": "String", "value": "DistillMLPToRank"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/hpclab/efficient_nn_for_ltr/main/README.md"}]}