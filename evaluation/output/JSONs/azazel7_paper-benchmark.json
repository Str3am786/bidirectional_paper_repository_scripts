{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:04:12"}, "code_repository": [{"result": {"value": "https://github.com/azazel7/paper-benchmark", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "azazel7", "type": "User"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2019-10-18T20:16:22Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2022-03-29T12:57:58Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "description": [{"result": {"value": "The latex code to compile the skeleton for the benchmark.", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Text_excerpt", "value": "This repository contains the script, the datasets, and the source code to\nconduct a benchmark of Mondrian Forest under Memory Constraints. The original study was proposed\nin [todo](). The results were obtained with the\nversion 1.1 of this repository.\n \n", "original_header": "Mondrian Forest Under Memory Constraints"}, "confidence": 0.9878612135172162, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}], "name": [{"result": {"value": "paper-benchmark", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "azazel7/paper-benchmark", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/azazel7/paper-benchmark/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/azazel7/paper-benchmark/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 0, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 0, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/azazel7/paper-benchmark/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 64471}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "C++", "name": "C++", "type": "Programming_language", "size": 26721}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Shell", "name": "Shell", "type": "Programming_language", "size": 13820}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Makefile", "name": "Makefile", "type": "Programming_language", "size": 9406}, "confidence": 1, "technique": "GitHub_API"}], "has_script_file": [{"result": {"value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/run_xp2.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/setup_xp0.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/setup_xp1_xp2.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/run_xp1.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "requirements": [{"result": {"value": "This benchmark requires the following software:\n- git: to download the source codes, the modules, and the datasets.\n- gcc: to compile.\n- pandas, seaborn, matplotlib: to plot the figures.\n", "type": "Text_excerpt", "original_header": "Requirements", "parent_header": ["A benchmark of data stream classification for human activity recognition on connected objects"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}], "installation": [{"result": {"value": "First we clone the repository and we initialize the submodules.\n```\ngit clone https://github.com/big-data-lab-team/benchmark-har-data-stream.git benchmark\ncd benchmark\ngit submodule init\ngit submodule update\n```\n\nThen we compile all the binary to run the experiment.\n```\n./setup_xp1_xp2.sh\n```\nThis script take care of compiling the binary files and placing these files into a directory related to the dataset name.\n\nThen we extract the datasets and we place the dataset in memory.\n```\ntar xf datasets_xp1_xp2.tar.xz\ncp *.log /tmp\n```\n\nTo run the experiment, we rely on two more scripts.\n```\n./run_xp1.sh\n./run_xp2.sh\n```\nTwo directories are generated, results_xp1 and results_xp2.\n\nFrom these results directories, we generate the plots with the following command:\n```\n./plot_xp1.py\n./plot_xp2.py\n```\n", "type": "Text_excerpt", "original_header": "Setup the repository for Mondrian Forest under Memory Constraints", "parent_header": ["Mondrian Forest Under Memory Constraints"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"value": "First we clone the repository and we initialize the submodules.\n```\ngit clone https://github.com/big-data-lab-team/benchmark-har-data-stream.git benchmark\ncd benchmark\ngit submodule init\ngit submodule update\n```\n\nThen we compile streamDM-Cpp. To get a static library, we patch the Makefile.\n```\npatch streamDM-Cpp/makefile streamdm_patch\ncd streamDM-Cpp\nmake -j 8 static\ncd ..\n```\n\nThen we compile all the binary to run the experiment.\n```\nmkdir bin\n./setup_xp0.sh\n```\nThis script take care of compiling the binary files and placing these files into a directory related to the dataset name.\n\nThen we extract the datasets and we place the dataset in memory.\n```\ntar xf datasets_xp0.tar.xz\ncp *.log /tmp\n```\n\nTo run the experiment, we rely on the make command, then we collect the result\non the current directory. Note that `make run` can be replaced by `make\ncalibration` to run an extensive search on the parameter.\n```\nmake run\ncp models.csv /tmp/output /tmp/output_runs .\n```\n\nFrom the experiment results, we generate the plots (Figure 1-3) with the following command:\n```\nmake plot_results\n```\n\nFrom the calibration results, we generate the plots (Figure 4,5) with this command:\n```\nmake plot_hyperparameters\n```\n\nRegenerating MOA datasets\n-------------------------\n\nThe MOA dataset can be regenerated with the command `make moa_xp0` even\nthough they are also stored in datasets.tar.xz.  MOA archive is available\n[here](https://sourceforge.net/projects/moa-datastream/). You can download it\nand place it in the repository under the name *moa* or you can modify the\nvariable *MOA_DIR* in the Makefile. Then you'll need to modify the arff files\nto remove the header and change the tabulation into commas and rename the class\nname to actual numbers starting at zero.\n\n\nResult Structure\n----------------\nThe results are split in three files:\n- models.csv\n- output \n- output_runs\n\nThe models.csv file contains information about the runs.\n- model_id: a primary key that identify each models (algorithm+parameter+dataset).\n- name: the algorithm's name.\n- file: the dataset used.\n- parameters: the other field are the parameter of the algorithm.\n\nThe file output_runs contains information about each repetition:\n- model_id: the id of the model.\n- run_id: the id of the repetition.\n- time: the runtime in seconds.\n- energy: the energy used in joules.\n- power: the power consumption in watts.\n\nThe file output is a CSV file split in these columns:\n- model_id: the id of the model seen in models.csv.\n- run_id: the id of the repetition, which is often a number between 0 and the number of repetitions.\n- element_count: the number of data point seen so far.\n- seed: the seed used for that repetition.\n- accuracy: the accuracy updated with the last data point.\n- f1: the F1 score updated with the last data point.\n- memory: The amount of memory used.\n", "type": "Text_excerpt", "original_header": "Setup the repository", "parent_header": ["A benchmark of data stream classification for human activity recognition on connected objects"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}], "acknowledgement": [{"result": {"value": "The MOA dataset can be regenerated with the command `make moa_xp1_xp2` even\nthough they are also stored in datasets.tar.xz.  MOA archive is available\n[here](https://sourceforge.net/projects/moa-datastream/). You can download it\nand place it in the repository under the name *moa* or you can modify the\nvariable *MOA_DIR* in the Makefile. Then you'll need to modify the arff files\nto remove the header and change the tabulation into commas and rename the class\nname to actual numbers starting at zero.\n\n", "type": "Text_excerpt", "original_header": "Regenerating MOA datasets", "parent_header": ["A benchmark of data stream classification for human activity recognition on connected objects"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"value": "The results are split in six directories containing the results for each datasets.\nFor a given dataset, there is one result file per method. For instance, the\nfile mondrian_t30_partial.csv contains the results for the Mondrian Forest with\n30 trees with the Partial Update out-of-memory strategy.\n\nAn output file is a CSV file split in these columns:\n- model_id: not used here.\n- run_id: the id of the repetition, which is a number between 0 and the number of repetitions.\n- element_count: the number of data point seen so far.\n- seed: the seed used for that repetition.\n- accuracy: the accuracy updated with the last data point.\n- f1: the F1 score updated with the last data point.\n- memory: The amount of memory used.\n", "type": "Text_excerpt", "original_header": "Result Structure", "parent_header": ["A benchmark of data stream classification for human activity recognition on connected objects"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"value": "This repository contains the script, the datasets, and the source code to\nconduct a benchmark of data stream classifiers. The original study was proposed\nin [here](https://arxiv.org/abs/2008.11880). The results were obtained with the\nversion 1.0 of this repository.\n\nRequirements\n------------\nThis benchmark requires the following software:\n- git: to download the source codes, the modules, and the datasets.\n- gcc: to compile.\n- perf: to evaluate the resource usage, in particular, the runtime and the energy.\n- pandas, seaborn, matplotlib: to plot the figures.\n- log4cpp: log4cpp is a requirement for streamDM-Cpp.\n", "type": "Text_excerpt", "original_header": "A benchmark of data stream classification for human activity recognition on connected objects"}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"value": "To add a new dataset, you need a CSV file where each line is a data point and\nthe last field of that line is an integer that represents the class of the data\npoint.  Then you need to add a make command in the script *setup.sh* to have\nthe binary files place in the proper directory. The name of that directory\nshould be the name of the dataset file.\n\nThen, you'll need to modify the function *final_list* in *makefile.py* to\nappend the name of the new dataset to the list.\n", "type": "Text_excerpt", "original_header": "Adding a dataset", "parent_header": ["A benchmark of data stream classification for human activity recognition on connected objects"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"value": "To add a new classifier, you need to code a C++ file that defines the function\n*get_classifier* and that returns a classifier object. This object must implement\ntwo functions: train and predict. The file *empty.cpp* is an example.\n\nOnce you have written the classifier code, you need to modify the Makefile so\nit compiles it depending on the parameter provided to *make* such as\nthe number of features or the number of classes.\n\nFinally, you will need to modify the function *final_list* in *makefile.py* to\nadd the classifier to each dataset.\n", "type": "Text_excerpt", "original_header": "Adding a classifier", "parent_header": ["A benchmark of data stream classification for human activity recognition on connected objects"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"value": "*** Mondrian Forest\n\nHyperparameters used for Mondrian:\n\n| Number of trees | Base count | Discount | Budget |\n|-----------------|------------|----------|--------|\n| 1               | 0.0        | 1.0      | 1.0    |\n| 5               | 0.0        | 1.0      | 0.4    |\n| 10              | 0.0        | 1.0      | 0.4    |\n| 50              | 0.0        | 1.0      | 0.2    |\n\nImpact of the base count with 10 trees, a budget of 1.0, and a discount factor of 0.2.\n![](paper/figures/calibration_mondrian_base.png)\n\nImpact of the budget with 10 trees, a base count of 0.1, and discount factor of 0.2.\n![](paper/figures/calibration_mondrian_discount.png)\n\nImpact of the discount factor with 10 trees, a budget of 1.0, and a base count of 0.1.\n![](paper/figures/calibration_mondrian_lifetime.png)\n\n*** MCNN\n\nHyperparameters used for MCNN:\n| Number of clusters | Error threshold | Participation threshold |\n|--------------------|-----------------|-------------------------|\n| 10                 | 2               | 10                      |\n| 20                 | 10              | 10                      |\n| 33                 | 16              | 10                      |\n| 40                 | 8               | 10                      |\n| 50                 | 2               | 10                      |\n\nError threshold tuning of \\mcnn with the first subject of Banos et al dataset. Error threshold in parenthesis.\n![](paper/calibration_mcnn.png)\n\n", "type": "Text_excerpt", "original_header": "Hyperparameters", "parent_header": ["A benchmark of data stream classification for human activity recognition on connected objects"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}], "full_title": [{"result": {"type": "String", "value": "Mondrian Forest Under Memory Constraints"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}], "image": [{"result": {"type": "Url", "value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/paper/figures/calibration_mondrian_base.png"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"type": "Url", "value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/paper/figures/calibration_mondrian_discount.png"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"type": "Url", "value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/paper/figures/calibration_mondrian_lifetime.png"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}, {"result": {"type": "Url", "value": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/paper/calibration_mcnn.png"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}], "related_papers": [{"result": {"type": "Url", "value": "https://arxiv.org/abs/2008.11880"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/azazel7/paper-benchmark/master/README.md"}]}