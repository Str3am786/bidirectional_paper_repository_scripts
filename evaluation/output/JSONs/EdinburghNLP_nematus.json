{"somef_provenance": {"somef_version": "0.9.4", "somef_schema_version": "1.0.0", "date": "2023-12-21 19:17:58"}, "code_repository": [{"result": {"value": "https://github.com/EdinburghNLP/nematus", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "owner": [{"result": {"value": "EdinburghNLP", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2016-04-26T13:34:49Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "date_updated": [{"result": {"value": "2023-12-20T03:14:43Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "license": [{"result": {"value": "https://api.github.com/licenses/bsd-3-clause", "type": "License", "name": "BSD 3-Clause \"New\" or \"Revised\" License", "url": "https://api.github.com/licenses/bsd-3-clause", "spdx_id": "BSD-3-Clause"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Copyright (c) 2015, Kyunghyun Cho\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of Nematus nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/LICENSE"}], "description": [{"result": {"value": "Open-Source Neural Machine Translation in Tensorflow", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"type": "Text_excerpt", "value": "Attention-based encoder-decoder model for neural machine translation built in Tensorflow. \n  - support for RNN and Transformer architectures \n - other usability features:\n     - command line interface for training, scoring, and decoding\n     - JSON-formatted storage of model hyperparameters, vocabulary files and training progress\n     - pretrained models for 13 translation directions (many top-performing at WMT shared task of respective year):\n       - http://data.statmt.org/rsennrich/wmt16_systems/\n       - http://data.statmt.org/wmt17_systems/\n     - backward compatibility: continue using publicly released models with current codebase (scripts to convert from Theano to Tensorflow-style models are provided) \n", "original_header": "NEMATUS"}, "confidence": 0.9138479808143952, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "Nematus originated as a fork of dl4mt-tutorial by Kyunghyun Cho et al. ( https://github.com/nyu-dl/dl4mt-tutorial ), and was implemented in Theano.\nSee https://github.com/EdinburghNLP/nematus/tree/theano for this Theano-based version of Nematus. \n", "original_header": "LEGACY THEANO VERSION"}, "confidence": 0.809161618464226, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "Rico Sennrich, Orhan Firat, Kyunghyun Cho, Alexandra Birch, Barry Haddow, Julian Hitschler, Marcin Junczys-Dowmunt, Samuel L\u00e4ubli, Antonio Valerio Miceli Barone, Jozef Mokry and Maria Nadejde (2017): Nematus: a Toolkit for Neural Machine Translation. In Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics, Valencia, Spain, pp. 65-68. \n"}, "confidence": 0.9738563714852548, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "the code is based on the following models: \nDzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio (2015): Neural Machine Translation by Jointly Learning to Align and Translate, Proceedings of the International Conference on Learning Representations (ICLR). \nplease refer to the Nematus paper for a description of implementation differences to the RNN model. \n", "original_header": "PUBLICATIONS"}, "confidence": 0.9543823446789063, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}], "name": [{"result": {"value": "nematus", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "full_name": [{"result": {"value": "EdinburghNLP/nematus", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/EdinburghNLP/nematus/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/EdinburghNLP/nematus/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 792, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "keywords": [{"result": {"value": "machine-translation, mt, neural-machine-translation, nmt, sequence-to-sequence", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "forks_count": [{"result": {"value": 273, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/EdinburghNLP/nematus/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "programming_languages": [{"result": {"value": "Python", "name": "Python", "type": "Programming_language", "size": 454705}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Perl", "name": "Perl", "type": "Programming_language", "size": 29347}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Emacs Lisp", "name": "Emacs Lisp", "type": "Programming_language", "size": 17034}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "JavaScript", "name": "JavaScript", "type": "Programming_language", "size": 17029}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Hack", "name": "Hack", "type": "Programming_language", "size": 10635}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Shell", "name": "Shell", "type": "Programming_language", "size": 6960}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Smalltalk", "name": "Smalltalk", "type": "Programming_language", "size": 1892}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Ruby", "name": "Ruby", "type": "Programming_language", "size": 1649}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "NewLisp", "name": "NewLisp", "type": "Programming_language", "size": 1582}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Slash", "name": "Slash", "type": "Programming_language", "size": 356}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "SystemVerilog", "name": "SystemVerilog", "type": "Programming_language", "size": 184}, "confidence": 1, "technique": "GitHub_API"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "has_script_file": [{"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/test/test_train_reload.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/test/test_train_outputactivations.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/test/test_train.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/test/test_train_l2_loss.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/test/test_train_mapl2_loss.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/test/test_train_transformer.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/test/test_train_summaries.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/data/merge.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/data/preprocess.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/data/postprocess.sh", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "support": [{"result": {"value": "For general support requests, there is a Google Groups mailing list at https://groups.google.com/d/forum/nematus-support . You can also send an e-mail to nematus-support@googlegroups.com .\n\n", "type": "Text_excerpt", "original_header": "SUPPORT"}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}], "installation": [{"result": {"value": "Nematus requires the following packages:\n\n - Python 3 (tested on version 3.5.2)\n - TensorFlow 1.15 / 2.X (tested on version 2.0)\n\nTo install tensorflow, we recommend following the steps at:\n  ( https://www.tensorflow.org/install/ )\n\nthe following packages are optional, but *highly* recommended\n\n - CUDA >= 7  (only GPU training is sufficiently fast)\n - cuDNN >= 4 (speeds up training substantially)\n\n", "type": "Text_excerpt", "original_header": "INSTALLATION"}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "|---        |---          |\n| --source_dataset PATH | parallel training corpus (source) |\n| --target_dataset PATH | parallel training corpus (target) |\n| --dictionaries PATH [PATH ...] | network vocabularies (one per source factor, plus target vocabulary) |\n| --save_freq INT | save frequency (default: 30000) |\n| --model PATH | model file name (default: model) |\n| --reload PATH | load existing model from this path. Set to \"latest_checkpoint\" to reload the latest checkpoint in the same directory of --model |\n| --no_reload_training_progress | don't reload training progress (only used if --reload is enabled) |\n| --summary_dir PATH | directory for saving summaries (default: same directory as the --model file) |\n| --summary_freq INT | Save summaries after INT updates, if 0 do not save summaries (default: 0) |\n", "type": "Text_excerpt", "original_header": "data sets; model loading and saving", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"type": "Text_excerpt", "value": "To test your setup, we provide some speed benchmarks with `test/test_train.sh',\non an Intel Xeon CPU E5-2620 v4, with a Nvidia GeForce GTX Titan X (Pascal) and CUDA 9.0: \n\nGPU, CuDNN 5.1, tensorflow 1.0.1: \n  CUDA_VISIBLE_DEVICES=0 ./test_train.sh \n", "original_header": "TRAINING SPEED"}, "confidence": 0.8983281301552339, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}], "usage": [{"result": {"value": "You can also create docker image by running following command, where you change `suffix` to either `cpu` or `gpu`:\n\n`docker build -t nematus-docker -f Dockerfile.suffix .`\n\nTo run a CPU docker instance with the current working directory shared with the Docker container, execute:\n\n``docker run -v `pwd`:/playground -it nematus-docker``\n\nFor GPU you need to have nvidia-docker installed and run:\n\n``nvidia-docker run -v `pwd`:/playground -it nematus-docker``\n\n", "type": "Text_excerpt", "original_header": "DOCKER USAGE"}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "All of the scripts below can be run with `--help` flag to get usage information.\n\nSample commands with toy examples are available in the `test` directory;\nfor training a full-scale RNN system, consider the training scripts at http://data.statmt.org/wmt17_systems/training/\n\nAn updated version of these scripts that uses the Transformer model can be found at https://github.com/EdinburghNLP/wmt17-transformer-scripts\n", "type": "Text_excerpt", "original_header": "USAGE INSTRUCTIONS"}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "|---        |---          |\n| --model_type {rnn,transformer} | model type (default: rnn) |\n| --embedding_size INT | embedding layer size (default: 512) |\n| --state_size INT | hidden state size (default: 1000) |\n| --source_vocab_sizes INT [INT ...] | source vocabulary sizes (one per input factor) (default: None) |\n| --target_vocab_size INT | target vocabulary size (default: -1) |\n| --factors INT | number of input factors (default: 1) - CURRENTLY ONLY WORKS FOR 'rnn' MODEL |\n| --dim_per_factor INT [INT ...] | list of word vector dimensionalities (one per factor): '--dim_per_factor 250 200 50' for total dimensionality of 500 (default: None) |\n| --tie_encoder_decoder_embeddings | tie the input embeddings of the encoder and the decoder (first factor only). Source and target vocabulary size must be the same |\n| --tie_decoder_embeddings | tie the input embeddings of the decoder with the softmax output embeddings |\n| --output_hidden_activation {tanh,relu,prelu,linear} | activation function in hidden layer of the output network (default: tanh) - CURRENTLY ONLY WORKS FOR 'rnn' MODEL |\n| --softmax_mixture_size INT | number of softmax components to use (default: 1) - CURRENTLY ONLY WORKS FOR 'rnn' MODEL |\n", "type": "Text_excerpt", "original_header": "network parameters (all model types)", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "|---        |---          |\n| --rnn_enc_depth INT | number of encoder layers (default: 1) |\n| --rnn_enc_transition_depth INT | number of GRU transition operations applied in the encoder. Minimum is 1. (Only applies to gru). (default: 1) |\n| --rnn_dec_depth INT | number of decoder layers (default: 1) |\n| --rnn_dec_base_transition_depth INT | number of GRU transition operations applied in the first layer of the decoder. Minimum is 2. (Only applies to gru_cond). (default: 2) |\n| --rnn_dec_high_transition_depth INT | number of GRU transition operations applied in the higher layers of the decoder. Minimum is 1. (Only applies to gru). (default: 1) |\n| --rnn_dec_deep_context | pass context vector (from first layer) to deep decoder layers |\n| --rnn_dropout_embedding FLOAT | dropout for input embeddings (0: no dropout) (default: 0.0) |\n| --rnn_dropout_hidden FLOAT | dropout for hidden layer (0: no dropout) (default: 0.0) |\n| --rnn_dropout_source FLOAT | dropout source words (0: no dropout) (default: 0.0) |\n| --rnn_dropout_target FLOAT | dropout target words (0: no dropout) (default: 0.0) |\n| --rnn_layer_normalisation | Set to use layer normalization in encoder and decoder |\n| --rnn_lexical_model | Enable feedforward lexical model (Nguyen and Chiang, 2018) |\n", "type": "Text_excerpt", "original_header": "network parameters (rnn-specific)", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "|---        |---          |\n| --transformer_enc_depth INT | number of encoder layers (default: 6) |\n| --transformer_dec_depth INT | number of decoder layers (default: 6) |\n| --transformer_ffn_hidden_size INT | inner dimensionality of feed-forward sub-layers (default: 2048) |\n| --transformer_num_heads INT | number of attention heads used in multi-head attention (default: 8) |\n| --transformer_dropout_embeddings FLOAT | dropout applied to sums of word embeddings and positional encodings (default: 0.1) |\n| --transformer_dropout_residual FLOAT | dropout applied to residual connections (default: 0.1) |\n| --transformer_dropout_relu FLOAT | dropout applied to the internal activation of the feed-forward sub-layers (default: 0.1) |\n| --transformer_dropout_attn FLOAT | dropout applied to attention weights (default: 0.1) |\n| --transformer_drophead FLOAT | dropout of entire attention heads (default: 0.0) |\n", "type": "Text_excerpt", "original_header": "network parameters (transformer-specific)", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "|---        |---          |\n| --loss_function {cross-entropy,per-token-cross-entropy, MRT} | loss function. MRT: Minimum Risk Training https://www.aclweb.org/anthology/P/P16/P16-1159.pdf) (default: cross-entropy) |\n| --decay_c FLOAT | L2 regularization penalty (default: 0.0) |\n| --map_decay_c FLOAT | MAP-L2 regularization penalty towards original weights (default: 0.0) |\n| --prior_model PATH | Prior model for MAP-L2 regularization. Unless using \" --reload\", this will also be used for initialization. |\n| --clip_c FLOAT | gradient clipping threshold (default: 1.0) |\n| --label_smoothing FLOAT | label smoothing (default: 0.0) |\n| --exponential_smoothing FLOAT | exponential smoothing factor; use 0 to disable (default: 0.0) |\n| --optimizer {adam} | optimizer (default: adam) |\n| --adam_beta1 FLOAT | exponential decay rate for the first moment estimates (default: 0.9) |\n| --adam_beta2 FLOAT | exponential decay rate for the second moment estimates (default: 0.999) |\n| --adam_epsilon FLOAT | constant for numerical stability (default: 1e-08) |\n| --learning_schedule {constant,transformer,warmup-plateau-decay} | learning schedule (default: constant) |\n| --learning_rate FLOAT | learning rate (default: 0.0001) |\n| --warmup_steps INT | number of initial updates during which the learning rate is increased linearly during learning rate scheduling (default: 8000) |\n| --plateau_steps INT | number of updates after warm-up before the learning rate starts to decay (applies to 'warmup-plateau-decay' learning schedule only). (default: 0) |\n| --maxlen INT | maximum sequence length for training and validation (default: 100) |\n| --batch_size INT | minibatch size (default: 80) |\n| --token_batch_size INT | minibatch size (expressed in number of source or target tokens). Sentence-level minibatch size will be dynamic. If this is enabled, batch_size only affects sorting by length. (default: 0) |\n| --max_sentences_per_device INT | maximum size of minibatch subset to run on a single device, in number of sentences (default: 0) |\n| --max_tokens_per_device INT | maximum size of minibatch subset to run on a single device, in number of tokens (either source or target - whichever is highest) (default: 0) |\n| --gradient_aggregation_steps INT | number of times to accumulate gradients before aggregating and applying; the minibatch is split between steps, so adding more steps allows larger minibatches to be used (default: 1) |\n| --maxibatch_size INT | size of maxibatch (number of minibatches that are sorted by length) (default: 20) |\n| --no_sort_by_length | do not sort sentences in maxibatch by length |\n| --no_shuffle | disable shuffling of training data (for each epoch) |\n| --keep_train_set_in_memory | Keep training dataset lines stores in RAM during training |\n| --max_epochs INT | maximum number of epochs (default: 5000) |\n| --finish_after INT | maximum number of updates (minibatches) (default: 10000000) |\n| --print_per_token_pro PATH | PATH to store the probability of each target token given source sentences over the training dataset (without training). If set to False, the function will not be triggered. (default: False). Please get rid of the 1.0s at the end of each list which are the probability of padding. |\n", "type": "Text_excerpt", "original_header": "training parameters", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "| parameter | description |\n|---        |---          |\n| --mrt_reference | add reference into MRT candidates sentences (default: False) |\n| --mrt_alpha FLOAT | MRT alpha to control the sharpness of the distribution of sampled subspace (default: 0.005) |\n| --samplesN INT | the number of sampled candidates sentences per source sentence (default: 100) |\n| --mrt_loss | evaluation metrics used to compute loss between the candidate translation and reference translation (default: SENTENCEBLEU n=4) |\n| --mrt_ml_mix FLOAT | mix in MLE objective in MRT training with this scaling factor (default: 0) |\n| --sample_way {beam_search, randomly_sample} | the sampling strategy to generate candidates sentences (default: beam_search) |\n| --max_len_a INT | generate candidates sentences with maximum length: ax + b, where x is the length of the source sentence (default: 1.5) |\n| --max_len_b INT | generate candidates sentences with maximum length: ax + b, where x is the length of the source sentence (default: 5) |\n| --max_sentences_of_sampling INT | maximum number of source sentences to generate candidates sentences at one time (limited by device memory capacity) (default: 0) |\n", "type": "Text_excerpt", "original_header": "minimum risk training parameters (MRT)", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "|---        |---          |\n| --valid_source_dataset PATH | source validation corpus (default: None) |\n| --valid_target_dataset PATH | target validation corpus (default: None) |\n| --valid_batch_size INT | validation minibatch size (default: 80) |\n| --valid_token_batch_size INT | validation minibatch size (expressed in number of source or target tokens). Sentence-level minibatch size will be dynamic. If this is enabled, valid_batch_size only affects sorting by length. (default: 0) |\n| --valid_freq INT | validation frequency (default: 10000) |\n| --valid_script PATH | path to script for external validation (default: None). The script will be passed an argument specifying the path of a file that contains translations of the source validation corpus. It must write a single score to standard output. |\n| --valid_bleu_source_dataset PATH | source validation corpus for external validation (default: None). If set to None, the dataset for calculating validation loss (valid_source_dataset) will be used |\n| --patience INT | early stopping patience (default: 10) |\n", "type": "Text_excerpt", "original_header": "validation parameters", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "|---        |---          |\n| --disp_freq INT | display loss after INT updates (default: 1000) |\n| --sample_freq INT | display some samples after INT updates (default: 10000) |\n| --beam_freq INT | display some beam_search samples after INT updates (default: 10000) |\n| --beam_size INT | size of the beam (default: 12) |\n", "type": "Text_excerpt", "original_header": "display parameters", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "|---        |---          |\n| --normalization_alpha [ALPHA] | normalize scores by sentence length (with argument, \" \"exponentiate lengths by ALPHA) |\n| --n_best | Print full beam |\n| --translation_maxlen INT | Maximum length of translation output sentence (default: 200) |\n| --translation_strategy {beam_search,sampling} | translation_strategy, either beam_search or sampling (default: beam_search) |\n", "type": "Text_excerpt", "original_header": "translate parameters", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "| parameter | description |\n|---        |---          |\n| -v, --verbose | verbose mode |\n| -m PATH [PATH ...], --models PATH [PATH ...] | model to use; provide multiple models (with same vocabulary) for ensemble decoding |\n| -b INT, --minibatch_size INT | minibatch size (default: 80) |\n| -i PATH, --input PATH | input file (default: standard input) |\n| -o PATH, --output PATH | output file (default: standard output) |\n| -k INT, --beam_size INT | beam size (default: 5) |\n| -n [ALPHA], --normalization_alpha [ALPHA] | normalize scores by sentence length (with argument, exponentiate lengths by ALPHA) |\n| --n_best | write n-best list (of size k) |\n| --maxibatch_size INT | size of maxibatch (number of minibatches that are sorted by length) (default: 20) |\n", "type": "Text_excerpt", "original_header": "`nematus/translate.py` : use an existing model to translate a source text", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "| parameter | description |\n|---        |---          |\n| -v, --verbose | verbose mode |\n| -m PATH [PATH ...], --models PATH [PATH ...] | model to use; provide multiple models (with same vocabulary) for ensemble decoding |\n| -b INT, --minibatch_size INT | minibatch size (default: 80) |\n| -n [ALPHA], --normalization_alpha [ALPHA] | normalize scores by sentence length (with argument, exponentiate lengths by ALPHA) |\n| -o PATH, --output PATH | output file (default: standard output) |\n| -s PATH, --source PATH | source text file |\n| -t PATH, --target PATH | target text file |\n\n", "type": "Text_excerpt", "original_header": "`nematus/score.py` : use an existing model to score a parallel corpus", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "The n-best list is assumed to have the same format as Moses:\n\n    sentence-ID (starting from 0) ||| translation ||| scores\n\nnew scores will be appended to the end. `rescore.py` has the same arguments as `score.py`, with the exception of this additional parameter:\n\n| parameter             | description |\n|---                    |--- |\n| -i PATH, --input PATH | input n-best list file (default: standard input) |\n\n", "type": "Text_excerpt", "original_header": "`nematus/rescore.py` : use an existing model to rescore an n-best list.", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"value": "If you have a Theano model (model.npz) with network architecture features that are currently\nsupported then you can convert it into a tensorflow model using `nematus/theano_tf_convert.py`.\n\n| parameter | description |\n|---        |---          |\n| --from_theano | convert from Theano to TensorFlow format |\n| --from_tf | convert from Tensorflow to Theano format |\n| --in PATH | path to input model |\n| --out PATH | path to output model |\n\n", "type": "Text_excerpt", "original_header": "`nematus/theano_tf_convert.py` : convert an existing theano model to a tensorflow model", "parent_header": ["USAGE INSTRUCTIONS"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}], "acknowledgement": [{"result": {"value": "This project has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreements 645452 (QT21), 644333 (TraMOOC), 644402 (HimL) and 688139 (SUMMA).\n", "type": "Text_excerpt", "original_header": "ACKNOWLEDGMENTS"}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}], "citation": [{"result": {"value": "@InProceedings{sennrich-EtAl:2017:EACLDemo,\n  author    = {Sennrich, Rico  and  Firat, Orhan  and  Cho, Kyunghyun  and  Birch, Alexandra  and  Haddow, Barry  and  Hitschler, Julian  and  Junczys-Dowmunt, Marcin  and  L\\\"{a}ubli, Samuel  and  Miceli Barone, Antonio Valerio  and  Mokry, Jozef  and  Nadejde, Maria},\n  title     = {Nematus: a Toolkit for Neural Machine Translation},\n  booktitle = {Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics},\n  month     = {April},\n  year      = {2017},\n  address   = {Valencia, Spain},\n  publisher = {Association for Computational Linguistics},\n  pages     = {65--68},\n  url       = {http://aclweb.org/anthology/E17-3017}\n}", "type": "Text_excerpt", "format": "bibtex"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}], "full_title": [{"result": {"type": "String", "value": ""}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}], "documentation": [{"result": {"type": "Url", "value": "https://github.com/EdinburghNLP/nematus/wiki", "format": "wiki"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}], "related_papers": [{"result": {"type": "Url", "value": "https://arxiv.org/abs/2004.13342\n\n - training features:\n     - multi-GPU support [documentation](doc/multi_gpu_training.md"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1707.07631\n     - dropout on all layers (Gal, 2015"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1608.05859\n     - layer normalisation (Ba et al, 2016"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1711.03953\n     - lexical model (Nguyen and Chiang, 2018"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}, {"result": {"type": "Url", "value": "https://arxiv.org/abs/1607.06450\n     - mixture of softmaxes (Yang et al., 2017"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/EdinburghNLP/nematus/master/README.md"}]}